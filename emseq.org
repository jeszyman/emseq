* Enzymatic Methylation Sequencing Bioinformatics Processes
:PROPERTIES:
:ID:       cd9489fd-c6e7-4c64-8317-e3d9a283b36c
:END:
#+begin_src emacs-lisp
;; In the problem buffers:
(setq-local org-element-use-cache nil)          ;; disable cache for this buffer
(remove-hook 'before-save-hook 'org-table-recalculate-buffer-tables t)
(remove-hook 'org-babel-post-tangle-hook #'remove-property-drawers-from-tangled-file)
(with-eval-after-load 'org-alert (org-alert-disable))  ;; pause org-alert
(remove-hook 'flyspell-post-command-hook #'flyspell-post-command-hook t)  ;; turn off flyspell in this buffer

#+end_src
** [[id:bda70cff-0713-4e32-8da1-ee83924b8f00][README]]
** [[elisp:(progn (org-babel-goto-named-src-block "git-workflow-up") (org-babel-execute-src-block))][Run git workflow up]]
*** Resource Used and Concurrency

EM-seq workflows use Snakemake's resources feature to control how many jobs of a given rule can run simultaneously. Each rule specifies a concurrency value, and a global limit is set at runtime. For example:

resources:
    concurrency=100

Run the workflow with a system-wide concurrency cap:

snakemake --resources concurrency=200

This setup allows Snakemake to schedule up to two jobs requiring concurrency=100 in parallel (200 / 100 = 2). This mechanism helps manage disk I/O, memory pressure, and other shared system resources.

The system is calibrated around a ~96-core machine, where rules requiring concurrency=100 are designed to run one at a time. On larger systems (e.g., 300 cores), multiple such jobs can run concurrently. Lighter-weight rules (e.g., fastp) may specify lower concurrency values (e.g., concurrency=10), allowing many to run in parallel relative to available resources.

Other jobs are better managed by a set CPU number, e.g. samtools sorting is I/O constrained so each job is limited to a set 8 cores. Threads are rule-specific and declared at the rule for such instances.
*** Input data structures
When aggregating library-level outputs into experiment-level analyses, workflows use nested Python dictionaries (dict of dicts) to define experiment metadata. For example:

#+begin_src python
meth_map = {
"test": {
"build": "hg38",
"mincov": "5",
"libs": library_ids,
"tx": "0,1"
}
}
#+end_src

Each top-level key in meth_map (e.g. "test") represents a single experiment — a defined set of libraries run under shared conditions. The associated value is a dictionary containing metadata and parameters for that experiment.

These maps are accessed dynamically in Snakemake rules using the wildcards.experiment variable. For example:

meth_caller = meth_map[wildcards.experiment]["meth_caller"]

This design enables flexible reuse of libraries across multiple experimental contexts, making it easy to reprocess the same samples under different parameter settings or analytical strategies.

*** Miscellaneous pipeline nuances

Most paths are relative to a common $data_dir and outputs have a set directory structure.

The emseq_bam_dir is individually declared. This allows for workflows where multiple sequencing lanes are merged per-sample at the bam level.

For example, so data_dir=/mnt/data/projects/nf1 and we run the pipeline for sample emseq_09. An output tree would look like:

/mnt/data/projects/nf1/
├── analysis
│   └── emseq
│       ├── fastqs
│       │   ├── emseq_09_failed.fastq.gz
│       │   ├── emseq_09_raw_R1.fastq.gz
│       │   ├── emseq_09_raw_R2.fastq.gz
│       │   ├── emseq_09_trimmed_R1.fastq.gz
│       │   └── emseq_09_trimmed_R2.fastq.gz
│       └── spike
│           ├── emseq_09.puc19.bwa_meth.coorsorted.bam
│           ├── emseq_09.puc19.bwa_meth.coorsorted.bam.bai
│           ├── emseq_09.puc19.bwa_meth_methyldackel_CpG.methylKit
│           ├── emseq_09.unmeth_lambda.bwa_meth.coorsorted.bam
│           ├── emseq_09.unmeth_lambda.bwa_meth.coorsorted.bam.bai
│           └── emseq_09.unmeth_lambda.bwa_meth_methyldackel_CpG.methylKit
├── inputs
│   ├── 9_em_seq_pilot_5_S9_R1_001.fastq.gz
│   ├── 9_em_seq_pilot_5_S9_R2_001.fastq.gz
│   ├── GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fa.gz
│   ├── Lambda_NEB.fa.gz
│   └── pUC19.fa.gz
├── logs
│   ├── emseq_09-emseq-fastp.html
│   ├── emseq_09-emseq-fastp.json
│   ├── emseq_09-emseq-fastp.log
│   ├── emseq_09.puc19.emseq_align_bwameth_spike.log
│   ├── emseq_09.unmeth_lambda.emseq_align_bwameth_spike.log
│   ├── emseq_09_puc19_bwa_meth_methyldackel.log
│   ├── emseq_09_raw_R1_fastqc.log
│   ├── emseq_09_raw_R2_fastqc.log
│   ├── emseq_09_trimmed_R1_fastqc.log
│   ├── emseq_09_trimmed_R2_fastqc.log
│   ├── emseq_09_unmeth_lambda_bwa_meth_methyldackel.log
│   ├── puc19_bwa_meth_index.log
│   └── unmeth_lambda_bwa_meth_index.log
├── qc
│   ├── emseq_09_raw_R1_fastqc.html
│   ├── emseq_09_raw_R1_fastqc.zip
│   ├── emseq_09_raw_R2_fastqc.html
│   ├── emseq_09_raw_R2_fastqc.zip
│   ├── emseq_09_trimmed_R1_fastqc.html
│   ├── emseq_09_trimmed_R1_fastqc.zip
│   ├── emseq_09_trimmed_R2_fastqc.html
│   └── emseq_09_trimmed_R2_fastqc.zip
└── ref
    └── bwa_meth
        ├── puc19
        │   ├── puc19.fa
        │   ├── puc19.fa.bwameth.c2t
        │   ├── puc19.fa.bwameth.c2t.0123
        │   ├── puc19.fa.bwameth.c2t.amb
        │   ├── puc19.fa.bwameth.c2t.ann
        │   ├── puc19.fa.bwameth.c2t.bwt.2bit.64
        │   ├── puc19.fa.bwameth.c2t.pac
        │   └── puc19.fa.fai
        └── unmeth_lambda
            ├── unmeth_lambda.fa
            ├── unmeth_lambda.fa.bwameth.c2t
            ├── unmeth_lambda.fa.bwameth.c2t.0123
            ├── unmeth_lambda.fa.bwameth.c2t.amb
            ├── unmeth_lambda.fa.bwameth.c2t.ann
            ├── unmeth_lambda.fa.bwameth.c2t.bwt.2bit.64
            ├── unmeth_lambda.fa.bwameth.c2t.pac
            └── unmeth_lambda.fa.fai


Alignments to spiked DNA references are specialized for fast accurate global methylation counts for these small references.

** Repository administration
#+begin_src bash :tangle ./tools/get_test_data.sh
#!/usr/bin/env bash
# setup_test_data.sh — chr22 subset + lambda + pUC19 FASTA, plus 4 tiny paired WGBS FASTQs
# Paired-only; hard-fails if a run lacks _1/_2. Cleans tests/full/ before writing.
set -euo pipefail

# --- self-locate & cd to repo root (script is assumed to live one level below root, e.g., tools/) ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_DIR="$(dirname "$SCRIPT_DIR")"
cd "$REPO_DIR" || { echo "ERR: failed to cd to repo root: $REPO_DIR" >&2; exit 1; }

# --- config ---
R_EMSEQ="${R_EMSEQ:-$PWD}"
TEST_DIR="${R_EMSEQ}/tests/full"
OUT_DIR="${TEST_DIR}/inputs"
OUT_FA="${OUT_DIR}/chr22.test.fa.gz"
OUT_LAMBDA="${OUT_DIR}/lambda.fa.gz"
OUT_PUC19="${OUT_DIR}/pUC19.fa.gz"
OUT_BLK="${OUT_DIR}/hg38-blacklist.v2.bed.gz"

# NEW: bed outputs
KEEP_BED="${OUT_DIR}/chr22.keep.bed"
EXCL_BED="${OUT_DIR}/chr22.exclude.blacklist.bed.gz"

REF_URL="https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/chr22.fa.gz"
FA_HEAD_LINES=4000000

# full (small) references
LAMBDA_URL="https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id=9626243&db=nuccore&report=fasta&retmode=text"

# pUC19 via NCBI efetch (hard-coded tool/email)
PUC19_EFETCH="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=L09137.2&rettype=fasta&retmode=text&tool=emseq_setup&email=anon@example.com"

BLK_URL="https://raw.githubusercontent.com/Boyle-Lab/Blacklist/master/lists/hg38-blacklist.v2.bed.gz"

NREADS="${NREADS:-60000}"   # reads per mate for FASTQ clipping
FQ_HEAD_LINES=$((NREADS * 4))

# ENA WGBS runs (paired) — adjust as needed
ACCESSIONS=( "ERR022484" "ERR022487" "ERR022003" "ERR022483" )

# --- deps ---
need(){ command -v "$1" >/dev/null 2>&1 || { echo "Missing: $1" >&2; exit 1; }; }
need git; need wget; need curl; need zcat; need gzip; need wc; need head; need grep; need sed
# NEW: for beds
need samtools; need bedtools; need bgzip; need tabix; need awk; need sort; need cut

# --- ensure .gitignore rules: ignore tests/full/* but NOT tests/full/inputs/** ---
ensure_gitignore() {
  local gi="${REPO_DIR}/.gitignore"
  local req1='tests/full/*'
  local req2='!tests/full/inputs/'
  local req3='!tests/full/inputs/**'
  touch "$gi"
  local have1=0 have2=0 have3=0
  grep -Fxq "$req1" "$gi" && have1=1 || true
  grep -Fxq "$req2" "$gi" && have2=1 || true
  grep -Fxq "$req3" "$gi" && have3=1 || true
  if (( ! have1 || ! have2 || ! have3 )); then
    {
      echo ''
      echo '# --- test data (auto-managed by setup_test_data.sh) ---'
      (( have1 )) || echo "$req1"
      (( have2 )) || echo "$req2"
      (( have3 )) || echo "$req3"
    } >> "$gi"
    echo "[gitignore] ensured patterns for tests/full with inputs preserved"
  fi
}

# ENA dir that contains both _1/_2
ena_dir_for() {
  local acc="$1" first6="${acc:0:6}" last3="${acc: -3}"
  local candidates=(
    "https://ftp.sra.ebi.ac.uk/vol1/fastq/${first6}/${acc}/"
    "https://ftp.sra.ebi.ac.uk/vol1/fastq/${first6}/${last3}/${acc}/"
  )
  for d in "${candidates[@]}"; do
    if wget -q --spider "${d}${acc}_1.fastq.gz" && wget -q --spider "${d}${acc}_2.fastq.gz"; then
      echo "$d"; return 0
    fi
  done
  return 1
}

# wget stream → zcat → head → gzip (silence SIGPIPE noise)
fetch_head() {
  ( set +o pipefail
    wget -qO- "$1" | zcat 2>/dev/null | head -n "$2" | gzip > "$3"
  ) || true
}

# download full compressed file (blacklist)
fetch_all_gz() { wget -qO "$2" "$1"; }

# --- add near fetch_puc19() ---
fetch_plain_fasta_gzip() {
  local url out tmp
  url="$1"
  out="$2"
  tmp="${out%.gz}.tmp"
  rm -f "$tmp" "$out"
  curl -fsSL "$url" -o "$tmp"
  [[ -s "$tmp" ]] || { echo "ERR: lambda fetch produced empty file"; exit 1; }
  head -n1 "$tmp" | grep -q '^>' || { echo "ERR: lambda FASTA header missing"; exit 1; }
  gzip -f "$tmp"
  mv "${tmp}.gz" "$out"
}

# robust pUC19: fetch plain FASTA to tmp with curl, validate header, then gzip
fetch_puc19() {
  local url out tmp
  url="$1"; out="$2"; tmp="${out%.gz}.tmp"
  rm -f "$tmp" "$out"
  curl -fsSL "$url" -o "$tmp"
  [[ -s "$tmp" ]] || { echo "ERR: pUC19 fetch produced empty file"; exit 1; }
  head -n1 "$tmp" | grep -q '^>' || { echo "ERR: pUC19 FASTA header missing"; exit 1; }
  gzip -f "$tmp"
  mv "${tmp}.gz" "$out"
}

check_fastq() {
  local f="$1"
  [[ -s "$f" ]] || { echo "ERR: empty $f" >&2; return 1; }
  local n; n=$(zcat "$f" 2>/dev/null | wc -l)
  (( n % 4 == 0 )) || echo "WARN: $f has $n lines (not multiple of 4)"
  echo "[ok] $(basename "$f"): $(( n / 4 )) reads"
}

# --- run ---
ensure_gitignore

echo "[clean] removing ${TEST_DIR}"
rm -rf "${TEST_DIR}"
mkdir -p "${OUT_DIR}"

# keep inputs dir tracked even if empty (optional helper file)
[[ -e "${OUT_DIR}/.gitkeep" ]] || : > "${OUT_DIR}/.gitkeep"

echo "[ref] chr22 subset → ${OUT_FA}"
fetch_head "${REF_URL}" "${FA_HEAD_LINES}" "${OUT_FA}"
[[ -s "${OUT_FA}" ]] || { echo "ERR: failed to write ${OUT_FA}"; exit 1; }

echo "[ref] lambda (full) → ${OUT_LAMBDA}"
fetch_plain_fasta_gzip "${LAMBDA_URL}" "${OUT_LAMBDA}"
[[ -s "${OUT_LAMBDA}" ]] || { echo "ERR: failed to write ${OUT_LAMBDA}"; exit 1; }

echo "[ref] pUC19 (NCBI efetch) → ${OUT_PUC19}"
fetch_puc19 "${PUC19_EFETCH}" "${OUT_PUC19}"
[[ -s "${OUT_PUC19}" ]] || { echo "ERR: failed to write ${OUT_PUC19}"; exit 1; }

echo "[ref] hg38 blacklist → ${OUT_BLK}"
fetch_all_gz "${BLK_URL}" "${OUT_BLK}"
[[ -s "${OUT_BLK}" ]] || { echo "ERR: failed to write ${OUT_BLK}"; exit 1; }


# --- tiny paired FASTQs ---
i=1
for acc in "${ACCESSIONS[@]}"; do
  dir="$(ena_dir_for "$acc")" || { echo "ERR: ${acc} is not paired on ENA" >&2; exit 1; }
  r1="${dir}${acc}_1.fastq.gz"
  r2="${dir}${acc}_2.fastq.gz"

  id=$(printf "lib%03d" "$i")
  out1="${OUT_DIR}/${id}.raw_R1.fastq.gz"
  out2="${OUT_DIR}/${id}.raw_R2.fastq.gz"
  echo "[fq] ${id} (${acc}) → ${out1}, ${out2}"

  fetch_head "$r1" "${FQ_HEAD_LINES}" "$out1"
  fetch_head "$r2" "${FQ_HEAD_LINES}" "$out2"
  check_fastq "$out1"
  check_fastq "$out2"
  i=$((i+1))
done

# --- NEW: build keep/exclude BEDs in inputs/ from chr22.test.fa.gz + blacklist ---
echo "[beds] building keep/exclude from ${OUT_FA}"
FA_UNGZ="${OUT_DIR}/chr22.test.fa"
zcat "${OUT_FA}" > "${FA_UNGZ}"
samtools faidx "${FA_UNGZ}"

# KEEP: spans for all contigs present in the .fai (chr22-only here)
awk 'BEGIN{OFS="\t"} {print $1,0,$2}' "${FA_UNGZ}.fai" \
  | sort -k1,1 -k2,2n > "${KEEP_BED}" |

# EXCLUDE: clip blacklist to contigs present in .fai and bgzip
awk 'NR==FNR{ok[$1]=1; next} ok[$1]' <(cut -f1 "${FA_UNGZ}.fai") <(zcat "${OUT_BLK}") \
  | sort -k1,1 -k2,2n | bgzip > "${EXCL_BED}" |
tabix -p bed "${EXCL_BED}" || true
echo "[beds] keep=${KEEP_BED}  exclude=${EXCL_BED}"

echo "Done. Outputs in: ${OUT_DIR}"
echo "  - FASTA subset: ${OUT_FA} (+ ${FA_UNGZ} + .fai)"
echo "  - Keep BED:     ${KEEP_BED}"
echo "  - Exclude BED:  ${EXCL_BED}"
#+end_src

*** Git
#+name: git-workflow-up
#+begin_src bash :results replace raw
source ~/repos/basecamp/lib/basecamp_functions.sh
cd ~/repos/emseq
output=$(git_wkflow_up 2>&1)
if [ $? -ne 0 ]; then
    echo "Error running git_wkflow_up"
    echo "$output"
    exit 1
fi

echo -e "$(date)\n$output"

#+end_src

#+RESULTS: git-workflow-up
Tue Jul 29 10:29:51 AM CDT 2025
[master 5f2f3ee] .
 2 files changed, 34 insertions(+), 2 deletions(-)
 create mode 100644 README.md
To github.com:jeszyman/emseq.git
   c8a1914..5f2f3ee  master -> master
Fri Jul 25 07:52:01 PM CDT 2025
[master 8b5da07] .
 7 files changed, 1 insertion(+), 107 deletions(-)
To github.com:jeszyman/emseq.git
   c61d380..8b5da07  master -> master
Tue Jun 10 12:09:57 PM CDT 2025
[master dac7ee5] .
 2 files changed, 4 insertions(+), 4 deletions(-)
To github.com:jeszyman/emseq.git
   1095335..dac7ee5  master -> master
Mon Jun  9 09:24:27 AM CDT 2025
[master 6ded313] .
 2 files changed, 2 insertions(+), 2 deletions(-)
To github.com:jeszyman/emseq.git
   4862c0c..6ded313  master -> master
**** first test
#+begin_src yaml :tangle ./.github/workflows/test-data.yml
name: test-data

on:
  pull_request:
    paths:
      - "tools/get_test_data.sh"
      - "tests/**"
      - "config/emseq-ci.yaml"
      - ".github/workflows/test-data.yml"
  schedule:
    - cron: "0 4 * * 1"
  workflow_dispatch: {}

concurrency:
  group: test-data-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

defaults:
  run:
    shell: bash -l {0}

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - name: Verify CI env file
        run: |
          set -euo pipefail
          test -f config/emseq-ci.yaml
          sed -n '1,40p' config/emseq-ci.yaml

      - name: Setup Conda (Miniforge)
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          auto-activate-base: false
          use-mamba: true
          environment-file: config/emseq-ci.yaml

      - name: Make script executable
        run: chmod +x tools/get_test_data.sh

      - name: Execute script (in env)
        run: ./tools/get_test_data.sh

      - name: Sanity checks
        run: |
          set -euo pipefail
          test -d tests/full || (echo "tests/full not created" >&2; exit 1)
          fq_count=$(find tests/full -type f -name "*fastq.gz" | wc -l)
          (( fq_count >= 4 )) || { echo "Expected ≥4 FASTQs, got ${fq_count}"; exit 1; }
          fasta_count=$(find tests/full -type f \( -name "*chr22*.fa*" -o -name "*lambda*.fa*" -o -name "*pUC19*.fa*" \) | wc -l)
          (( fasta_count >= 1 )) || { echo "Expected ≥1 reference FASTA"; exit 1; }
          echo "OK: test data present."

#+end_src

*** README
:PROPERTIES:
:ID:       bda70cff-0713-4e32-8da1-ee83924b8f00
:export_file_name: README
:END:
[[file:README.md]]
#+begin_src bash
python3 ~/repos/basecamp/scripts/emacs_export_header_to_markdown.py --org_file ~/repos/emseq/emseq.org --node_id bda70cff-0713-4e32-8da1-ee83924b8f00

#+end_src

The EM-seq repository contains modular workflows intended to be run from within a over-wrapping snakemake workflow.

Current stable version tested with minimal in-repo example is tagged emseq.v3.0.0.

[[file:resources/test_smk.png]]

**** Prerequisites
**** Change Log
- Dev
  - [2025-09-19 Fri] Added a first github workflow test
  - [2025-09-19 Fri] Robust annotation of methylkit outputs validated as rscript
- [2025-09-19 Fri] Updated EM-seq main pipeline to wf/emseq/v3.0.0.
  - Includes in-repo small test data for a complete run of emseq.smk
  - Includes test.smk wrapper and corresponding test.yaml for in-repo small test run
  - emseq.smk expanded to include differential methylation from nested list map
  - Many small fixes for consistent naming and run condition optimization
- [2025-09-18 Thu] Updated EM-seq main pipeline to wf/emseq/v2.0.0. Mainly improved and simplified variable naming.
** Conda environmental YAMLs
*** Test data
#+begin_src yaml :tangle ./config/testdata-conda-env.yaml
name: testdata
channels:
  - conda-forge
  - bioconda

dependencies:
  - seqtk

#+end_src

*** EM-seq
#+begin_src yaml :tangle ./config/emseq-conda-env.yaml
name: emseq
channels:
  - conda-forge
  - bioconda

dependencies:
  - fastp
  - fastqc
  - bedtools
  - samtools
  - bioconductor-genomeinfodbdata=1.2.7
  - biscuit=1.6.0.20241216=*_1
  - dupsifter=1.3.0.20241113=*_1
  - bismark
  - bwa
  - bwameth
  - methyldackel
  - mosdepth
  - multiqc
  - r-argparse
  - r-data.table
  - r-ggplot2
  - r-cairo
  - r-scales
  - r-patchwork
  - r-matrixstats

#+end_src
*** MethylKit
#+begin_src yaml :tangle ./config/methylkit-conda-env.yaml
name: methylkit
channels:
  - conda-forge
  - bioconda

dependencies:
  - r-argparse
  - bioconductor-methylkit
  - r-data.table=1.15.4
  - r-tidyverse
  - bioconductor-genomicranges
  - bioconductor-annotatr
  - bioconductor-txdb.hsapiens.ucsc.hg38.knowngene
  - bioconductor-org.hs.eg.db
  - bioconductor-genomation
  - r-arrow
#+end_src
*** Mosdepth
#+begin_src yaml :tangle ./config/mosdepth-conda-env.yaml
name: mosdepth
channels:
  - conda-forge
  - bioconda

dependencies:
  - samtools
  - bioconductor-genomeinfodbdata=1.2.7
  - mosdepth
  - r-argparse
  - r-data.table
  - r-ggplot2
  - r-cairo
  - jpeg
  - r-scales
  - r-patchwork
  - r-matrixstats
  - r-r.utils
#+end_src

*** bwa-meth
#+begin_src yaml :tangle ./config/bwa-meth-env.yaml
name: bwa_mem
channels:
  - conda-forge
  - bioconda

dependencies:
  - samtools
  - bwa
  - bwameth
  - methyldackel
#+end_src

** Input data model
#+begin_src yaml
defaults:
  required: false       # Default: fields are not required unless specified
  primary_key: false    # Default: fields are not primary keys unless specified

entities:
  - name: subjects
    attributes:
      - name: subject_id
        type: string
        primary_key: true      # Unique identifier for each subject
        required: true

  - name: samples
    attributes:
      - name: sample_id
        type: string
        primary_key: true      # Unique ID for each sample
        required: true
      - name: subject_id
        type: string
        foreign_key: subjects.subject_id   # Link back to subject
        required: true
      - name: sample_type
        type: enum
        values: [biofluid, tissue]         # Sample subtype
        required: true
      - name: collection_date
        type: datetime                         # When sample was collected

  - name: biofluid
    attributes:
      - name: sample_id
        type: string
        primary_key: true
        foreign_key: samples.sample_id     # Must match a sample of type biofluid
        required: true
      - name: biofluid_type
        type: enum
        values: [plasma, serum, csf, drain, urine, other]   # Specific fluid type
      - name: cfdna_conc
        type: float
        unit: ng/uL                         # Concentration of cfDNA

  - name: biofluid_derivative
    attributes:
      - name: aliquot_id
        type: string
        primary_key: true                  # Unique ID for each aliquot
        required: true
      - name: sample_id
        type: string
        foreign_key: biofluid.sample_id    # Parent biofluid sample
        required: true
      - name: biofluid_derivative_type
        type: enum
        values: [ppp, pfp, other]          # Processing method
      - name: derivative_processing_date
        type: date                         # When derivative was processed

  - name: tissue
    attributes:
      - name: sample_id
        type: string
        primary_key: true
        foreign_key: samples.sample_id     # Must match a sample of type tissue
        required: true

  - name: libraries
    attributes:
      - name: library_id
        type: string
        primary_key: true                  # Unique ID for each library
        required: true
      - name: sample_id
        type: string
        foreign_key: samples.sample_id     # Source sample for this library
        required: true
      - name: pcr_cycltes
        type: integer
      - name: expected_coverage
        type: integer

  - name: sequencing
    attributes:
      - name: seq_run_id
        type: string
        primary_key: true                  # Unique ID for sequencing run
        required: true
      - name: library_id
        type: string
        foreign_key: libraries.library_id  # Library used in sequencing
        required: true
      - name: run_date
        type: date                         # When sequencing occurred
      - name: read_length
        type: integer                      # Read length (e.g. 150)
        required: true
      - name: paired_end
        type: boolean                      # True if paired-end sequencing
        required: true

relationships:
  - from: subjects
    to: samples
    type: one-to-many       # One subject can have many samples

  - from: samples
    to: libraries
    type: one-to-many       # One sample can yield multiple libraries

  - from: samples
    to: biofluid
    type: one-to-one        # A sample is either biofluid or tissue

  - from: samples
    to: tissue
    type: one-to-one        # "

  - from: biofluid
    to: biofluid_derivative
    type: one-to-many       # Each biofluid must have at least one aliquot

  - from: libraries
    to: sequencing
    type: one-to-many       # A library can be sequenced multiple times
#+end_src
** Methylation sequence processing
:PROPERTIES:
:ID:       92e64b67-c219-4146-a89b-a8710d91a634
:header-args:snakemake: :tangle ./workflows/emseq.smk
:END:
[[file:workflows/emseq.smk]]

#+begin_src python :results output replace
import re
from pathlib import Path

snakefile = Path("./workflows/emseq.smk").read_text()

# Matches: config["..."] or config['...']
matches = re.findall(r"config\[['\"]([^'\"]+)['\"]\]", snakefile)

# Deduplicate and sort
unique_keys = sorted(set(matches))

print("Config keys required:")
for key in unique_keys:
    print(f"- {key}")

#+end_src

#+RESULTS:
: Config keys required:
: - emseq_ref_assemblies


The BWA-meth and biscuit workflows requires a reference gzipped fasta in $data_dir/inputs, specified in the config yaml like:
#+begin_src yaml
emseq_ref_assemblies:
  ensembl_hg38:
    url: https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
    name: ensembl_hg38
    input: Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
#+end_src

This will be indexed and used for alignment.

*** Writeup

- Sample preparation and sequencing.
  Cell-free DNA was extracted and prepared using the NEBNext® Enzymatic Methyl-seq (EM-seq) Kit following the manufacturer's protocol. Libraries were sequenced on an Illumina platform using paired-end 150 bp reads.

- Sequencing read pre-processing and quality control.
  Raw sequencing reads were processed with fastp using default parameters, with adapter detection enabled and quality filtering disabled. FastQC was used to assess read quality before and after trimming.

- Alignment and de-duplication.
  Reads were aligned to reference genome(s) using BWA-meth with default parameters. Resulting BAMs were coordinate-sorted and deduplicated using dupsifter (https://github.com/brentp/dupsifter), which performs read name-aware de-duplication optimized for bisulfite-style alignments. Only properly paired reads (SAM flag 0x2) were retained prior to deduplication.

- Methylation calling.
  Methylation calls were made on deduplicated BAMs using MethylDackel (v0.6.1), with CpG-context methylation extracted in methylKit-compatible format (--methylKit). Calls were further processed using methylKit (v1.22.0) for filtering, tabix compression, and downstream differential methylation analysis. For each sample, methylation calls were filtered using a minimum coverage threshold of 10×.

- Quality Control
  - Depth estimation.
    Coverage profiles were generated using mosdepth (v0.3.3) on deduplicated BAMs. Runs were performed in fast mode with 1 kb windows and median depth calculation enabled. Per-sample coverage threshold summaries and quantization tracks were generated and aggregated using a custom R script, which also calculated autosomal median depth and generated multi-panel PDF plots showing coverage distribution across user-defined thresholds.

  - Spike-in controls and conversion rate estimation.
    Each EM-seq library included unmethylated Lambda and fully methylated CpG pUC19 spike-ins. Reads were aligned to spike-in references using BWA-meth, and methylation levels were quantified using MethylDackel. Conversion efficiency was estimated from Lambda (expected methylation <1%), and methylation completeness from pUC19 (expected >90% CpG methylation) [@vaisvila2021; @chauhan2024; @emseq2023manual].

  - M-bias detection.
    To detect potential position-dependent biases in methylation calls, MethylDackel's mbias mode was used on deduplicated BAMs. Reads were assessed for strand-specific methylation bias across read positions, and results were reviewed to ensure negligible systematic error.

- Pipeline orchestration.
  All steps were executed using a reproducible Snakemake (v7.x) workflow with conda-based environment isolation. Logging was performed at each rule level, and intermediate files were tracked and retained as needed.

*** Preamble
#+begin_src snakemake
############################
###   EM-Seq Snakefile   ###
############################

#########1#########2#########3#########4#########5#########6#########7#########8
#
# A snakefile for basic processing of EM-seq sequencing data
#+end_src

*** Spike workflow

The EM-seq kit includes two control DNA spike-ins, unmethylated Lambda and CpG methylated pUC19.

"Regardless of sequencing depth, a minimum of 5,000 paired end reads with a read length of 76 bases, for unmethylated Lambda DNA, and 500 paired end reads with a read length of 76 bases, for CpG methylated pUC19, are needed to give enough coverage for accurate conversion estimates." [cite:@emseq2023manual].

We expect Lambda methylation rates below 1% as shown in [cite:@vaisvila2021]

and we expect above 90% methylation of exclusively CpG sites for pUC19

#+CAPTION: vaisvila2021figs7c.png
#+NAME: fig:vaisvila2021fig7c
#+ATTR_ORG: :width 800
[[file:./resources/vaisvila2021figs7c.png]]

The spike workflow uses bwa-meth to quickly align to phage reference genomes. Coordinate-sorted BAM output is limited to only reads matching the phage index (-F 4). CpG methylation is called in methyldackel, allowing duplicates,

- [cite:@vaisvila2021]
- [cite:@chauhan2024]
- [cite:@emseq2023manual]

**** Align
#+begin_src snakemake
rule emseq_align_bwameth_spike:
    message: "EM-seq bwameth (spike) for {wildcards.library_id} {wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    threads: 48
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}"
    resources:
        concurrency=50
    input:
        r1  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        ref = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    output:
        bam = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.bwa_meth.coorsort.bam",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth_spike.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth_spike.tsv"
    shell:
        r"""

        exec &>> "{log.cmd}"
        echo "[bwameth-spike] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} threads={threads}"

        bwameth.py --threads {threads} \
          --reference "{input.ref}" \
          "{input.r1}" "{input.r2}" \
        | samtools view -@ 8 -u -F 4 - \
        | samtools sort -@ 8 -T "{params.temp_prefix}" -o "{output.bam}"
        """

#+end_src

**** Call methylation
#+begin_src snakemake
rule emseq_methyldackel_spike:
    message: "EM-seq MethylDackel (spike) for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_EMSEQ
    threads: 8
    input:
        bam   = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.bam",
        fasta = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    output:
        bed = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel_spike.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel_spike.tsv"
    params:
        out_prefix = lambda wc, input, output: output.bed.rsplit("_CpG.methylKit", 1)[0]
    shell:
        r"""
        mkdir -p "$(dirname "{params.out_prefix}")"


        exec &>> "{log.cmd}"
        echo "[methyldackel-spike] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"

        MethylDackel extract \
          -@ {threads} \
          --methylKit \
          "{input.fasta}" \
          "{input.bam}" \
          -o "{params.out_prefix}"
        """
#+end_src


*** BWA-Meth

BWA-meth alignment is much faster than biscuit.

BWA-meth output is a duplicated, coordinate sorted BAM. This is de-duplicated during methylation calls by methyldackel.

Reference
- https:/github.com/brentp/bwa-meth

**** Index

#+begin_src snakemake
# -------- Index (bwa-meth) --------
rule bwa_meth_index:
    message: "bwa-meth index for {wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    input:
        lambda wc: f"{D_INPUTS}/{config['emseq_ref_assemblies'][wc. emseq_ref_name]['input']}"
    output:
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.0123",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.amb",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.ann",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.bwt.2bit.64",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.pac",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",
    params:
        fasta_target = lambda wc: f"{D_REF}/bwa_meth/{wc.emseq_ref_name}/{wc.emseq_ref_name}.fa"
    log:
        cmd = f"{D_LOGS}/{{emseq_ref_name}}_bwa_meth_index.log",
    benchmark:
        f"{D_BENCHMARK}/{{emseq_ref_name}}_bwa_meth_index.tsv"
    shell:
        r"""
        exec &>> "{log.cmd}"
        echo "[bwa-meth index] $(date) emseq_ref_name={wildcards.emseq_ref_name} threads={threads}"


        if file -b "{input}" | grep -qi gzip; then
            zcat "{input}" > "{params.fasta_target}"
        else
            cat "{input}" > "{params.fasta_target}"
        fi

        samtools faidx "{params.fasta_target}"
        bwameth.py index-mem2 "{params.fasta_target}"
        """
#+end_src

**** Align

#+begin_src snakemake
# -------- Align (bwa-meth) --------
rule emseq_align_bwameth:
    message: "EM-seq bwameth for {wildcards.library_id} {wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    threads: min(workflow.cores, 48)
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}",
    resources:
        concurrency = 50,
    input:
        r1  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        ref = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        c2t = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t",
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.bwa_meth.coorsort.bam",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}_bwameth.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}_bwameth.tsv"
    shell:
        r"""
        exec &>> "{log.cmd}"
        echo "[bwameth] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} threads={threads}"

        mkdir -p "$(dirname "{params.temp_prefix}")"

        bwameth.py --threads {threads} \
          --reference "{input.ref}" \
          "{input.r1}" "{input.r2}" \
        | samtools view -u - \
        | samtools sort -@ 8 -T "{params.temp_prefix}" -o "{output.bam}"
        """
#+end_src

**** Post-align
***** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
***** [[id:6a1d8806-5649-42e9-977d-c681a3106784][Filter]]
***** [[id:e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c][Call methylation]]
*** Biscuit
**** Index
#+begin_src snakemake
rule biscuit_index:
    message: "biscuit index for {wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    input:
        lambda wc: f"{D_INPUTS}/{config['emseq_ref_assemblies'][wc.emseq_ref_name]['input']}"
    output:
        fasta = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        fai = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",
        index = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.par.sa",
        biscuit_index_done = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.biscuit.index.done"
    log:
        cmd = f"{D_LOGS}/{{emseq_ref_name}}_biscuit_index.log"
    shell:
        r"""
        exec &>> "{log.cmd}"
        mkdir -p "$(dirname "{output.fasta}")"
        zcat "{input}" > "{output.fasta}"
        samtools faidx "{output.fasta}"
        biscuit index "{output.fasta}"
        touch "{output.biscuit_index_done}"
        """
#+end_src
**** Align
#+begin_src snakemake
rule emseq_align_biscuit:
    message: "Biscuit alignment for {wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    threads: min(workflow.cores, 48)
    input:
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        fasta = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        index = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.par.sa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.biscuit.coorsort.log",
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.biscuit.coorsort.bam",
    params:
        tmp_dir = D_DATA,
    resources:
        concurrency = 100
    shell:
        r"""
        exec &>> "{log.cmd}"
        mkdir -p "{params.tmp_dir}/tmp"
        biscuit align -@ {threads} "{input.fasta}" "{input.r1}" "{input.r2}" \
        | samtools sort -@ {threads} -m 2G \
            -T "{params.tmp_dir}/tmp/{wildcards.library_id}_sorttmp" \
            -o "{output.bam}"
        """

#+end_src

**** Post-align
***** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
***** [[id:6a1d8806-5649-42e9-977d-c681a3106784][Filter]]
***** [[id:e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c][Call methylation]]
*** Common Steps
**** Common fastq
***** Fastp
#+begin_src snakemake
rule emseq_fastp:
    message: "EM-seq fastp for {wildcards.library_id}"
    conda: ENV_EMSEQ
    threads: 8
    params:
        extra = config.get("fastp", {}).get("extra", ""),
    input:
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R2.fastq.gz",
    output:
        failed = f"{D_EMSEQ}/fastqs/{{library_id}}.failed.fastq.gz",
        html = f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.html",
        json = f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.json",
        r1     = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2     = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
    log:
        cmd  = f"{D_LOGS}/{{library_id}}_emseq_fastp.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}_emseq_fastp.tsv"
    shell:
        r"""

        # Logging and console output
        exec &>> "{log.cmd}"
        echo "[fastp] $(date) lib={wildcards.library_id} threads={threads}"

        # Main
        fastp \
          --detect_adapter_for_pe \
          --disable_quality_filtering \
          --in1 "{input.r1}" --in2 "{input.r2}" \
          --out1 "{output.r1}" --out2 "{output.r2}" \
          --failed_out "{output.failed}" \
          --json "{output.json}" --html "{output.html}" \
          --thread {threads} \
          {params.extra}
        """
#+end_src

***** FastQC
#+begin_src snakemake
rule emseq_fastqc:
    message: "EM-seq FastQC for {wildcards.library_id} {wildcards.processing} {wildcards.read}"
    conda: ENV_EMSEQ
    threads: 4
    resources:
        concurrency = 25
    input:
        fq = f"{D_EMSEQ}/fastqs/{{library_id}}.{{processing}}_{{read}}.fastq.gz",
    output:
        html = f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.html",
        zip  = f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{processing}}_{{read}}_emseq_fastqc.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{processing}}_{{read}}_emseq_fastqc.tsv"
    shell:
        r"""
        exec &>> "{log.cmd}"
        echo "[fastqc] $(date) lib={wildcards.library_id} proc={wildcards.processing} read={wildcards.read} threads={threads}"

        fastqc \
          --outdir "$(dirname "{output.html}")" \
          --quiet \
          --threads {threads} \
          "{input.fq}"
        """

#+end_src
**** Common alignment processing
***** Depth
#+begin_src snakemake
rule emseq_mosdepth:
    message: "EM-seq mosdepth for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_EMSEQ
    threads: 8
    resources:
        concurrency = 20
    params:
        script       = f"{R_EMSEQ}/scripts/emseq_mosdepth.sh",
        quant_levels = config.get("mosdepth-quant-levels", ""),
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        index = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
    output:
        summary       = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
        global_dist   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.global.dist.txt",
        region_dist   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.region.dist.txt",
        regions       = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.regions.bed.gz",
        regions_idx   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.regions.bed.gz.csi",
        quantized     = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.quantized.bed.gz",
        quantized_idx = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.quantized.bed.gz.csi",
        thresholds    = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.thresholds.bed.gz",
        thresholds_idx= f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.thresholds.bed.gz.csi",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mosdepth.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mosdepth.tsv"
    shell:
        r"""

        exec &>> "{log.cmd}"
        echo "[mosdepth] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"

        "{params.script}" \
        "{input.bam}" \
        "$(dirname "{output.summary}")" \
        "{wildcards.library_id}.{wildcards.emseq_ref_name}.{wildcards.align_method}" \
        '{params.quant_levels}' \
        {threads}
        """

#+end_src

#+begin_src bash :tangle ./scripts/emseq_mosdepth.sh :tangle-mode (identity #o444)
#!/usr/bin/env bash

# -----------------------------------------------------------------------------
# mosdepth-wrapper.sh
#
# This script wraps the `mosdepth` tool to compute read depth over a BAM file,
# optimized for EM-seq cfDNA data. It configures the run to:
#   - use median depth (`--use-median`)
#   - run in fast mode (no per-base depth)
#   - report thresholds and quantized bins
#   - generate output in 1000bp windows
#
# Output files are written using a prefix of "mosdepth_<OUT_PREFIX>" in <OUT_DIR>.
# Designed for use in explicit I/O workflows like Snakemake or manual batch calls.
# -----------------------------------------------------------------------------

print_usage() {
    cat <<EOF
USAGE: mosdepth-wrapper.sh <BAM> <OUT_DIR> <OUT_PREFIX> <QUANT_LEVELS> [THREADS]

DESCRIPTION:
  Run mosdepth on a BAM file with EM-seq-appropriate settings.
  QUANT_LEVELS is a comma-separated string of coverage cutoffs (e.g. 1,5,10,20).
  The OUT_PREFIX will be prepended with 'mosdepth_' before being passed to mosdepth.
  Output files (e.g. mosdepth_<OUT_PREFIX>.summary.txt) will be written to OUT_DIR.
  THREADS is optional (default: 8).
EOF
}

main() {
    parse_args "$@"
    run_mosdepth
}

parse_args() {
    if [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
        print_usage
        exit 0
    fi

    if [[ $# -lt 4 ]]; then
        echo "Error: Missing required arguments." >&2
        print_usage
        exit 1
    fi

    declare -g bam_file="$1"                         # Input BAM file
    declare -g out_dir="$2"                          # Output directory
    declare -g user_prefix="$3"                      # Base prefix from user
    declare -g quant_levels="$4"                     # Coverage thresholds (e.g. 1,5,10)
    declare -g threads="${5:-8}"                     # Optional threads param (default: 8)

    [[ -f "$bam_file" ]] || { echo "Error: BAM file not found: $bam_file" >&2; exit 1; }

    mkdir -p "$out_dir"

    declare -g out_prefix="mosdepth_${user_prefix}"  # Final output prefix
    declare -g out_path="${out_dir%/}/${out_prefix}" # Full path to output base
    declare -g quant_str="0:${quant_levels/,/:}"    # Convert to colon-delimited format
}

run_mosdepth() {
    echo "[INFO] PID $$ running mosdepth on $bam_file" >&2
    echo "[INFO] Output prefix: $out_path" >&2
    echo "[INFO] Quantize string: $quant_str" >&2
    echo "[INFO] Threads: $threads" >&2

    mosdepth \
        --threads "$threads" \
        --no-per-base \
        --fast-mode \
        --use-median \
        --quantize "$quant_str" \
        --by 1000 \
        --thresholds "$quant_levels" \
        "$out_path" "$bam_file"

    echo "[INFO] mosdepth complete for PID $$" >&2
}

main "$@"
#+end_src
#+begin_src bash :tangle ./scripts/emseq_mosdepth.sh :tangle-mode (identity #o777) :comments no
# (can be just a trailing newline)
#+end_src

***** M-bias
#+begin_src snakemake
rule emseq_mbias:
    message: "EM-seq MethylDackel mbias for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_EMSEQ
    threads: 10
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    output:
        txt = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.tsv"
    shell:
        r"""

        exec &>> "{log.cmd}"
        echo "[mbias] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"

        MethylDackel mbias \
          -@ {threads} \
          --noSVG \
          "{input.fasta}" "{input.bam}" > "{output.txt}"
        """

#+end_src
***** De-duplicate
:PROPERTIES:
:ID:       4ac48779-f505-4291-b7bf-cc950d3339e6
:END:
#+begin_src snakemake
rule emseq_dedup:
    message: "EM-seq dedup (dupsifter) for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_EMSEQ
    threads: 8
    resources:
        concurrency = 25
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}.{wc.align_method}.coorsort"
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    output:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        index = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_dedup.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_dedup.tsv"
    shell:
        r"""

        mkdir -p "$(dirname "{params.temp_prefix}")"

        # append all stdout+stderr to the command log
        exec >> "{log.cmd}" 2>&1    # use this if you want POSIX; otherwise: exec &>> "{log.cmd}"

        echo "[dedup] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"

        # Clean previous temp chunks (unquoted glob on purpose)
        rm -f {params.temp_prefix}.tmp.*

        # Proper pairs -> name-sort (BAM) -> dupsifter -> coord-sort -> index
        samtools view -bh -f 0x2 "{input.bam}" \
        | samtools sort -n -@ {threads} -O BAM -T "{params.temp_prefix}.tmp" -o - \
        | dupsifter \
        --add-mate-tags \
        --stats-output "{log.cmd}.dupsifter.tsv" \
        "{input.fasta}" - \
        | samtools sort -@ {threads} -O BAM -T "{params.temp_prefix}.tmp" -o "{output.bam}"

        samtools index -@ {threads} "{output.bam}"
        """
#+end_src

***** Filter
:PROPERTIES:
:ID:       6a1d8806-5649-42e9-977d-c681a3106784
:END:
#+begin_src snakemake :tangle no
rule emseq_filter_bam:
    message: "Filtering of EM-seq deduplicated bam for {wildcards.library_id}."
    conda: ENV_EMSEQ
    input:
        bam  = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        bai  = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
        mask_bed = emseq_mask_bed,
        fasta = lambda wc: f"{D_REF}/bwa_meth/{wc.emseq_ref_name}/{wc.emseq_ref_name}.fa",
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        bai = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam.bai",
    log:
        f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_filter_bam.log",
    benchmark:
        f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_filter_bam.tsv",
    shell:
        r"""
        # build autosome bed from FASTA index
        fai="{input.fasta}.fai"
        if [ ! -s "$fai" ]; then
        samtools faidx "{input.fasta}"
        fi
        awk 'BEGIN{{OFS="\t"}} $1 ~ /^chr([1-9]|1[0-9]|2[0-2])$/ {{print $1,0,$2}}' "$fai" > autosomes.bed

        # filter BAM
        samtools view -b -f 2 -q 30 -F 2816 "{input.bam}" \
        | bedtools intersect -abam stdin -b "{input.mask_bed}" -v \
        | bedtools intersect -abam stdin -b autosomes.bed \
        > "{output.bam}"

        samtools index "{output.bam}" "{output.bai}"
        """

#+end_src
#+begin_src snakemake
rule emseq_filter_bam:
    message: "Filtering deduped BAM for {wildcards.library_id}"
    conda: ENV_EMSEQ
    threads: 16
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        bai   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
        keep_bed    = KEEP_BED,     # from preamble, bedtools-sorted with this FAI
        exclude_bed = EXCL_BED,     # from preamble, bedtools-sorted with this FAI
        fai   = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",  # produced by your index rule
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        bai = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam.bai",
    shell: r"""
        samtools view -@ {threads} -u -f 2 -q 30 -F 2816 "{input.bam}" \
          | bedtools intersect -sorted -g "{input.fai}" -a stdin -b "{input.exclude_bed}" -v -ubam \
          | bedtools intersect -sorted -g "{input.fai}" -a stdin -b "{input.keep_bed}"    -ubam \
          > "{output.bam}"
        samtools index -@ {threads} "{output.bam}" "{output.bai}"
    """

#+end_src
***** Samstats
#+begin_src snakemake
rule emseq_samtools_stats:
    message: "Samtools stats + flagstat for {wildcards.library_id}.{wildcards.emseq_ref_name}"
    conda: ENV_EMSEQ
    input:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
    log:
        f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.stats.log",
    output:
        stats   = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.stats.txt",
        flagstat = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.flagstat.txt",
    params:
        threads = 8,
    threads: 8
    resources:
        concurrency=40
    shell:
        r"""
        samtools stats -@ {threads} {input.bam} > {output.stats} 2>> {log}
        samtools flagstat -@ {threads} {input.bam} > {output.flagstat} 2>> {log}
        """

#+end_src

**** Call methylation
:PROPERTIES:
:ID:       e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c
:END:
#+begin_src snakemake
# -------- Call methylation (MethylDackel) --------
rule emseq_methyldackel:
    message: "EM-seq MethylDackel for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_EMSEQ
    threads: 20
    resources:
        concurrency = 25
    input:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    output:
        bed = f"{D_EMSEQ}/meth/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    params:
        out_prefix = lambda wc, input, output: output.bed.rsplit("_CpG.methylKit", 1)[0]
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel_dedup.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel.tsv"
    shell:
        r"""
        exec &>> "{log.cmd}"
        echo "[methyldackel] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"

        MethylDackel extract \
          -@ {threads} \
          --methylKit \
          "{input.fasta}" \
          "{input.bam}" \
          -o "{params.out_prefix}"
        """
#+end_src
#+begin_src snakemake
# -------- Build single methylKit (R) --------
rule make_single_methylkit_amp_obj:
    message: "Build tabix-backed methylKit object for {wildcards.library_id} {wildcards.emseq_ref_name} {wildcards.align_method}"
    conda: ENV_METHYLKIT
    threads: 1
    input:
        f"{D_EMSEQ}/meth/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    output:
        bgz = f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
        tbi = f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz.tbi",
    params:
        Rscript   = f"{R_EMSEQ}/scripts/make_single_amp_methylkit_obj.R",
        mincov    = emseq_mincov,
        build     = lambda wc: {wc.emseq_ref_name},
        treatment = 1,
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_single_methylkit_amp.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_single_methylkit_amp.tsv"
    shell:
        r"""
        exec &>> "{log.cmd}"
        echo "[methylKit-amp] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method}"

        Rscript "{params.Rscript}" \
          --amp_file "{input}" \
          --library_id "{wildcards.library_id}.{wildcards.emseq_ref_name}.{wildcards.align_method}.methyldackel" \
          --mincov {params.mincov} \
          --out_dir "$(dirname "{output.bgz}")" \
          --treatment {params.treatment} \
          --build {params.build}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_amp_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--amp_file", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--mincov", required = TRUE)
parser$add_argument("--build", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

obj <- methRead(
  location = args$amp_file,
  sample.id = args$library_id,
  assembly = args$build,
  treatment = args$treatment,
  pipeline = "amp",
  context = "CpG",
  resolution = "base",
  header = TRUE,
  mincov = args$mincov,
  dbtype = "tabix",
  dbdir = args$out_dir
)

#+end_src
**** MultiQC
#+begin_src snakemake
rule emseq_multiqc:
    message: f"MultiQC report for EM-seq (n={len(emseq_library_ids)} libraries)"
    conda: ENV_EMSEQ
    input:
        fastqc = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
            library_id=emseq_library_ids,
            processing=["raw","trimmed"],
            read=["R1","R2"],
            allow_missing=True,
        ),
        fastp_html = expand(
            f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.html",
            library_id=emseq_library_ids,
            allow_missing=True,
        ),
        fastp_json = expand(
            f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.json",
            library_id=emseq_library_ids,
            allow_missing=True,
        ),
        mbias = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            allow_missing=True,
        ),
        mosdepth_summary = expand(
            f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            allow_missing=True,
        ),
        mosdepth_dists = expand(
            f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.{{dist}}.dist.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            dist=["global","region"],
            allow_missing=True,
        ),
        samstats = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.{{stat}}.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            stat = ["stats","flagstat"]),
    log:
        f"{D_LOGS}/emseq_multiqc.log"
    output:
        html = f"{D_EMSEQ}/qc/multiqc.html",
        data = directory(f"{D_EMSEQ}/qc/multiqc_data"),  # <-- match MultiQC
    params:
        extra = "--force",
    threads: 4
    resources:
        concurrency=20
    shell:
        r"""
        mkdir -p $(dirname {output.html})

        multiqc \
            {input} \
            {params.extra} \
            --outdir $(dirname {output.html}) \
            --filename $(basename {output.html}) \
            &> {log}
        """

#+end_src
*** Methylkit
See for stranding https://claude.ai/chat/c39b78cc-5b2f-49ed-9f02-ed349824a07a
**** Per base
***** United per sample
#+begin_src snakemake
rule make_methylkit_unite_db:
    conda: ENV_METHYLKIT
    threads: 32
    input:
        mkit_lib_db=lambda wc: expand(
            f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
            library_id=meth_map[wc.experiment]["libs"],
            emseq_ref_name=meth_map[wc.experiment]["emseq_ref_name"],
            align_method=meth_map[wc.experiment]["align_method"],
        ),
    output:
        mbase=f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    params:
        library_id=lambda wc: " ".join(meth_map[wc.experiment]["libs"]),
        treatment_list=lambda wc: " ".join(map(str, meth_map[wc.experiment]["tx"])),
        script=f"{R_EMSEQ}/scripts/make_methylkit_unite_db.R",
        mincov=lambda wc: meth_map[wc.experiment]["mincov"],
        min_per_group=lambda wc: meth_map[wc.experiment]["mingroup"],
        chunk_size=lambda wc: meth_map[wc.experiment]["chunksize"],
    log:
        f"{D_LOGS}/{{experiment}}_make_methylkit_unite_db.log",
    shell:
        r"""
        # destructive pre-clean (script also unlinks)
        rm -f {output.mbase}*

        Rscript {params.script} \
          --lib_db_list "{input.mkit_lib_db}" \
          --lib_id_list "{params.library_id}" \
          --treatment_list "{params.treatment_list}" \
          --cores {threads} \
          --out_dir "$(dirname "{output.mbase}")" \
          --suffix {wildcards.experiment} \
          --assembly "hg38" \
          --mincov {params.mincov} \
          --min_per_group {params.min_per_group} \
          --chunk_size {params.chunk_size} \
          > {log} 2>&1
        """

#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_unite_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
split_ws <- function(x) trimws(unlist(strsplit(x, "\\s+")))
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num_chunk <- function(x, nm="chunk_size") {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (accepts forms like 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--lib_db_list", required=TRUE, help="Space-separated tabix files")
parser$add_argument("--lib_id_list", required=TRUE, help="Space-separated sample IDs")
parser$add_argument("--treatment_list", required=TRUE, help="Space-separated 0/1 indicators")
parser$add_argument("--cores", default="4", help="Parallel workers (default: 4)")
parser$add_argument("--out_dir", required=TRUE, help="Output directory for methylKit DBs")
parser$add_argument("--suffix", required=TRUE, help="Suffix for DB files (e.g., 'test')")
parser$add_argument("--assembly", default="hg38", help="Genome assembly (default: hg38)")
parser$add_argument("--mincov", default="10", help="Minimum coverage per CpG (integer; default: 10)")
parser$add_argument("--min_per_group", default="1", help="Min samples per group per CpG (integer; default: 1)")
parser$add_argument("--chunk_size", default="1e9", help="Chunk size (accepts '1e9' style; default: 1e9)")

args <- parser$parse_args()

# --- parse & validate ---
lib_db_list    <- split_ws(args$lib_db_list)
lib_id_list    <- split_ws(args$lib_id_list)
treatment_list <- as.numeric(split_ws(args$treatment_list))

if (length(lib_db_list) != length(lib_id_list) ||
    length(lib_id_list) != length(treatment_list)) {
  stop(sprintf("Length mismatch: lib_db_list=%d, lib_id_list=%d, treatment_list=%d",
               length(lib_db_list), length(lib_id_list), length(treatment_list)))
}

cores        <- as_int(args$cores, "cores")
mincov       <- as_int(args$mincov, "mincov")
min_per_grp  <- as_int(args$min_per_group, "min_per_group")
chunk_size   <- as_num_chunk(args$chunk_size, "chunk_size")

# destructive overwrite of methylBase only
mbase_path <- file.path(args$out_dir, sprintf("methylBase_%s.txt.bgz", args$suffix))
suppressWarnings(file.remove(mbase_path, paste0(mbase_path, ".tbi")))

# --- Read (tabix + CpG only) ---
merged_obj <- methRead(
  location   = as.list(lib_db_list),
  sample.id  = as.list(lib_id_list),
  treatment  = treatment_list,
  context    = "CpG",
  assembly   = args$assembly,
  dbtype     = "tabix",
  mincov     = mincov
)

# --- Unite (destrand hardcoded TRUE, save.db always TRUE) ---
meth <- unite(
  merged_obj,
  destrand      = TRUE,
  chunk.size    = chunk_size,
  mc.cores      = cores,
  save.db       = TRUE,
  min.per.group = min_per_grp,
  suffix        = args$suffix,
  dbdir         = args$out_dir
)

message("Done. methylBase: ", mbase_path)

#+end_src

***** Run differential methylation calling
#+begin_src snakemake
rule make_methylkit_diff_db:
    conda: ENV_METHYLKIT
    threads: 32
    input:
        mbase = f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    output:
        mdiff = f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
    params:
        script     = f"{R_EMSEQ}/scripts/make_methylkit_diff_db.R",
        chunk_size = lambda wc: meth_map[wc.experiment]["chunksize"],
    log:
        f"{D_LOGS}/{{experiment}}_make_methylkit_diff_db.log",
    shell:
        r"""
        # destructive pre-clean
        rm -f {output.mdiff} {output.mdiff}.tbi

        Rscript {params.script} \
          --mbase "{input.mbase}" \
          --cores {threads} \
          --out_dir "$(dirname "{output.mdiff}")" \
          --suffix {wildcards.experiment} \
          --chunk_size {params.chunk_size} \
          > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_diff_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num_chunk <- function(x, nm="chunk_size") {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (accepts forms like 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--mbase", required=TRUE,
                    help="Path to methylBase_*.txt.bgz from unite step")
parser$add_argument("--cores", default="4",
                    help="Parallel workers (default: 4)")
parser$add_argument("--out_dir", required=TRUE,
                    help="Output directory for methylKit DBs")
parser$add_argument("--suffix", required=TRUE,
                    help="Suffix for DB files (e.g., 'test')")
parser$add_argument("--chunk_size", default="1e9",
                    help="Chunk size (accepts '1e9' style; default: 1e9)")

args <- parser$parse_args()

cores      <- as_int(args$cores, "cores")
chunk_size <- as_num_chunk(args$chunk_size, "chunk_size")

# --- load methylBase (tabix backend) ---

meth <- methylKit:::readMethylDB(args$mbase)

# --- Differential methylation ---
diff <- calculateDiffMeth(
  meth,
  mc.cores   = cores,
  chunk.size = chunk_size,
  save.db    = TRUE,
  dbdir      = args$out_dir
)

diff_path <- file.path(args$out_dir, sprintf("methylDiff_%s.txt.bgz", args$suffix))
message("Done. methylDiff: ", diff_path)
#+end_src
**** Tiled

#+begin_src snakemake
rule make_methylkit_diff_db_tiled:
    conda: ENV_METHYLKIT
    input:
        mkit_lib_db = lambda wildcards: expand(f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
                                               library_id = meth_map[wildcards.experiment]['libs'],
                                               emseq_ref_name = meth_map[wildcards.experiment]['emseq_ref_name'],
                                               align_method = meth_map[wildcards.experiment]['align_method']),
    log:
        f"{D_LOGS}/{{experiment}}_make_methylkit_diff_tiled_db.log",
    output:
        unite = f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
        diff = f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}_tiled.txt.bgz",
    params:
        library_id = lambda wildcards: " ".join(meth_map[wildcards.experiment]['libs']),
        treatment_list = lambda wc: " ".join(map(str, meth_map[wc.experiment]['tx'])),
        script = f"{R_EMSEQ}/scripts/make_methylkit_diff_tiled_db.R",
        mincov=lambda wc: meth_map[wc.experiment]["mincov"],
        chunk_size=lambda wc: meth_map[wc.experiment]["chunksize"],
        min_per_group=lambda wc: meth_map[wc.experiment]["mingroup"],
        win_size = lambda wc: meth_map[wc.experiment]["win_size"],
    shell:
        """
        # remove old outputs if they exist
        rm -f {output.unite}* {output.diff}*

        Rscript {params.script} \
        --lib_db_list "{input.mkit_lib_db}" \
        --lib_id_list "{params.library_id}" \
        --treatment_list "{params.treatment_list}" \
        --cores {threads} \
        --out_dir "$(dirname "{output.unite}")" \
        --suffix {wildcards.experiment} \
        --assembly "hg38" \
        --mincov {params.mincov} \
        --win_size {params.win_size} \
        --min_per_group {params.min_per_group} \
        --chunk_size {params.chunk_size} \
        > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_diff_tiled_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
split_ws <- function(x) trimws(unlist(strsplit(x, "\\s+")))
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num <- function(x, nm) {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (e.g., 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--lib_db_list", required = TRUE)
parser$add_argument("--lib_id_list", required = TRUE)
parser$add_argument("--treatment_list", required = TRUE)
parser$add_argument("--cores", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)
parser$add_argument("--suffix", required = TRUE)
parser$add_argument("--assembly", required = TRUE)
parser$add_argument("--mincov", required = TRUE)
parser$add_argument("--win_size", required = TRUE)
parser$add_argument("--chunk_size", required = TRUE)
parser$add_argument("--min_per_group", default="1", help="Min samples per group per CpG (integer; default: 1)")
args <- parser$parse_args()

dir.create(args$out_dir, recursive = TRUE, showWarnings = FALSE)

# --- parse ---
lib_db_list    <- split_ws(args$lib_db_list)
lib_id_list    <- split_ws(args$lib_id_list)
treatment_list <- as.numeric(split_ws(args$treatment_list))

if (length(lib_db_list) != length(lib_id_list) ||
    length(lib_id_list) != length(treatment_list)) {
  stop(sprintf("Length mismatch: lib_db_list=%d, lib_id_list=%d, treatment_list=%d",
               length(lib_db_list), length(lib_id_list), length(treatment_list)))
}

cores      <- as_int(args$cores, "cores")
mincov     <- as_int(args$mincov, "mincov")
win_size   <- as_int(args$win_size, "win_size")      # FIX: was args$winsize → numeric(0)
min_per_grp  <- as_int(args$min_per_group, "min_per_group")
chunk_size <- as_num(args$chunk_size, "chunk_size")

# --- destructive cleanup: only *_tiled* (both base & diff) ---
tiled_patterns <- c(
  file.path(args$out_dir, sprintf("methylBase_%s_tiled*.txt.bgz*", args$suffix)),
  file.path(args$out_dir, sprintf("methylDiff_%s_tiled*.txt.bgz*", args$suffix))
)
tiled_paths <- unlist(lapply(tiled_patterns, Sys.glob))
if (length(tiled_paths) > 0) suppressWarnings(file.remove(tiled_paths))

# --- read methylation DBs ---
merged_obj <- methRead(
  location  = as.list(lib_db_list),
  sample.id = as.list(lib_id_list),
  treatment = treatment_list,
  context   = "CpG",
  assembly  = args$assembly,
  dbtype    = "tabix",
  mincov    = mincov
)

# --- tile per sample ---
tiled_raw <- tileMethylCounts(
  merged_obj,
  win.size   = win_size,
  step.size  = win_size,
  cov.bases  = 1,
  save.db    = TRUE,
  suffix     = args$suffix,
  dbdir      = args$out_dir,
  mc.cores   = cores
)

# --- unite tiles into methylBaseDB ---
tiled_obj <- unite(
  tiled_raw,
  destrand = FALSE,
  save.db  = TRUE,
  suffix   = paste0(args$suffix, "_tiled"),
  dbdir    = args$out_dir,
  min.per.group = min_per_grp,
  mc.cores = cores
)

# --- differential methylation on tiles ---
diff <- calculateDiffMeth(
  tiled_obj,
  mc.cores   = cores,
  chunk.size = chunk_size,   # FIX: missing comma previously
  save.db    = TRUE,
  dbdir      = args$out_dir,
)
#+end_src

https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html



*** Ideas
:PROPERTIES:
:ID:       f6cfad3a-21c6-4c33-94e2-0a6cb53a5fe3
:header-args:snakemake: :tangle no
:END:
- note that multicq inputs cannot promp new runs
- push methmap to config
#+begin_src snakemake
rule all_experiment_tiled_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}_tiled.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_tiled_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src

**** biscuit Pileup
#+begin_src snakemake
rule emseq_biscuit_pileup:
    conda:
        "../config/emseq-conda-env.yaml",
    input:
        bam = f"{data_dir}/emseq/bams/{{library_id}}.{{emseq_ref_name}}.biscuit.coorsort.deduped.bam",
        fasta = f"{data_dir}/ref/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}.biscuit_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf",
    shell:
        """
        biscuit pileup \
        -@ 20 \
        -o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
#+begin_src snakemake
rule emseq_biscuit_post_pileup:
    conda:
        "../config/emseq-conda-env.yaml",
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf.gz",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}_emseq_biscuit_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input.vcf} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark} &> {log}
        """
#+end_src

#+begin_src snakemake
rule make_single_biscuit_methylkit_obj:
    conda: ENV_METHYLKIT
    input:
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_bismark_cov.bed",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}_make_single_biscuit_methylkit_obj.log",
    output:
        txt = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt",
        bgz = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt.bgz",
        tbi = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt.bgz.tbi",
    params:
        Rscript = f"{emseq_script_dir}/make_single_biscuit_methylkit_obj.R",
        out_dir = f"{data_dir}/analysis/emseq/post-biscuit",
    shell:
        """
        Rscript {params.Rscript} \
          --bismark_cov_bed {input.bismark} \
          --library_id {wildcards.library_id} \
          --out_dir {params.out_dir} \
          &> {log}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_biscuit_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--bismark_cov_bed", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

myobj= methRead(args$bismark_cov_bed,
                sample.id = args$library_id,
                treatment = 1,
                context="CpG",
                pipeline="bismarkCoverage",
                mincov = 2,
                assembly= "hg38",
                dbtype = "tabix",
                dbdir = args$out_dir)

#+end_src


***** OLD Methylation sequence processing
:PROPERTIES:
:ID:       c3bdbbcc-5a4c-475a-8ab1-33884ab14ef5
:header-args:snakemake: :tangle no
:END:
****** methylKit per experiment
******* Grouped objects and differential methylation
******** Per-position
#+begin_src snakemake
rule make_methylkit_diff_db:
    input:
        mkit_lib_db = lambda wildcards: expand(
            f"{emseq_dir}/dmr/tabix/{{library_id}}.txt.bgz",
            library_id = meth_map[wildcards.experiment]['libs']
        ),
    log:
        f"{log_dir}/{{experiment}}_make_methylkit_diff_db.log",
    output:
        unite = f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
        diff = f"{emseq_dir}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
    params:
        library_id = lambda wildcards: " ".join(meth_map[wildcards.experiment]['libs']),
        treatment_list = lambda wildcards: meth_map[wildcards.experiment]['tx'],
        out_dir = f"{emseq_dir}/dmr/diff",
        script = f"{emseq_script_dir}/make_methylkit_diff_db.R",
    shell:
        """
        Rscript {params.script} \
        --lib_db_list "{input.mkit_lib_db}" \
        --lib_id_list "{params.library_id}" \
        --treatment_list "{params.treatment_list}" \
        --cores 32 \
        --out_dir {params.out_dir} \
        --suffix {wildcards.experiment} > {log} 2>&1
        """
#+end_src



#+begin_src snakemake
rule all_experiment_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_pos_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src


#+begin_src R :tangle ./scripts/all_experiment_methylation.R
library(argparse)
library(methylKit)
library(tidyverse)

# --- Argument Parsing ---
parser <- ArgumentParser()
parser$add_argument("--db_file", required = TRUE, help = "Path to tabix-indexed methylBase file")
parser$add_argument("--out_file", required = TRUE, help = "Output TSV path for percent methylation matrix")
parser$add_argument("--chunk_size", type = "double", default = 1e9, help = "Chunk size for methylKit operations")
args <- parser$parse_args()

# --- Check Header and Load Object ---
methylKit:::checkTabixHeader(args$db_file)
meth <- methylKit:::readMethylDB(args$db_file)

# --- Extract Percent Methylation Matrix ---
meth_matrix <- percMethylation(meth, rowids = TRUE, chunk.size = args$chunk_size)

# --- Write Output ---
write_tsv(
  as.data.frame(meth_matrix) %>% rownames_to_column(var = "coord"),
  args$out_file
)

#+end_src

******** Tiled

#+begin_src snakemake
rule make_methylkit_diff_db_tiled:
    input:
        mkit_lib_db = lambda wildcards: expand(
            f"{emseq_dir}/dmr/tabix/{{library_id}}.txt.bgz",
            library_id = meth_map[wildcards.experiment]['libs']
        ),
    log:
        f"{log_dir}/{{experiment}}_make_methylkit_diff_tiled_db.log",
    output:
        unite = f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
        diff = f"{emseq_dir}/dmr/diff/methylDiff_{{experiment}}_tiled.txt.bgz",
    params:
        library_id = lambda wildcards: " ".join(meth_map[wildcards.experiment]['libs']),
        treatment_list = lambda wildcards: meth_map[wildcards.experiment]['tx'],
        out_dir = f"{emseq_dir}/dmr/diff",
        script = f"{emseq_script_dir}/make_methylkit_diff_tiled_db.R",
        win_size = 1000000,
        step_size= 1000000,
    shell:
        """
        Rscript {params.script} \
        --lib_db_list "{input.mkit_lib_db}" \
        --lib_id_list "{params.library_id}" \
        --treatment_list "{params.treatment_list}" \
        --cores 32 \
        --out_dir {params.out_dir} \
        --win_size {params.win_size} \
        --step_size {params.step_size} \
        --suffix {wildcards.experiment} \
        > {log} 2>&1
        """
#+end_src



#+begin_src snakemake
rule all_experiment_tiled_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}_tiled.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_tiled_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src

******** Exploratory data analysis

#+begin_src R
# Compute global methylation (mean per sample)

library(tidyverse)
library(methylKit)

db_file = "/mnt/data/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz"

methylKit:::checkTabixHeader(db_file)

meth = methylKit:::readMethylDB(db_file)

# Extract percent methylation matrix
meth_matrix <- percMethylation(
  meth,
  rowids = TRUE,
  chunk.size = 1e+09)


ls()

global_df <- data.frame(
  library_id = colnames(meth_matrix),
  global_methylation = colMeans(meth_matrix, na.rm = TRUE)
)

global_df = meth_matrix %>% as.data.frame() %>% as_tibble()

global_df <- meth_matrix %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE))

global_df


binMeth <- tileMethylCounts(
  meth,
  win.size = 1000,      # bin/window size in bp
  step.size = 1000,     # step size (same as win.size for non-overlapping bins)
  cov.bases = 5,
  mc.cores = 4          # optional parallelization
)

binMeth <- tileMethylCounts(
  meth,
  win.size = 1000,
  step.size = 1000,  # Distance shift (>win is gap, <win is overlap)
  cov.bases = 5,                    # minimum number of CpGs per bin
  sample.ids = meth@sample.ids,     # explicit sample IDs
  treatment = meth@treatment,       # explicit treatment vector
  mc.cores = 12
)

#########1#########2#########3#########4#########5#########6#########7#########8


full = full %>% mutate(library_id = sample)

full = full %>%
  mutate(group = case_when(
    str_starts(library_id, "NH") ~ "healthy",
    str_starts(library_id, "PRO") ~ "cancer",
    TRUE ~ NA_character_
  ))

global_df = global_df %>% left_join(full, by = "library_id")


# Violin plot (one point per library, jittered for clarity)
ggplot(global_df, aes(x = group, y = global_methylation, fill = group)) +
  geom_violin(width = 1.0, trim = TRUE, alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(title = "Global Methylation per Library",
       y = "Mean % Methylation",
       x = "Group")


str(global_df)

prog = global_df %>% filter(group == "cancer")

prog$interval_progression

ggplot(prog, aes(x = interval_progression, y = global_methylation)) + geom_point()


#########1#########2#########3#########4#########5#########6#########7#########8

library(methylKit)
library(tidyverse)
library(patchwork)

# Load methylation data
db_file <- "/mnt/data/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz"
meth <- methylKit:::readMethylDB(db_file)

# Calculate global methylation per library
global_df <- percMethylation(meth) %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE), .groups = "drop")

# Annotate with metadata
global_df <- global_df %>%
  left_join(full %>% mutate(library_id = sample), by = "library_id") %>%
  mutate(group = case_when(
    str_starts(library_id, "NH") ~ "Healthy",
    str_starts(library_id, "PRO") ~ "Cancer",
    TRUE ~ NA_character_
  )) %>%
  mutate(group = factor(group, levels = c("Healthy", "Cancer")))

# Plot 1: Violin plot
p1 <- ggplot(global_df, aes(x = group, y = global_methylation, fill = group)) +
  geom_violin(width = 0.9, alpha = 0.4, color = NA) +
  geom_jitter(width = 0.1, size = 2, color = "black") +
  labs(x = NULL, y = "Global % Methylation") +
  scale_fill_manual(values = c("Healthy" = "#1B9E77", "Cancer" = "#D95F02")) +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none")

# Plot 2: Scatter vs interval_progression
p2 <- global_df %>%
  filter(group == "Cancer", !is.na(interval_progression)) %>%
  ggplot(aes(x = interval_progression, y = global_methylation)) +
  geom_point(size = 3, color = "#D95F02", stroke = 1, shape = 21, fill = "#D95F02") +
  labs(x = "Progression-Free Survival (days)", y = "Global % Methylation") +
  theme_minimal(base_size = 16)

p2 <- global_df %>%
  filter(group == "Cancer", !is.na(interval_progression)) %>%
  ggplot(aes(x = interval_progression, y = global_methylation)) +
  geom_point(size = 3, color = "#D95F02", stroke = 1, shape = 21, fill = "#D95F02") +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1, linetype="dotted") +
  labs(x = "Progression-Free Survival (days)", y = "Global % Methylation") +
  theme_minimal(base_size = 16)

# Combine side by side
p1 + p2 + plot_layout(widths = c(1, 1))

ggsave("/tmp/global_meth.png", p1 + p2, width = 12, height = 5, dpi = 300)
#+end_src

- global methylation
- tiled methylation beta heatmap
-
****** Dev
:properties:
:header-args:snakemake: :tangle no
:end:

- dmr heatmap
  #+begin_src R
library(methylKit)
ls()

methylKit:::checkTabixHeader("/mnt/data/jeszyman/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz")

test= methylKit:::readMethylDB("/mnt/data/jeszyman/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz")


#########1#########2#########3#########4#########5#########6#########7#########8

rm(baseDB.obj)

methylKit:::checkTabixHeader(mydbpath)
readMethylDB(mydbpath)


methylBase_PRO_5_vs_NH_54.txt.bgz", dbtype = "tabix")

meth = test
meth_mat <- percMethylation(meth)
library(matrixStats)

variances <- rowVars(meth_mat, na.rm = TRUE)
top_idx <- order(variances, decreasing = TRUE)[1:500]  # or 1000
top_meth <- meth_mat[top_idx, ]

top_meth_z <- t(scale(t(top_meth)))  # mean-center and scale each CpG row

library(pheatmap)

pheatmap(top_meth_z,
         cluster_rows = TRUE,
         cluster_cols = TRUE,
         show_rownames = FALSE,
         main = "Top Variable CpG Sites")

#+end_src
- dmr pca
  #+begin_src R
# From full matrix
meth_mat <- percMethylation(meth)
meth_mat[is.na(meth_mat)] <- 0

# Select top variable rows
library(matrixStats)
vars <- rowVars(meth_mat)
top_idx <- order(vars, decreasing = TRUE)[1:1000]  # adjust as needed
meth_mat_top <- meth_mat[top_idx, ]

# Z-score normalize
meth_z <- t(scale(t(meth_mat_top)))

# PCA
pca <- prcomp(t(meth_z), scale. = FALSE)

#+end_src
- dmr global
  #+begin_src R
meth_mat <- percMethylation(meth)
sample_means <- colMeans(meth_mat, na.rm = TRUE)
df <- data.frame(
  sample = colnames(meth_mat),
  treatment = factor(c(1, 1, 0, 0)),  # adjust as needed
  global_methylation = sample_means
)
library(ggplot2)

ggplot(df, aes(x = treatment, y = global_methylation)) +
  geom_violin(trim = FALSE, fill = "gray80", color = "black") +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(x = "Treatment", y = "Global % Methylation", title = "Global Methylation per Sample")

#+end_src

******* Depth
#+begin_src bash

ls /tmp/breast/analysis/emseq/bams-merged/PRO_13_deduped.bam

mosdepth \
    --threads 8 \
    --no-per-base \
    --fast-mode \
    --use-median \
    --quantize 0:5:10:20 \
    /tmp/breast/qc/PRO_13_emseq_mosdepth \
    /tmp/breast/analysis/emseq/bams-merged/PRO_13_deduped.bam

#+end_src

******* EM-seq methylation
- Consider reference w/ decoys https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369
******** Biscuit index
#+begin_src bash
source ~/repos/breast/config/bash-env.sh
Y


if [ -e "$data_dir/inputs/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz" ]; then
    echo "File exists, skipping download."
else
    aria2c -c -x 10 -s 10 -m 5 -d $data_dir/inputs/ \
	   -o Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \
	   https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz

fi


if [ -e "$data_dir/inputs/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz" ]; then
    echo "File exists, skipping download."
else
    aria2c -c -x 10 -s 10 -m 5 -d $data_dir/inputs/ \
	   -o GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz \
	   https:/ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
fi

#+end_src


#+begin_src bash
source ~/repos/breast/config/bash-env.sh

# Ensembl primary assembly
ensembl_dir="$data_dir/ref/biscuit-ensembl-hg38"
ensembl_input="$data_dir/inputs/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
ensembl_fa="$ensembl_dir/Homo_sapiens.GRCh38.dna.primary_assembly.fa"

mkdir -p "$ensembl_dir"
gunzip -c "$ensembl_input" > "$ensembl_fa"
samtools faidx "$ensembl_fa"
nohup biscuit index "$ensembl_fa" & disown

# NCBI decoy set
ncbi_dir="$data_dir/ref/biscuit-ncbi-decoy-hg38"
ncbi_input="$data_dir/inputs/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz"
ncbi_fa="$ncbi_dir/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna"

mkdir -p "$ncbi_dir"
gunzip -c "$ncbi_input" > "$ncbi_fa"
samtools faidx "$ncbi_fa"
#

nohup biscuit index "$ncbi_fa" & disown
#+end_src
******** Make methylation position calls

#+begin_src bash
biscuit pileup \
	-@ 8 \
	-o /tmp/test/post/pileup.vcf \
	"$data_dir/ref/biscuit/Homo_sapiens.GRCh38.dna.primary_assembly.fa" \
	/tmp/test/post/pos-sorted.bam

bgzip -@ 8 /tmp/test/post/pileup.vcf

tabix -p vcf /tmp/test/post/pileup.vcf.gz

biscuit vcf2bed \
	-t cg \
	/tmp/test/post/pileup.vcf.gz \
	> /tmp/test/post/pileup.bed


head /tmp/test/post/pileup.vcf_meth_average.tsv
#+end_src
- snakemake, inline
  #+begin_src snakemake
rule emseq_pileup:
    input:
        bam = f"{emseq_bam_dir}/{{library_id}}_deduped.bam",
        fasta = f"{ref_dir}/biscuit/{emseq_ref_fasta}",
    log:
        f"{log_dir}/{{library_id}}_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf",
    shell:
        """
        biscuit pileup \
	-@ 8 \
	-o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
- snakemake, inline
  #+begin_src snakemake
rule emseq_post_pileup:
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz",
    log:
        f"{log_dir}/{{library_id}}_emseq_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark}
        """
#+end_src

******** DMR
https:/www.bioconductor.org/packages/release/bioc/vignettes/dmrseq/inst/doc/dmrseq.html
https:/huishenlab.github.io/biscuit/docs/methylextraction.html
https:/bioconductor.org/packages/release/bioc/html/DSS.html
https:/ziemann-lab.net/public/guppy_methylseq/PCAanalysis.html


#+begin_src python
from pathlib import Path
import pandas as pd

pileup_dir = Path("/tmp/breast/analysis/emseq/pileup")
out_suffix = "_methylkit.tsv"

for bedfile in pileup_dir.glob("*_pileup.bed"):
    df = pd.read_csv(bedfile, sep="\t", header=None,
                     names=["chr", "start", "end", "meth_ratio", "coverage"])
    df["pos"] = df["start"] + 1  # methylKit expects 1-based coordinate
    df["strand"] = "+"
    df["num_mC"] = (df["meth_ratio"] * df["coverage"]).round().astype(int)
    df["num_C"] = df["coverage"] - df["num_mC"]

    out_df = df[["chr", "pos", "strand", "coverage", "num_mC", "num_C"]]

    outfile = bedfile.with_name(bedfile.stem.replace("_pileup", "") + out_suffix)
    out_df.to_csv(outfile, sep="\t", header=False, index=False)

#+end_src

#+begin_src snakemake
rule methylkit_dmr_obj:
    input:
        bismark_cov lambda wildcards: expand(f"{emseq_dir}/pileup/{{library_id}}_bismark_cov.bed",
                                             library = emseq_map[wildcards.experiment]['libs']),
    log:
    output:
        f"{}
#+end_src

#+begin_src R
# biscuit vcf2bed -k 2 -c PRO_13_pileup.vcf.gz > my_beta_m_u.bed

library(methylKit)

myobj = methRead("/tmp/breast/analysis/emseq/pileup/my_beta_m_u.bed",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 sample.id = "TEST",
                 assembly="hg38")


myobj

getMethylationStats(myobj,plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj,plot=TRUE,both.strands=FALSE)

filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)

filtered.myobj

obj=read("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",sample.id="test",assembly="hg38",header=FALSE, context="CpG", resolution="base",
          pipeline=list(fraction=TRUE,chr.col=1,start.col=2,end.col=2,
                        coverage.col=4,strand.col=3,freqC.col=5 )
        )

obj

methRead()

library(methylKit)

help(methRead)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = TRUE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    freqC.col = 5
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv", header = FALSE)
str(df)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = FALSE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


file.list <- list(
  "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  "/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit.tsv"
)

# read the files to a methylRawList object: myobj
myobj=methRead(file.list,
           sample.id=list("test1","ctrl1"),
           assembly="hg38",
           treatment=c(1,0),
           context="CpG",
           mincov = 2
           )


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "generic",
  header = FALSE
)


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "bismarkCoverage",
  header = FALSE
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    context.col = NULL,
    context.filter = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    fraction = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    column.names = c("chr", "start", "strand", "coverage", "numCs", "numTs")
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

library(methylKit)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_like.tsv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
str(df)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                 sep = "\t", header = FALSE, colClasses = c("character", "integer", "integer", "integer", "integer", "character"))

obj <- methRead(df,
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  resolution = "base"
)


write.table(df, "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean2.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)

obj <- methRead(
  location = "NH22_bismark_clean2.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

head(df)


obj=methRead("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
         sample.id="test",
         assembly="hg38",
         header=FALSE,
         context="CpG",
         resolution="base",
         pipeline=list(fraction=FALSE,
                       chr.col=1,
                       start.col=2,
                       end.col=3,
                       coverage.col=4,
                       strand.col=6,
                       freqC.col=5 )
        )


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  context = "CpG",
  resolution = "base",
  treatment = 0,
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    meth.col = 4,
    unmeth.col = 5,
    strand.col = 6
  )
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  pipeline = "bismark"
)

# Read in your original data
data <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                  header = FALSE,
                  col.names = c("chr", "start", "end", "meth", "unmeth", "strand"))

# Calculate total coverage and methylation percentage
data$coverage <- data$meth + data$unmeth
data$methPercent <- round(data$meth / data$coverage * 100, 2)

# Write to a new file in methylKit-compatible format
write.table(data[, c("chr", "start", "end", "strand", "coverage", "methPercent")],
            file = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  resolution = "base",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    strand.col = 4,
    coverage.col = 5,
    freqC.col = 6
  )
)


generic.file=system.file("extdata", "generic1.CpG.txt",package = "methylKit")
read.table(generic.file,header=TRUE)

test= read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=T)

head(test)

# And this is how you can read that generic file as a methylKit object
myobj=methRead(test,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj

nrow(read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=TRUE))  # should match wc -l minus 1

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

# And this is how you can read that generic file as a methylKit object
myobj=methRead( generic.file,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj
# This creates tabix files that save methylation

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_patched.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")
myobj



myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1",
                 mincov = 1,
                 assembly="hg38")




myobj = methRead("/tmp/breast/analysis/emseq/pileup/test.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

#+end_src

******** Reference
- Alignment reference choice
  - discussion [[https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369][gtp]]
  - see [[id:326ecd60-8cd4-4815-a389-967b2c3fef0a][Nucleic acid sequence alignment]]
- [cite:@chauhan2024]
- [[id:5e9e8bfa-ac9e-4103-9cc5-7123337b4e24][biscuit]]

******** Ideas
- for qc https:/www.google.com/search?sca_esv=45e5c8ab8ae118cf&sxsrf=AHTn8zrPW-wtm7PgHxohfizFJXC9p5Qtlw:1742500238525&q=m-bias+plots&udm=2&fbs=ABzOT_CWdhQLP1FcmU5B0fn3xuWpA-dk4wpBWOGsoR7DG5zJBtmuEdhfywyzhendkLDnhcrUz6wxBwARHD96EKWkSbZoQZGasaHPJ9csj0AVVVUDNHqfR7gd1arUfaOpw1v5Icccwayh65rdsqdiyPvxAA9gXK95YqgoHnUzfZ5jo9jiMl2Q8DaMUR4I1U0kl1-ho1NSBjy_chexdcGuJmvrFewYJaqjljog&sa=X&ved=2ahUKEwj90vOdt5mMAxXLGlkFHdQWG7IQtKgLegQIExAB&biw=1745&bih=908&dpr=1.1
- https:/sequencing.qcfail.com/articles/mispriming-in-pbat-libraries-causes-methylation-bias-and-poor-mapping-efficiencies/
- consider https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html#6_Frequently_Asked_Questions

******* EM-seq cfDNA copy number alteration
EM-seq protects 5mC and 5hmC from damination with TET2 enzymatic oxidation. Unprotected cytosines are deaminated to uracils.

******* DMR
https:/www.bioconductor.org/packages/release/bioc/vignettes/dmrseq/inst/doc/dmrseq.html
https:/huishenlab.github.io/biscuit/docs/methylextraction.html
https:/bioconductor.org/packages/release/bioc/html/DSS.html
https:/ziemann-lab.net/public/guppy_methylseq/PCAanalysis.html


#+begin_src python
from pathlib import Path
import pandas as pd

pileup_dir = Path("/tmp/breast/analysis/emseq/pileup")
out_suffix = "_methylkit.tsv"

for bedfile in pileup_dir.glob("*_pileup.bed"):
    df = pd.read_csv(bedfile, sep="\t", header=None,
                     names=["chr", "start", "end", "meth_ratio", "coverage"])
    df["pos"] = df["start"] + 1  # methylKit expects 1-based coordinate
    df["strand"] = "+"
    df["num_mC"] = (df["meth_ratio"] * df["coverage"]).round().astype(int)
    df["num_C"] = df["coverage"] - df["num_mC"]

    out_df = df[["chr", "pos", "strand", "coverage", "num_mC", "num_C"]]

    outfile = bedfile.with_name(bedfile.stem.replace("_pileup", "") + out_suffix)
    out_df.to_csv(outfile, sep="\t", header=False, index=False)

#+end_src
        bismark = lambda wildcards: expand(f"{emseq_dir}/pileup/{{library_id}}_bismark_cov.bed",
                                           library = meth_map[wildcards.experiment]['libs']),


#+begin_src bash
Rscript ~/repos/emseq/scripts/make_single_methylkit_obj.R \
	--bismark_cov_bed "/tmp/breast/analysis/emseq/pileup/NH_11_bismark_cov.bed" \
	--library_id "NH_11" \
	--treatment 0 \
	--mincov 2 \
	--out_dir "/tmp/breast/analysis/emseq/dmr/tabix"

#+end_src


#+begin_src R
file.list = list()

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_bismark_cov.bed",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 sample.id = "TEST",
                 assembly="hg38")

file.list =list(
  "/tmp/breast/analysis/emseq/pileup/PRO_13_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/NH_11_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/PRO_10_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/NH_13_bismark_cov.bed")


myobj = methRead(file.list,
                 sample.id=list("test1","ctrl1","test2","ctrl2"),
                 treatment=c(1,0,1,0),
                 context="CpG",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 assembly="hg38")

myobj

myobj = methRead(file.list,
                 sample.id=list("test1","ctrl1","test2","ctrl2"),
                 treatment=c(1,0,1,0),
                 context="CpG",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 assembly="hg38",
                 dbtype = "tabix",
                 dbdir = "/tmp/breast/analysis/emseq/pileup")

print(myobj[[1]]@dbpath)

#########1#########2#########3#########4#########5#########6#########7#########8

library(methylKit)

myobj = methRead(
  location = list("/tmp/breast/analysis/emseq/dmr/tabix/NH_11.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/NH_13.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/PRO_10.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/PRO_13.txt.bgz"),
  sample.id = list("NH_11", "NH_13", "PRO_10", "PRO_13"),
  treatment = c(1, 1, 0, 0),
  context = "CpG",
  assembly = "hg38",
  dbtype = "tabix",
)

myobj[1]

getMethylationStats(myobj[[2]],plot=FALSE,both.strands=FALSE)


getMethylationStats(myobj[[2]],plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj[[2]],plot=TRUE,both.strands=FALSE)

#
filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)
# ERRORS if no reads match

meth=unite(myobj, destrand = F)

head(meth)

getCorrelation(meth, plot = T)

clusterSamples(meth, dist="correlation", method="ward", plot=TRUE)

hc = clusterSamples(meth, dist="correlation", method="ward", plot=FALSE)

PCASamples(meth)
myobj

myDiff=calculateDiffMeth(meth)

diffMethPerChr(myDiff,plot=T, qvalue.cutoff=.5, meth.cutoff=3)

myDiff=calculateDiffMeth(meth,mc.cores=2)

library(tibble)

pvals_tbl <- getData(myDiff) |>
  as_tibble()

pvals_tbl %>% sort(qvalue)

|>
  select(pvalue)

# read the files to a methylRawListDB object: myobjDB
# and save in databases in folder methylDB


myobjDB=methRead(file.list,
           sample.id=list("test1","ctrl1","test2","ctrl2"),
           assembly="hg38",
           treatment=c(1,0,1,0),
           context="CpG",
           dbtype = "tabix",
           dbdir = "/tmp/breast/analysis/emseq/pileup"
           )

print(myobjDB[[1]]@dbpath)

getMethylationStats(myobj,plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj,plot=TRUE,both.strands=FALSE)

filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)

filtered.myobj

obj=read("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",sample.id="test",assembly="hg38",header=FALSE, context="CpG", resolution="base",
          pipeline=list(fraction=TRUE,chr.col=1,start.col=2,end.col=2,
                        coverage.col=4,strand.col=3,freqC.col=5 )
        )

obj

methRead()

library(methylKit)

help(methRead)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = TRUE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    freqC.col = 5
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv", header = FALSE)
str(df)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = FALSE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


file.list <- list(
  "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  "/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit.tsv"
)

# read the files to a methylRawList object: myobj
myobj=methRead(file.list,
           sample.id=list("test1","ctrl1"),
           assembly="hg38",
           treatment=c(1,0),
           context="CpG",
           mincov = 2
           )


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "generic",
  header = FALSE
)


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "bismarkCoverage",
  header = FALSE
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    context.col = NULL,
    context.filter = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    fraction = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    column.names = c("chr", "start", "strand", "coverage", "numCs", "numTs")
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

library(methylKit)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_like.tsv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
str(df)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                 sep = "\t", header = FALSE, colClasses = c("character", "integer", "integer", "integer", "integer", "character"))

obj <- methRead(df,
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  resolution = "base"
)


write.table(df, "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean2.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)

obj <- methRead(
  location = "NH22_bismark_clean2.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

head(df)


obj=methRead("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
         sample.id="test",
         assembly="hg38",
         header=FALSE,
         context="CpG",
         resolution="base",
         pipeline=list(fraction=FALSE,
                       chr.col=1,
                       start.col=2,
                       end.col=3,
                       coverage.col=4,
                       strand.col=6,
                       freqC.col=5 )
        )


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  context = "CpG",
  resolution = "base",
  treatment = 0,
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    meth.col = 4,
    unmeth.col = 5,
    strand.col = 6
  )
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  pipeline = "bismark"
)

# Read in your original data
data <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                  header = FALSE,
                  col.names = c("chr", "start", "end", "meth", "unmeth", "strand"))

# Calculate total coverage and methylation percentage
data$coverage <- data$meth + data$unmeth
data$methPercent <- round(data$meth / data$coverage * 100, 2)

# Write to a new file in methylKit-compatible format
write.table(data[, c("chr", "start", "end", "strand", "coverage", "methPercent")],
            file = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  resolution = "base",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    strand.col = 4,
    coverage.col = 5,
    freqC.col = 6
  )
)


generic.file=system.file("extdata", "generic1.CpG.txt",package = "methylKit")
read.table(generic.file,header=TRUE)

test= read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=T)

head(test)

# And this is how you can read that generic file as a methylKit object
myobj=methRead(test,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj

nrow(read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=TRUE))  # should match wc -l minus 1

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

# And this is how you can read that generic file as a methylKit object
myobj=methRead( generic.file,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj
# This creates tabix files that save methylation

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_patched.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")
myobj



myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1",
                 mincov = 1,
                 assembly="hg38")




myobj = methRead("/tmp/breast/analysis/emseq/pileup/test.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

#+end_src


#+begin_src R
library(methylKit)
library(tidyverse)

meth <- methylKit:::readMethylBaseDB("/tmp/breast/analysis/emseq/dmr/tabix/methylBase_108f6516736d92.txt.bgz")

meth



# Get percent methylation matrix
meth_matrix <- percMethylation(meth)

head(meth_matrix)

clin = data.frame(library_id = c("NH_11","NH_13","PRO_10","PRO_13"),
           cohort = c("healthy","healthy","progressor","progressor"))

# Compute global methylation (mean per sample)
global_df <- meth_matrix %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE)) %>%
  left_join(clin, by = "library_id")

global_df



# Violin plot (one point per library, jittered for clarity)
ggplot(global_df, aes(x = cohort, y = global_methylation, fill = cohort)) +
  geom_violin(width = 1.0, trim = TRUE, alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(title = "Global Methylation per Library",
       y = "Mean % Methylation",
       x = "Group")


# Melt to long format
meth_df <- meth_matrix %>%
  as.data.frame() %>%
  rownames_to_column("CpG") %>%
  pivot_longer(-CpG, names_to = "library_id", values_to = "methylation")

head(meth_df)

# Add group info
meth_df <- left_join(meth_df, sample_metadata, by = "library_id")  # sample_metadata must have `library_id` and `group`

# Violin plot
ggplot(meth_df, aes(x = group, y = methylation, fill = group)) +
  geom_violin(scale = "width", trim = TRUE) +
  facet_wrap(~library_id, nrow = 1) +
  theme_minimal() +
  labs(title = "Global Methylation per Library", y = "% Methylation", x = "Group")

#+end_src



** cfDNA methylation and fragmentation
- [cite:@noe2024]

*** An 2023 methylation and fragmentation patterns


#+begin_src bash
#ssh jeff-nf1

#mamba install -c bioconda -c conda-forge bismark -n emseq

conda activate emseq



# ---- settings ----
GENOME_NAME=ncbi_hg38
GENOME_ROOT=/mnt/data/projects/nf1/ref/bismark
GENOME_DIR=$GENOME_ROOT/$GENOME_NAME
INDEX_DIR=$GENOME_DIR/bismark_index
THREADS=16

# ---- prep dirs ----
mkdir -p "$INDEX_DIR"

# By default, bismark expects fasta(s) in the target folder.
# So place the FASTA there (symlink is fine) BEFORE running:

cd /mnt/data/projects/nf1/inputs

wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz

gunzip -c GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz.1 > ../ref/bismark/ncbi_hg38/bismark_index/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa

cd "$GENOME_DIR"

# ---- build the Bismark index (Bowtie2) ----
# (Requires: bismark, bowtie2, perl)
bismark_genome_preparation \
  --bowtie2 \
  --parallel "$THREADS" \
  --verbose \
  "$INDEX_DIR"


# ---- sanity check: index files should now exist ----
ls -1 "$INDEX_DIR" | grep -E 'Bisulfite_Genome|.bt2$'

mkdir -p /mnt/data/projects/nf1/tmp

cd /mnt/data/projects/nf1/tmp/bismark_out

# these write to dir of action
bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out

nohup bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out \
  > bismark_emseq05.log 2>&1 &

nohup bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_06.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_06.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out \
  > bismark_emseq06.log 2>&1 &

##########1##########2##########3##########4##########5##########6##########7##########8
cp /mnt/data/projects/nf1/tmp/bismark_out/emseq_05.raw_R1_bismark_bt2_pe.bam /mnt/data/projects/nf1/tmp/an/emseq_05.bam

cp /mnt/data/projects/nf1/tmp/bismark_out/emseq_06.raw_R1_bismark_bt2_pe.bam /mnt/data/projects/nf1/tmp/an/emseq_06.bam

cd /mnt/data/projects/nf1/tmp/an
ls

samtools view -h emseq_05.bam | samtools view -b -o emseq_05_repaired.bam

samtools view -h emseq_06.bam | samtools view -b -o emseq_06_repaired.bam

python3 test3.py emseq_05_repaired.bam 10 > /tmp/emseq_05_meth_and_frag.tsv

python3 test3.py emseq_06_repaired.bam 10 > /tmp/emseq_06_meth_and_frag.tsv

python3 test3.py emseq_05_repaired.bam > /tmp/emseq_05_meth_and_frag.tsv

python3 test3.py emseq_06_repaired.bam > /tmp/emseq_06_meth_and_frag.tsv

##########1##########2##########3##########4##########5##########6##########7##########8
# 2) Deduplicate the Bismark BAM (paired-end)
deduplicate_bismark --bam --paired \
  --output_dir /mnt/data/projects/nf1/tmp/bismark_out \
  /mnt/data/projects/nf1/tmp/bismark_out/emseq_12.raw_R1_bismark_bt2_pe.bam

#+end_src

#+begin_src R
library(tidyverse)

pn = read_tsv("/tmp/emseq_05_meth_and_frag.tsv") %>% mutate(dx = "pn")
mpnst = read_tsv("/tmp/emseq_06_meth_and_frag.tsv") %>% mutate(dx = "mpnst")

test=rbind(pn, mpnst)

test %>%
  filter(label != "mid") %>%
  filter(tlen < 167) %>%
  ggplot(aes(x = dx, fill = label)) +
  geom_bar(position = "fill") +
  labs(x = "Diagnosis", y = "Proportion", fill = "Methylation category")


test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(0, 400, 10))) %>%
  group_by(tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, group = 1)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(150, 300, 5))) %>%
  group_by(dx, tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, color = dx, group = dx)) +
  #geom_line() +
  geom_smooth(se=F) +
  labs(x = "Fragment length (bp bins)", y = "Mean CpG fraction") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(0, 400, 10))) %>%
  group_by(dx, tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, group = dx, color = dx)) +
  geom_line() +
  facet_wrap(~dx) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  filter(label != "mid") %>%
  filter(tlen > 167) %>%
  ggplot(aes(x = dx, fill = label)) +
  geom_bar(position = "fill") +
  labs(x = "Diagnosis", y = "Proportion", fill = "Methylation category")


test %>%
  mutate(frag_bin = ifelse(tlen < 167, "<167", ">167")) %>%
  group_by(dx, frag_bin) %>%
  summarise(frac_hyper = mean(label == "hypo"), .groups = "drop") %>%
  tidyr::pivot_wider(
    names_from = frag_bin,
    values_from = frac_hyper
  )

test %>%
  mutate(frag_bin = ifelse(tlen < 167, "<167", ">167")) %>%
  group_by(frag_bin) %>%
  summarise(frac_hyper = mean(label == "hypo"), .groups = "drop") %>%
  tidyr::pivot_wider(
    names_from = frag_bin,
    values_from = frac_hyper
  )

test %>%
  filter(label != "mid") %>%
  filter(tlen > 250) %>%
  count(dx, label) %>%
  ggplot(aes(x = dx, y = n, fill = label)) +
  geom_bar(stat = "identity") +
  labs(x = "Diagnosis", y = "Count", fill = "Methylation category")

test %>%
  filter(label != "mid") %>%
  ggplot(., aes(x=tlen, color = label)) + geom_density()

test %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_density(adjust = 0.7) +
  facet_wrap(~dx)

test %>%
  filter(tlen >155, tlen <250) %>%
  ggplot(aes(x = tlen, color = dx)) +
  geom_density(adjust = 0.6) +
  facet_wrap(~label)


test %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, fill = label)) +
  geom_histogram(position = "identity", alpha = 0.4, bins = 50)

df %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_density(adjust = 0.7)   # smaller = less smooth, more jagged

df %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_freqpoly(binwidth = 1)


#########1#########2#########3#########4#########5#########6#########7#########8

meth=read_tsv("/tmp/meth.tsv")

meth <- meth %>% rename(global_meth = `global%meth`)

# Run two-sample t-test
t.test(global_meth ~ dx, data = meth)
#+end_src

** Test
#+begin_src yaml :tangle ./config/test.yaml
# -----------------------------
# Global runtime/config knobs
# -----------------------------
available-concurrency: 50
threads: 24
main-data-dir: "tests/full"
mosdepth-quant-levels: "1,5"

# -----------------------------
# Environments and repositories
# -----------------------------
envs:
  emseq: "~/repos/emseq/config/emseq-conda-env.yaml"
  methylkit: "~/repos/emseq/config/methylkit-conda-env.yaml"

repos:
  emseq: "~/repos/emseq"

# -----------------------------
# Sample set and region filters
# -----------------------------
library-ids: ["lib001", "lib002", "lib003", "lib004"]
keep-bed: "tests/full/inputs/chr22.keep.bed"
exclude-bed: "tests/full/inputs/chr22.exclude.blacklist.bed.gz"

# -----------------------------
# Reference assemblies (primary + spike)
# -----------------------------
emseq_ref_assemblies:
  chr22:
    url: https:/ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
    name: chr22
    input: chr22.test.fa.gz
  unmeth_lambda:
    url: https://www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/lambdafsa.txt?rev=c0c6669b9bd340ddb674ebfd9d55c691&hash=7E6375924CFF9457D0157D0D87C9AC19
    name: unmeth_lambda
    input: lambda.fa.gz
  puc19:
    url: https://www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/puc19fsa.txt?rev=6e10f4c4a4234d638e401cd2f4578ef0&hash=E71970068EEA191C175B3458DB99D7BB
    name: puc19
    input: pUC19.fa.gz

# -----------------------------
# Experiments (differential methylation experiments for methylKit;
# i.e., groupings/contrasts used to build methylBase/methylDiff)
# -----------------------------
meth-map:
  test:
    libs:        ["lib001","lib003","lib003","lib004"]
    emseq_ref_name:    ["chr22"]
    align_method: bwa_meth
    tx:          [0,0,1,1]
    mincov:      10
    mingroup:    1
    chunksize:   "1e9"
    win_size:    10000
#+end_src

#+begin_src snakemake :tangle ./workflows/test.smk
# -----------------------------
# Imports
# -----------------------------
import os

# -----------------------------
# Path expansion for strings in config (~, $VARS)
# -----------------------------
def resolve_config_paths(config_dict):
    for k, v in config_dict.items():
        if isinstance(v, str):
            config_dict[k] = os.path.expandvars(os.path.expanduser(v))
        elif isinstance(v, dict):
            resolve_config_paths(v)
        elif isinstance(v, list):
            config_dict[k] = [os.path.expandvars(os.path.expanduser(i)) if isinstance(i, str) else i for i in v]

resolve_config_paths(config)

# -----------------------------
# Environments
# -----------------------------
ENV_EMSEQ = config['envs']['emseq']
ENV_METHYLKIT = config['envs']['methylkit']

# -----------------------------
# Repositories
# -----------------------------
R_EMSEQ = config['repos']['emseq']

# -----------------------------
# Data directories (derived from main-data-dir)
# -----------------------------
D_DATA = f"{config['main-data-dir']}"
D_EMSEQ = f"{D_DATA}/emseq"
D_REF = f"{D_DATA}/ref"
D_LOGS = f"{D_DATA}/logs"
D_BENCHMARK = f"{D_DATA}/benchmark"
D_INPUTS = f"{D_DATA}/inputs"

# -----------------------------
# Tool/global params
# -----------------------------
mosdepth_quant_levels = config["mosdepth-quant-levels"]
emseq_mincov = 2  # used by per-sample methylKit object rule

# -----------------------------
# Sample set (required by emseq.smk)
# -----------------------------
emseq_library_ids = config["library-ids"]

# -----------------------------
# Reference selections (kept explicit)
# -----------------------------
spike_builds = ["puc19", "unmeth_lambda"]
emseq_ref_names = ["chr22"]

# -----------------------------
# Region filtering inputs
# -----------------------------
KEEP_BED = config["keep-bed"]
EXCL_BED = config["exclude-bed"]

# -----------------------------
# Experiments map from YAML
# (differential methylation experiments for methylKit)
# -----------------------------
meth_map = config["meth-map"]

rule all:
    input:
        # FASTQs
        expand(f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_{{read}}.fastq.gz",
               library_id=emseq_library_ids,
               read=["R1","R2"]),
        #
        # Alignment and methylation calling

        expand(f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
               library_id = emseq_library_ids,
               emseq_ref_name = emseq_ref_names,
               align_method = ["bwa_meth", "biscuit"]),
        #
        # Spike workflow
        expand(f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
               library_id = emseq_library_ids,
               emseq_ref_name = spike_builds,
               align_method = "bwa_meth"),

        # QC
        expand(f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
               library_id = emseq_library_ids,
               processing = ["raw","trimmed"],
               read = ["R1","R2"]),

        expand(f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
               library_id = emseq_library_ids,
               emseq_ref_name = emseq_ref_names,
               align_method = ["bwa_meth", "biscuit"]),

        expand(f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
               library_id = emseq_library_ids,
               emseq_ref_name = emseq_ref_names,
               align_method = ["bwa_meth", "biscuit"]),

        f"{D_EMSEQ}/qc/multiqc.html",
        # NOTE: MultiQC rule DOES NOT prompt inputs to run, need individual QC output calls
        #
        # MethylKit
        expand(f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
               experiment = meth_map.keys()),

        expand(f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
               experiment = meth_map.keys()),

        expand(f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
               experiment = meth_map.keys()),


rule symlink_input_fastqs:
    input:
        r1=f"{D_DATA}/inputs/{{library_id}}.raw_R1.fastq.gz",
        r2=f"{D_DATA}/inputs/{{library_id}}.raw_R2.fastq.gz",
    output:
        r1=f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R1.fastq.gz",
        r2=f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R2.fastq.gz",
    shell:
        r'''
        mkdir -p "$(dirname "{output.r1}")"
        ln -sfr "{input.r1}" "{output.r1}"
        ln -sfr "{input.r2}" "{output.r2}"
        '''

include: f"{R_EMSEQ}/workflows/emseq.smk"


#+end_src

#+begin_src snakemake

# Development snakemake to test
mosdepth_quant_levels = config["mosdepth-quant-levels"]
repo = "~/repos/emseq"
data_dir=config["data_dir"]
emseq_script_dir = "~/repos/emseq/scripts"
log_dir = f"{data_dir}/logs"

emseq_mincov = 2
emseq_build = "hg38"

threads = 80
# We specify em-seq bam directory directly to allow for workflows that merge at the bam level:
emseq_bam_dir = f"{data_dir}/analysis/emseq/bams"


# Explicitly select which references to build
index_targets = ["unmeth_lambda", "puc19"]

library_ids = ["NH_15_L3", "PRO_6_L2"]

spike_ref_names = ["unmeth_lambda"]

ref_names = ["ncbi_decoy_hg38"]

align_methods = ["bwa_meth"]

emseq_library_ids = library_ids

meth_map = {
    "test": {
        "build": "hg38",
        "mincov": "5",
        "libs": library_ids,
        "tx": "0,1"
}
}


mosdepth_map = {
    "tests": {
        "library_ids": ["NH_15_L3", "PRO_6_L2"],
        "ref_name": "ncbi_decoy_hg38",
        "align_method": "bwa_meth"
    }
}

rule all:
    input:
        # FASTQs
        expand(f"{data_dir}/analysis/emseq/fastqs/{{library_id}}_{{processing}}_{{read}}.fastq.gz",
               library_id = library_ids,
               processing = ["raw","trimmed"],
               read = ["R1","R2"]),

        expand(f"{data_dir}/qc/{{library_id}}_{{processing}}_{{read}}_fastqc.{{suffix}}",
               library_id = library_ids,
               processing = ["raw","trimmed"],
               read = ["R1","R2"],
               suffix = ["zip","html"]),

        # Spike-ins
        expand(f"{data_dir}/analysis/emseq/spike/{{library_id}}.{{ref_name}}.bwa_meth.coorsort.bam",
               library_id = library_ids,
               ref_name = spike_ref_names,
               align_method = "bwa_meth"),

        expand(f"{data_dir}/analysis/emseq/spike/{{library_id}}.{{ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
               library_id=library_ids,
               ref_name=spike_ref_names,
               align_method= "bwa_meth"),

        # Biscuit 1 steps
        ## Index
        expand(f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.fai",
               name = "ncbi_decoy_hg38"),

        ## Align
        expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
               library_id = library_ids,
               ref_name = ref_names),

        # BWA-meth
        # ## Index
        # expand(f"{data_dir}/ref/bwa_meth/{{name}}/{{name}}.fa.bwameth.c2t",
        #        name = ref_names),

        # ## Align

        # expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.bwa_meth.coorsort.bam",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        align_method = "bwa_meth"),

        ## COMMON DEDUP HERE

        ## Pileup
        # expand(f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.{{suffix}}",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        suffix = ["vcf.gz","vcf_meth_average.tsv"]),

        # ## Make per-library methylkit objects
        # expand(f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.{{suffix}}",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        suffix = ["txt", "txt.bgz", "txt.bgz.tbi"]),

        # Common post-alignment per-library steps
        ## Deduplicate
        expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.{{align_method}}.coorsort.deduped.bam",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit","bwa_meth"]),

        ## Depth
        expand(f"{data_dir}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.mosdepth.summary.txt",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit","bwa_meth"]),

        ## Call methylation
        expand(f"{data_dir}/analysis/emseq/meth/{{library_id}}.{{ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit", "bwa_meth"]),

        ## Create per-library methylkit objects
        expand(f"{data_dir}/analysis/emseq/dmr/tabix/{{library_id}}.{{ref_name}}.{{align_method}}.txt",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = "bwa_meth"),

        expand(f"{data_dir}/qc/{{experiment}}.emseq_mosdepth_agg_plot.pdf",
               experiment = mosdepth_map.keys()),





#+end_src

*** Example wrapper

#+begin_src yaml :tangle ./config/example-config.yaml
data_dir: /mnt/data/projects/breast
emseq_ref_assemblies:
  ncbi_decoy_hg38:
    url: https:/ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
    name: ncbi_decoy_hg38
    input: GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fa.gz

  ensembl_hg38:
    url: https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
    name: ensembl_hg38
    input: Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz

  unmeth_lambda:
    url: https:/www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/lambdafsa.txt?rev=c0c6669b9bd340ddb674ebfd9d55c691&hash=7E6375924CFF9457D0157D0D87C9AC19
    name: unmeth_lambda
    input: Lambda_NEB.fa.gz

  puc19:
    url: https:/www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/puc19fsa.txt?rev=6e10f4c4a4234d638e401cd2f4578ef0&hash=E71970068EEA191C175B3458DB99D7BB
    name: puc19
    input: pUC19.fa.gz


mosdepth-quant-levels: "1,5,10,20,30"

#+end_src

#+begin_src bash
conda activate biotools

cd ~/repos/emseq
data_dir=/mnt/data/projects/nf1

mkdir -p $data_dir/inputs

config_yaml=config/test.yaml

config_yaml=config/example-config.yaml

url=$(yqgo '.emseq_ref_assemblies.puc19.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.puc19.input' "$config_yaml") && \
wget -O - --user-agent="Mozilla/5.0" --referer="https:/www.neb.com" "$url" | \
  gzip > "$data_dir/inputs/$outfile"


url=$(yqgo '.emseq_ref_assemblies.unmeth_lambda.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.unmeth_lambda.input' "$config_yaml") && \
wget -O - --user-agent="Mozilla/5.0" --referer="https:/www.neb.com" "$url" | \
  gzip > "$data_dir/inputs/$outfile"


url=$(yqgo '.emseq_ref_assemblies.ncbi_decoy_hg38.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.ncbi_decoy_hg38.input' "$config_yaml") && \
wget -O "$data_dir/inputs/$outfile" "$url"


#+end_src


#+begin_src snakemake :tangle ./workflows/test-wrap.smk

repo = "~/repos/emseq"
data_dir=config["data_dir"]

# Explicitly select which references to build
index_targets = ["unmeth_lambda", "puc19"]

rule all:
    input:
        expand(f"{data_dir}/ref/{{name}}.fa.bwameth.c2t", name=index_targets)


include: f"{repo}/workflows/dev.smk"

#+end_src
** Reference
- [[id:79dfda7e-8b6d-45c7-88d5-804979155763][cfDNA methylation]]
- Alternative cfDNA WGMS profiling
  - TET-Assisted Pyridine Borane Sequencing (TAPS) [cite:@vavoulis2025]
- https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41587-022-01652-0
- Alignment reference choice
  - discussion [[https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369][gtp]]
  - see [[id:326ecd60-8cd4-4815-a389-967b2c3fef0a][Nucleic acid sequence alignment]]
- [cite:@vaisvila2021]
- [cite:@chauhan2024]
- [[id:5e9e8bfa-ac9e-4103-9cc5-7123337b4e24][biscuit]]
- https:/github.com/semenko/serpent-methylation-pipeline
- EM-seq protects 5mC and 5hmC from damination with TET2 enzymatic oxidation. Unprotected cytosines are deaminated to uracils.
- cfDNA WGBS hypomethylation and CNAs as a general cancer marker [cite:@chan2013meth]
- [cite:@chan2013meth]
  - [cite:@liu2020]
  - [cite:@shen2018plasma]
    - [cite:@liang2021meth]
    - [cite:@shen2019cfmedip]
    - [cite:@nuzzo2020] *
    - [cite:@nassiri2020] *
  - [cite:@li20175hmc]
  - [cite:@song20175hmc]
  - [cite:@li2018meth]
    - [cite:@liang2021meth]
    - [cite:@hlady2019]
    - [cite:@moss2020]
    - [cite:@stackpole2022]
      - [cite:@wong2023]
      - [cite:@li2023cfdna]
      - [cite:@melton2023]
    - [cite:@wu2020]
    - [cite:@delvecchio2020]


- [cite:@bie2023]
https:/www-pnas-org.mclibrary.idm.oclc.org/doi/full/10.1073/pnas.2017421118#sec-3
https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41551-021-00746-5#Sec11

https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41586-022-05580-6

[cite:@melton2023]

https:/www-scopus-com.mclibrary.idm.oclc.org/results/results.uri?sort=cp-f&src=s&sid=02157e5ff2f1b8a77a24e67aeefcb07b&sot=a&sdt=a&cluster=scosubtype%2C%22ar%22%2Ct&sl=76&s=%28TITLE-ABS-KEY%28%22cell-free+DNA%22%29+AND+TITLE-ABS-KEY%28methylation%29%29+AND+NOT%28PCR%29&origin=searchadvanced&editSaveSearch=&txGid=3b8b26bec1c779cef84de4d3803c1be9&sessionSearchId=02157e5ff2f1b8a77a24e67aeefcb07b&limit=10

https:/www-nature-com.mclibrary.idm.oclc.org/articles/ng.3805

| article             | group      | platform    | depth | tissue | target | times cited | date |
|---------------------+------------+-------------+-------+--------+--------+-------------+------|
| [cite:@nassiri2020] | decarvalho | cfMeDIP-seq |       | CNS    | CNS    |             |      |

Original EM-seq methods paper - [cite:@vaisvila2021]. Code is in the repo at [[file:resources/EM-seq-master/]]


EM-seq and WGBS are not compatible- have different unique methylated CpGs at 8x [[/home/jeszyman/repos/emseq/emseq.org_20250605_135724.png][./resources/vaisvila2021fig4c.png]]
** Ideas
- config optinos as switches
- Mosdepth aggregator
  #+begin_src snakemake :tangle no
print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        thresholds = expand(f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.thresholds.bed.gz",
                            library_id=emseq_library_ids),
        regions = expand(f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.regions.bed.gz",
                         library_id=emseq_library_ids),
    output:
        pdf = f"{qc_dir}/emseq_mosdepth_agg_plot.pdf",
        tsv = f"{qc_dir}/emseq_mosdepth_agg.tsv",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf} \
        --output_tsv {output.tsv}
        """

#+end_src
  #+begin_src snakemake :tangle no

def flatten(x):
    return [item for sublist in x for item in (sublist if isinstance(sublist, list) else [sublist])]

print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        threshold_list = lambda wildcards, input: " ".join(flatten(input.thresholds)),
        regions_list = lambda wildcards, input: " ".join(flatten(input.regions)),
    output:
        pdf = f"{qc_dir}/mosdepth_agg_plot.pdf",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src

  #+begin_src snakemake
rule emseq_mosdepth_agg_plot:
    conda:
        "../config/mosdepth-conda-env.yaml",
    input:
        thresholds = lambda wildcards: expand(
            f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{mosdepth_map[wildcards.experiment]['ref_name']}."
            f"{mosdepth_map[wildcards.experiment]['align_method']}.thresholds.bed.gz",
            library_id=mosdepth_map[wildcards.experiment]['library_ids']
        ),
        regions = lambda wildcards: expand(
            f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{mosdepth_map[wildcards.experiment]['ref_name']}."
            f"{mosdepth_map[wildcards.experiment]['align_method']}.regions.bed.gz",
            library_id=mosdepth_map[wildcards.experiment]['library_ids']
        )
    output:
        pdf = f"{config['emseq-dir']}/qc/{{experiment}}.emseq_mosdepth_agg_plot.pdf",
        tsv = f"{config['emseq-dir']}/qc/{{experiment}}.emseq_mosdepth_agg.tsv",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = lambda wildcards: " ".join(mosdepth_map[wildcards.experiment]['library_ids']),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf} \
        --output_tsv {output.tsv}
        """

#+end_src

  #+begin_src R :tangle no
#!/usr/bin/env Rscript

# ==============================================================================
# Description:
#   Parses multiple mosdepth threshold files (*.thresholds.bed.gz) and generates
#   a single paginated PDF plot (4×6 panels per page) showing counts of bases
#   covered at actual observed thresholds (e.g., 1X, 2X, 5X...) per sample.
#
#   Infers 0X bins by identifying regions where all threshold counts are zero.
#
# Inputs:
#   --threshold_list   Space-separated list of mosdepth threshold files
#   --library_list     Space-separated list of sample names (must match order)
#   --output_pdf       Full path to output PDF file (single file, multi-page)
# ==============================================================================

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
})


suppressWarnings(library(matrixStats))  # at top


# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (length(threshold_files) != length(library_ids)) {
  stop("Error: threshold_list and library_list must be the same length")
}

# -------------------------------
# Function to parse each threshold file
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

# -------------------------------
# Read and combine all files
# -------------------------------

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Compute median depth per sample
# -------------------------------

hist_data[, threshold_numeric := as.numeric(sub("X$", "", threshold))]
medians <- hist_data[!is.na(threshold_numeric),
  .(median = weightedMedian(threshold_numeric, w = count)),
  by = sample]


# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

# Correct threshold order based on numeric prefix
threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Panel layout and plotting
# -------------------------------

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id, median]
  subtitle <- sprintf("Median depth: %.1f×", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output: single PDF with multiple pages
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()

#+end_src
  #+begin_src R :tangle no
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
  suppressWarnings(library(matrixStats))
})

# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--regions_list", required = TRUE,
                    help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
regions_files <- unlist(strsplit(args$regions_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
  stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
}

# -------------------------------
# Read and melt threshold files
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
hist_data[, count := as.numeric(count)]

all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Read autosomal median from regions.bed.gz
# -------------------------------

get_autosomal_median <- function(file, sample_id) {
  df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
  df <- df[chrom %in% as.character(1:22)]
  df[, sample := sample_id]
  df[, median := median(depth)]
  df[1, .(sample, median)]
}

medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Plot panels
# -------------------------------
print(medians)

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id][["median"]]
  subtitle <- sprintf("Median depth: %.1f×", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()
#+end_src
  - [[file:scripts/emseq_mosdepth_agg_plot.R]]
    #+begin_src R :tangle ./scripts/emseq_mosdepth_agg_plot.R
  #!/usr/bin/env Rscript

  suppressPackageStartupMessages({
    suppressWarnings(library(argparse))
    suppressWarnings(library(data.table))
    suppressWarnings(library(ggplot2))
    suppressWarnings(library(Cairo))
    suppressWarnings(library(scales))
    suppressWarnings(library(patchwork))
    suppressWarnings(library(matrixStats))
  })

  # -------------------------------
  # Argument parsing
  # -------------------------------

  prog <- basename(commandArgs(trailingOnly = FALSE)[1])

  parser <- ArgumentParser(
    description = "Generate a paginated threshold coverage plot from mosdepth output.",
    prog = prog
  )

  parser$add_argument("--threshold_list", required = TRUE,
                      help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
  parser$add_argument("--regions_list", required = TRUE,
                      help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
  parser$add_argument("--library_list", required = TRUE,
                      help = "Space-separated list of sample names (must match file order)")
  parser$add_argument("--output_pdf", required = TRUE,
                      help = "Full output PDF file path (e.g., /tmp/plot.pdf)")
  parser$add_argument("--output_tsv", required = TRUE,
                      help = "Path for tabular output")

  args <- parser$parse_args()
  threshold_files <- unlist(strsplit(args$threshold_list, " "))
  regions_files <- unlist(strsplit(args$regions_list, " "))
  library_ids <- unlist(strsplit(args$library_list, " "))
  output_tsv <- args$output_tsv
  output_pdf <- args$output_pdf

  if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
    stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
  }

  # -------------------------------
  # Read and melt threshold files
  # -------------------------------

  read_thresholds <- function(file, sample) {
    header <- fread(file, nrows = 0)
    names(header)[1] <- sub("^#", "", names(header)[1])
    threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
    df <- fread(file, skip = 1, col.names = names(header))
    df[, sample := sample]
    melted <- melt(df,
      id.vars = c("chrom", "start", "end", "region", "sample"),
      measure.vars = threshold_cols,
      variable.name = "threshold",
      value.name = "count"
    )
    list(data = melted, thresholds = threshold_cols)
  }

  parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
  hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
  hist_data[, count := as.numeric(count)]

  all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

  # -------------------------------
  # Read autosomal median from regions.bed.gz
  # -------------------------------

  get_autosomal_median <- function(file, sample_id) {
    df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
    df <- df[chrom %in% paste0("chr", 1:22)]
    df[, sample := sample_id]
    df[, median := median(depth)]
    df[1, .(sample, median)]
  }

  medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

  # -------------------------------
  # Infer 0X bins from zeroed rows
  # -------------------------------

  hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                     value.var = "count", fill = 0)
  hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
  zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
  zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
  zero_counts[, threshold := "0X"]

  # -------------------------------
  # Aggregate and bind all data
  # -------------------------------

  plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
  plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

  threshold_levels <- unique(plot_data$threshold)
  threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
  plot_data[, threshold := factor(threshold, levels = threshold_levels)]

  # -------------------------------
  # Plot panels
  # -------------------------------
  print(medians)

  make_panel <- function(sample_id) {
    median_val <- medians[sample == sample_id][["median"]]
    subtitle <- sprintf("Median depth: %.1f×", median_val)

    ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
      geom_col(width = 0.8) +
      scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
      scale_fill_brewer(palette = "Set2", guide = "none") +
      labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
      theme_minimal(base_size = 10) +
      theme(
	axis.text = element_text(size = 8),
	axis.title = element_text(size = 9),
	plot.title = element_text(size = 10, hjust = 0.5),
	plot.subtitle = element_text(size = 9, hjust = 0.5),
	panel.grid = element_line(linewidth = 0.2, colour = "grey90")
      )
  }

  ncol <- 4
  nrow <- 6
  panels_per_page <- ncol * nrow
  sample_list <- unique(plot_data$sample)
  pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

  # -------------------------------
  # Output
  # -------------------------------

  CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
  for (i in seq_along(pages)) {
    plots <- lapply(pages[[i]], make_panel)
    layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
      plot_annotation(
	title = "Coverage threshold by sample",
	theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
      )
    print(layout)
  }
  dev.off()

  fwrite(medians,   file = args$output_tsv, sep = "\t")

  #+end_src
- Copy number integration
  - [cite:@chan2013meth]
  - [cite:@widman2024]
- Annotation
  - https:/bioconductor.org/packages/devel/bioc/vignettes/annotatr/inst/doc/annotatr-vignette.html
  - get nearest TSS
  - get region annotation
- TSS coverage
  - https:/deeptools.readthedocs.io/en/stable/content/tools/plotProfile.html
- state fit for methylation like hyper /hypo of bins
- Mosdepth aggregator
  #+begin_src snakemake
print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        thresholds = expand(f"{data_dir}/qc/mosdepth_{{library_id}}.thresholds.bed.gz", library_id=emseq_library_ids),
        regions = expand(f"{data_dir}/qc/mosdepth_{{library_id}}.regions.bed.gz", library_id=emseq_library_ids),
    output:
        pdf = f"{data_dir}/qc/mosdepth_agg_plot.pdf",
    params:
        script = f"{emseq_script_dir}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src
  #+begin_src snakemake :tangle no

def flatten(x):
    return [item for sublist in x for item in (sublist if isinstance(sublist, list) else [sublist])]

print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        threshold_list = lambda wildcards, input: " ".join(flatten(input.thresholds)),
        regions_list = lambda wildcards, input: " ".join(flatten(input.regions)),
    output:
        pdf = f"{qc_dir}/mosdepth_agg_plot.pdf",
    params:
        script = f"{emseq_script_dir}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src

  #+begin_src R
#!/usr/bin/env Rscript

# ==============================================================================
# Description:
#   Parses multiple mosdepth threshold files (*.thresholds.bed.gz) and generates
#   a single paginated PDF plot (4×6 panels per page) showing counts of bases
#   covered at actual observed thresholds (e.g., 1X, 2X, 5X...) per sample.
#
#   Infers 0X bins by identifying regions where all threshold counts are zero.
#
# Inputs:
#   --threshold_list   Space-separated list of mosdepth threshold files
#   --library_list     Space-separated list of sample names (must match order)
#   --output_pdf       Full path to output PDF file (single file, multi-page)
# ==============================================================================

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
})


suppressWarnings(library(matrixStats))  # at top


# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (length(threshold_files) != length(library_ids)) {
  stop("Error: threshold_list and library_list must be the same length")
}

# -------------------------------
# Function to parse each threshold file
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

# -------------------------------
# Read and combine all files
# -------------------------------

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Compute median depth per sample
# -------------------------------

hist_data[, threshold_numeric := as.numeric(sub("X$", "", threshold))]
medians <- hist_data[!is.na(threshold_numeric),
  .(median = weightedMedian(threshold_numeric, w = count)),
  by = sample]


# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

# Correct threshold order based on numeric prefix
threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Panel layout and plotting
# -------------------------------

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id, median]
  subtitle <- sprintf("Median depth: %.1f×", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output: single PDF with multiple pages
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()

#+end_src
  #+begin_src R :tangle no
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
  suppressWarnings(library(matrixStats))
})

# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--regions_list", required = TRUE,
                    help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
regions_files <- unlist(strsplit(args$regions_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
  stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
}

# -------------------------------
# Read and melt threshold files
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
hist_data[, count := as.numeric(count)]

all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Read autosomal median from regions.bed.gz
# -------------------------------

get_autosomal_median <- function(file, sample_id) {
  df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
  df <- df[chrom %in% as.character(1:22)]
  df[, sample := sample_id]
  df[, median := median(depth)]
  df[1, .(sample, median)]
}

medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Plot panels
# -------------------------------
print(medians)

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id][["median"]]
  subtitle <- sprintf("Median depth: %.1f×", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()
#+end_src
*** Methylkit output annotation
https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html
- get nearest TSS
- get region annotation


#+begin_src R
## --- deps ---
library(methylKit)
library(GenomicRanges)
library(dplyr)
library(tidyr)

# CpG context
library(annotatr)

# Gene parts + TSS
library(genomation)  # (for distanceToNearest helper; also loads GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(GenomeInfoDb)
library(AnnotationDbi)
library(org.Hs.eg.db)

## --- 0) load methylKit base-resolution object ---
# md should be methylBase/methylBaseDB at base resolution (not tiles)
md <- methylKit:::readMethylDB(
  "~/repos/emseq/tests/full/emseq/dmr/diff/methylDiff_test.txt.bgz"
)

gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)   # stable key per CpG

## --- 1) CpG context flags: island / shore / shelf / inter (open sea) ---
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) |>
  as_tibble() |>
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(GenomicRanges::seqnames(gr)),
  q_start = GenomicRanges::start(gr),
  q_end   = GenomicRanges::end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a |>
  right_join(keys, by = c("q_chr","q_start","q_end")) |>
  group_by(qid) |>
  summarize(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

## --- 2) Gene parts + nearest TSS (strand-aware) ---
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb), use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = 2000, downstream = 500)  # tweak widths
tsspt <- promoters(txdb, upstream = 0,    downstream = 1)    # 1bp TSS

# harmonize naming; drop to seqlevels present in gr
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

# per-CpG flags
is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0

gene_part_primary <- ifelse(is_prom,  "promoter",
                       ifelse(is_exon,  "exon",
                       ifelse(is_intron,"intron",
                       ifelse(is_5utr,  "5UTR",
                       ifelse(is_3utr,  "3UTR", "intergenic")))))

# nearest TSS distance + symbol
nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# map TSS to gene symbols (TxDb uses Entrez gene_id)
gs <- genes(txdb); gs <- keepSeqlevels(gs, wanted, pruning.mode = "coarse")
sub_hits <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select = "first")
entrez   <- mcols(gs)$gene_id[sub_hits]
sym_map  <- AnnotationDbi::select(org.Hs.eg.db,
                                  keys = unique(na.omit(entrez)),
                                  keytype = "ENTREZID", columns = "SYMBOL")
sym_lut  <- setNames(sym_map$SYMBOL, sym_map$ENTREZID)
nearest_symbol <- unname(sym_lut[entrez])

tss_key <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  nearest_gene_symbol = nearest_symbol
)

dist_tbl <- dist_tbl |>
  left_join(tss_key, by = "tss_idx") |>
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) |>
  left_join(dist_tbl, by = "qid")

## --- 3) Final one-row-per-CpG table (no writing yet) ---
out <- as_tibble(getData(md)) |>
  mutate(qid = row_number()) |>
  left_join(cpg_flags,  by = "qid") |>
  left_join(gene_flags, by = "qid")

out
#+end_src

#+begin_src R
# ------- inputs: mb_base (base-resolution methylBase/DB for cohort) -------
library(methylKit)
library(GenomicRanges)
library(annotatr)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(GenomeInfoDb)
library(AnnotationDbi)
library(org.Hs.eg.db)
library(dplyr)
library(arrow)  # or fst/feather

# 1) cohort CpG set from mb_base
dt <- as.data.frame(getData(mb_base))      # chr,start,end,strand, counts...
gr <- GRanges(dt$chr, IRanges(dt$start, dt$end), strand = dt$strand)
cpg_id <- paste(dt$chr, dt$start, sep=":")

# 2) CpG-context flags via annotatr (island/shore/shelf/inter)
ann_cpg <- build_annotations(genome="hg38", annotations="hg38_cpgs")
a <- annotate_regions(gr, ann_cpg, ignore.strand=TRUE, quiet=TRUE) |>
     as_tibble() |>
     transmute(q_chr=as.character(seqnames), q_start=start, type=annot.type)
keys <- tibble(q_chr=as.character(seqnames(gr)), q_start=start(gr), qid=seq_along(gr))
cpg_ctx <- a |>
  right_join(keys, by=c("q_chr","q_start")) |>
  group_by(qid) |>
  summarise(
    is_island  = any(type=="hg38_cpg_islands"),
    is_shore   = any(type=="hg38_cpg_shores"),
    is_shelf   = any(type=="hg38_cpg_shelves"),
    is_opensea = any(type=="hg38_cpg_inter"),
    .groups="drop"
  )

# 3) Gene parts + TSS (strand-aware) via TxDb
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
ex    <- keepStandardChromosomes(exons(txdb),   pruning.mode="coarse")
intr  <- keepStandardChromosomes(unlist(intronsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
utr5  <- keepStandardChromosomes(unlist(fiveUTRsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
utr3  <- keepStandardChromosomes(unlist(threeUTRsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
prom  <- keepStandardChromosomes(promoters(txdb, 2000, 500), pruning.mode="coarse")
tsspt <- keepStandardChromosomes(promoters(txdb, 0, 1), pruning.mode="coarse")
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex<-keepSeqlevels(ex,wanted,pruning.mode="coarse"); intr<-keepSeqlevels(intr,wanted,"coarse")
utr5<-keepSeqlevels(utr5,wanted,"coarse"); utr3<-keepSeqlevels(utr3,wanted,"coarse")
prom<-keepSeqlevels(prom,wanted,"coarse"); tsspt<-keepSeqlevels(tsspt,wanted,"coarse")

is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0
gene_primary <- ifelse(is_prom,"promoter",
                  ifelse(is_exon,"exon",
                  ifelse(is_intron,"intron",
                  ifelse(is_5utr,"5UTR",
                  ifelse(is_3utr,"3UTR","intergenic")))))

nn <- distanceToNearest(gr, tsspt, ignore.strand=FALSE)
dist_tbl <- tibble(qid = queryHits(nn), dist_to_TSS = mcols(nn)$distance, tss_idx = subjectHits(nn))
gs <- genes(txdb); gs <- keepSeqlevels(gs, wanted, pruning.mode="coarse")
map <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select="first")
entrez <- mcols(gs)$gene_id[map]
sym <- AnnotationDbi::select(org.Hs.eg.db, keys=unique(na.omit(entrez)),
                             keytype="ENTREZID", columns="SYMBOL")
sym_lut <- setNames(sym$SYMBOL, sym$ENTREZID)
tss_key <- tibble(tss_idx = unique(dist_tbl$tss_idx),
                  nearest_gene_symbol = unname(sym_lut[entrez]))
dist_tbl <- left_join(dist_tbl, tss_key, by="tss_idx") |> select(-tss_idx)

gene_flags <- tibble(
  qid = seq_along(gr),
  is_promoter = is_prom, is_exon = is_exon, is_intron = is_intron,
  is_5utr = is_5utr, is_3utr = is_3utr,
  gene_part_primary = gene_primary
) |>
  left_join(dist_tbl, by="qid")

# 4) Persist CpG annotation keyed by cpg_id (chr:start)
cpg_anno <- tibble(
  cpg_id = cpg_id
) |>
  mutate(qid = row_number()) |>
  left_join(cpg_ctx,  by="qid") |>
  left_join(gene_flags, by="qid") |>
  dplyr::select(-qid)

write_parquet(cpg_anno, "/tmp/cpg_annotation_hg38.parquet")   # <— reuse for every diff file

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges)
  library(GenomeInfoDb)
  library(dplyr)
  library(tidyr)
  library(annotatr)
  library(genomation)
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  library(AnnotationDbi)
  library(org.Hs.eg.db)
})

## --- 1) CLI arguments ---
parser <- ArgumentParser(description = "Annotate base-resolution methylKit objects with CpG context, gene parts, and TSS info")

parser$add_argument("--db", required = TRUE,
  help = "Path to methylKit base-resolution DB file (.txt.bgz)")
parser$add_argument("--prom-up", type = "integer", default = 2000,
  help = "Promoter upstream bp [default: 2000]")
parser$add_argument("--prom-dn", type = "integer", default = 500,
  help = "Promoter downstream bp [default: 500]")
parser$add_argument("--with-symbols", action = "store_true",
  help = "Also map nearest TSS to HGNC gene symbol")
parser$add_argument("--out", required = TRUE,
  help = "Output TSV with annotations")

args <- parser$parse_args()

## --- 2) Load methylKit DB ---
md <- methylKit:::readMethylDB(args$db)

gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)

## --- 3) CpG context (island/shore/shelf/opensea) ---
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) %>%
  as_tibble() %>%
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(seqnames(gr)),
  q_start = start(gr),
  q_end   = end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a %>%
  right_join(keys, by = c("q_chr","q_start","q_end")) %>%
  group_by(qid) %>%
  summarise(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

## --- 4) Gene parts + nearest TSS ---
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = args$prom_up, downstream = args$prom_dn)
tsspt <- promoters(txdb, upstream = 0, downstream = 1)

for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0

gene_part_primary <- ifelse(is_prom,  "promoter",
                        ifelse(is_exon,  "exon",
                        ifelse(is_intron,"intron",
                        ifelse(is_5utr,  "5UTR",
                        ifelse(is_3utr,  "3UTR", "intergenic")))))

nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

if (args$with_symbols) {
  gs <- genes(txdb) %>% keepSeqlevels(wanted, pruning.mode = "coarse")
  sub_hits <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select = "first")
  entrez   <- mcols(gs)$gene_id[sub_hits]
  sym_map  <- AnnotationDbi::select(org.Hs.eg.db,
                                    keys = unique(na.omit(entrez)),
                                    keytype = "ENTREZID", columns = "SYMBOL")
  sym_lut  <- setNames(sym_map$SYMBOL, sym_map$ENTREZID)
  nearest_symbol <- unname(sym_lut[entrez])

  tss_key <- tibble(
    tss_idx = unique(dist_tbl$tss_idx),
    nearest_gene_symbol = nearest_symbol
  )

  dist_tbl <- dist_tbl %>%
    left_join(tss_key, by = "tss_idx") %>%
    dplyr::select(-tss_idx)
} else {
  dist_tbl <- dist_tbl %>%
    dplyr::select(-tss_idx)
}

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) %>%
  left_join(dist_tbl, by = "qid")

## --- 5) Assemble and write output ---
out <- as_tibble(getData(md)) %>%
  mutate(qid = dplyr::row_number()) %>%
  left_join(cpg_flags,  by = "qid") %>%
  left_join(gene_flags, by = "qid") %>%
  dplyr::select(
    chr, start, end, strand,
    qid,
    dplyr::starts_with("is_"),
    gene_part_primary,
    dist_to_TSS,
    dplyr::everything()
  )

readr::write_tsv(out, args$out)

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges)
  library(GenomeInfoDb)
  library(dplyr)
  library(tidyr)
  library(annotatr)                               # CpG context (hg38_cpgs)
  library(genomation)                             # distanceToNearest()
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)      # promoters/exons/introns/UTRs/TSS
  library(AnnotationDbi)
  library(org.Hs.eg.db)                           # ENTREZ↔SYMBOL/ENSEMBL
  library(readr)
})

# ----------------------------- CLI -----------------------------
parser <- ArgumentParser(
  description = "Annotate base-resolution methylKit DB with CpG context, gene parts, and TSS info"
)
parser$add_argument("--db", required = TRUE,
  help = "Path to methylKit tabix DB (.txt.bgz) for base-resolution or methylDiff")
parser$add_argument("--prom-up", type = "integer", default = 2000,
  help = "Promoter upstream bp [default: 2000]")
parser$add_argument("--prom-dn", type = "integer", default = 500,
  help = "Promoter downstream bp [default: 500]")
parser$add_argument("--with-symbols", action = "store_true",
  help = "Also map nearest TSS to SYMBOL and ENSEMBL (via org.Hs.eg.db)")
parser$add_argument("--out", required = TRUE,
  help = "Output TSV path")
args <- parser$parse_args()

# ----------------------- Load loci (STRICT) ----------------------
# You told me to always use this reader. Done.
md <- methylKit:::readMethylDB(args$db)
gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)   # stable key per CpG locus

# -------------------- CpG context (annotatr) --------------------
# hg38_cpgs yields *disjoint* classes: islands, shores, shelves, inter
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) %>%
  as_tibble() %>%
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(seqnames(gr)),
  q_start = start(gr),
  q_end   = end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a %>%
  right_join(keys, by = c("q_chr","q_start","q_end")) %>%
  group_by(qid) %>%
  summarise(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

# --------------- Gene parts + nearest TSS (TxDb) ----------------
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

# Transcript-level features
ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = args$prom_up, downstream = args$prom_dn)
tsspt <- promoters(txdb, upstream = 0, downstream = 1)  # 1-bp TSS; has tx_id

# Harmonize naming + limit to chromosomes we actually have
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

# Fast boolean flags (no many-to-many expansion)
is_prom   <- countOverlaps(gr, prom) > 0L
is_exon   <- countOverlaps(gr, ex)   > 0L
is_intron <- countOverlaps(gr, intr) > 0L
is_5utr   <- countOverlaps(gr, utr5) > 0L
is_3utr   <- countOverlaps(gr, utr3) > 0L

# Precedence (explicit, reproducible):
# promoter > exon > intron > 5UTR > 3UTR > intergenic
gene_part_primary <- ifelse(is_prom,  "promoter",
                        ifelse(is_exon,  "exon",
                        ifelse(is_intron,"intron",
                        ifelse(is_5utr,  "5UTR",
                        ifelse(is_3utr,  "3UTR", "intergenic")))))

# Nearest TSS distance (strand-aware)
nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# Map nearest TSS transcript -> ENTREZID -> SYMBOL/ENSEMBL
# (TxDb promoters carry tx_id; use TxDb::select to map TXID -> GENEID/ENTREZ)
tx_for_tss <- mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)]
tx_map <- AnnotationDbi::select(
  x       = txdb,
  keys    = as.character(tx_for_tss),
  keytype = "TXID",
  columns = c("TXID","GENEID")
)
# Keep first mapping per TSS index
tss2tx <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  TXID    = as.character(mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)])
) %>%
  left_join(tx_map, by = "TXID") %>%
  distinct(tss_idx, .keep_all = TRUE)

# Add SYMBOL and ENSEMBL
if (args$with_symbols) {
  gene_map <- AnnotationDbi::select(
    org.Hs.eg.db,
    keys    = unique(na.omit(tss2tx$GENEID)),
    keytype = "ENTREZID",
    columns = c("SYMBOL","ENSEMBL")
  )
  gene_map <- gene_map %>%
    distinct(ENTREZID, .keep_all = TRUE) %>%
    rename(ENTREZID = ENTREZID)
  tss2tx <- tss2tx %>%
    rename(ENTREZID = GENEID) %>%
    left_join(gene_map, by = "ENTREZID")
} else {
  tss2tx <- tss2tx %>% rename(ENTREZID = GENEID)
}

dist_tbl <- dist_tbl %>%
  left_join(tss2tx %>% dplyr::select(tss_idx, ENTREZID, dplyr::any_of(c("SYMBOL","ENSEMBL"))),
            by = "tss_idx") %>%
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) %>%
  left_join(dist_tbl, by = "qid")

# -------------------- Assemble & write --------------------------
out <- as_tibble(getData(md)) %>%
  mutate(qid = dplyr::row_number()) %>%
  left_join(cpg_flags,  by = "qid") %>%
  left_join(gene_flags, by = "qid") %>%
  # put useful columns first (your style: dplyr::select)
  dplyr::select(
    chr, start, end, strand,
    qid,
    dplyr::starts_with("is_"),
    gene_part_primary,
    dist_to_TSS,
    dplyr::any_of(c("ENTREZID","SYMBOL","ENSEMBL")),
    dplyr::everything()
  )

readr::write_tsv(out, args$out)

# --------------------- Notes (sources) --------------------------
# CpG context: annotatr::hg38_cpgs (islands/shores/shelves/inter) – disjoint classes.
# Gene models: TxDb.Hsapiens.UCSC.hg38.knownGene (UCSC knownGene; transcript-centric).
# TSS: 1-bp promoters(txdb, 0, 1); nearest computed strand-aware with distanceToNearest().
# ID mapping: org.Hs.eg.db (ENTREZID↔SYMBOL/ENSEMBL).
# Overlap/precedence: booleans may all be TRUE for a locus (e.g., exon & promoter overlap);
#   we report all flags and a primary label using:
#   promoter > exon > intron > 5UTR > 3UTR > intergenic (fixed).

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges); library(GenomeInfoDb)
  library(dplyr); library(tidyr); library(readr)
  library(annotatr)                               # CpG context (hg38_cpgs)
  suppressWarnings(library(genomation))           # hush Biostrings::pattern clash
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)      # gene parts / TSS
  library(AnnotationDbi); library(org.Hs.eg.db)   # ENTREZ ↔ SYMBOL/ENSEMBL
})

# ----- CLI -----
parser <- ArgumentParser(description="Annotate methylKit DB with CpG context, gene parts, TSS, and IDs")
parser$add_argument("--db",  required=TRUE, help="Path to methylKit tabix DB (.txt.bgz)")
parser$add_argument("--out", required=TRUE, help="Output TSV")
parser$add_argument("--prom-up", type="integer", default=2000, help="Promoter upstream bp [2000]")
parser$add_argument("--prom-dn", type="integer", default=500,  help="Promoter downstream bp [500]")
args <- parser$parse_args()

# ----- noise filter for seqinfo ALT/decoy warnings -----
muffle_outofbound <- function(expr) {
  withCallingHandlers(expr, warning=function(w){
    if (grepl("out-of-bound ranges located on sequences", conditionMessage(w)))
      invokeRestart("muffleWarning")
  })
}

# ----- Load loci (STRICT reader) -----
md <- methylKit:::readMethylDB(args$db)
gr <- as(md, "GRanges"); mcols(gr)$qid <- seq_along(gr)

# ----- CpG context (disjoint) -----
ann_cpg <- suppressMessages(build_annotations(genome="hg38", annotations="hg38_cpgs"))

a <- annotate_regions(gr, ann_cpg, ignore.strand=TRUE, quiet=TRUE) |>
  as_tibble() |>
  transmute(q_chr=as.character(seqnames), q_start=start, q_end=end, type=annot.type)

keys <- tibble(q_chr=as.character(seqnames(gr)), q_start=start(gr), q_end=end(gr), qid=mcols(gr)$qid)

cpg_flags <- a |>
  right_join(keys, by=c("q_chr","q_start","q_end")) |>
  group_by(qid) |>
  summarise(
    is_island  = any(type=="hg38_cpg_islands",  na.rm=TRUE),
    is_shore   = any(type=="hg38_cpg_shores",   na.rm=TRUE),
    is_shelf   = any(type=="hg38_cpg_shelves",  na.rm=TRUE),
    is_opensea = any(type=="hg38_cpg_inter",    na.rm=TRUE),
    .groups="drop"
  )

# ----- Gene parts + nearest TSS -----
txdb  <- TxDb.Hsapiens.UCSC.hg38.knownGene
ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names=FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names=FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names=FALSE)
prom  <- promoters(txdb, upstream=args$prom_up, downstream=args$prom_dn)
tsspt <- promoters(txdb, upstream=0, downstream=1)

for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
muffle_outofbound({
  ex    <- keepStandardChromosomes(ex,   pruning.mode="coarse")
  intr  <- keepStandardChromosomes(intr, pruning.mode="coarse")
  utr5  <- keepStandardChromosomes(utr5, pruning.mode="coarse")
  utr3  <- keepStandardChromosomes(utr3, pruning.mode="coarse")
  prom  <- keepStandardChromosomes(prom, pruning.mode="coarse")
  tsspt <- keepStandardChromosomes(tsspt,pruning.mode="coarse")

  wanted <- intersect(seqlevels(gr), seqlevels(ex))
  ex    <- keepSeqlevels(ex,    wanted, pruning.mode="coarse")
  intr  <- keepSeqlevels(intr,  wanted, pruning.mode="coarse")
  utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode="coarse")
  utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode="coarse")
  prom  <- keepSeqlevels(prom,  wanted, pruning.mode="coarse")
  tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode="coarse")
})

is_prom     <- countOverlaps(gr, prom) > 0L
is_5utr     <- countOverlaps(gr, utr5) > 0L
is_3utr     <- countOverlaps(gr, utr3) > 0L
is_exon_raw <- countOverlaps(gr, ex)   > 0L
is_exon     <- is_exon_raw & !is_5utr & !is_3utr   # UTR ⊂ exon → exclude
is_intron   <- countOverlaps(gr, intr) > 0L

# Corrected precedence: promoter > 5UTR > 3UTR > exon > intron > intergenic
gene_part_primary <- ifelse(is_prom, "promoter",
                        ifelse(is_5utr, "5UTR",
                        ifelse(is_3utr, "3UTR",
                        ifelse(is_exon, "exon",
                        ifelse(is_intron, "intron", "intergenic")))))

# nearest TSS (strand-aware)
nn <- distanceToNearest(gr, tsspt, ignore.strand=FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# TSS -> TXID -> ENTREZID -> SYMBOL/ENSEMBL
tx_for_tss <- mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)]
tx_map <- suppressMessages(AnnotationDbi::select(
  x=txdb, keys=as.character(tx_for_tss),
  keytype="TXID", columns=c("TXID","GENEID")
))

tss2tx <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  TXID    = as.character(mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)])
) |>
  left_join(tx_map, by="TXID") |>
  distinct(tss_idx, .keep_all=TRUE) |>
  rename(ENTREZID = GENEID)

gene_map <- suppressMessages(AnnotationDbi::select(
  org.Hs.eg.db,
  keys    = unique(na.omit(tss2tx$ENTREZID)),
  keytype = "ENTREZID",
  columns = c("SYMBOL","ENSEMBL")
)) |>
  distinct(ENTREZID, .keep_all=TRUE)

tss2tx <- tss2tx |> left_join(gene_map, by="ENTREZID")

dist_tbl <- dist_tbl |>
  left_join(tss2tx |> dplyr::select(tss_idx, ENTREZID, SYMBOL, ENSEMBL), by="tss_idx") |>
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  is_exon     = is_exon,
  is_intron   = is_intron,
  gene_part_primary = gene_part_primary
) |>
  left_join(dist_tbl, by="qid")

# ----- Assemble; DROP coverage/numC/numT -----
raw_dt <- as_tibble(getData(md))

out <- raw_dt |>
  mutate(qid = dplyr::row_number()) |>
  left_join(cpg_flags,  by="qid") |>
  left_join(gene_flags, by="qid") |>
  dplyr::select(
    chr, start, end, strand, qid,
    dplyr::starts_with("is_"),
    gene_part_primary, dist_to_TSS,
    ENTREZID, SYMBOL, ENSEMBL,
    dplyr::everything(),
    -dplyr::matches("^(coverage|numCs?|numTs?)\\d*$", ignore.case=TRUE)
  )

readr::write_tsv(out, args$out)
#+end_src

*** Biscuit
**** Index
#+begin_src snakemake
rule emseq_biscuit_index:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        lambda wildcards: f"{data_dir}/inputs/{config['emseq_ref_assemblies'][wildcards.name]['input']}"
    output:
        fasta = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa",
        fai = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.fai",
        biscuit_index_done = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.biscuit.index.done"
    log:
        f"{config['log-dir']}/{{name}}_biscuit_index.log"
    shell:
        """
        mkdir -p $(dirname {output.fasta}) && \
        zcat {input} > {output.fasta} && \
        samtools faidx {output.fasta} && \
        biscuit index {output.fasta} > {log} 2>&1 && \
        touch {output.biscuit_index_done}
        """

#+end_src

**** Align
#+begin_src snakemake
rule emseq_align_biscuit:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        r1 = f"{data_dir}/analysis/emseq/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2 = f"{data_dir}/analysis/emseq/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        fasta = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa",
        index = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa.par.sa",
    log:
        cmd = f"{config['log-dir']}/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
    output:
        bam = f"{config['emseq-dir']}/bams/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
    params:
        threads = 80,
    resources:
        concurrency=100
    shell:
        """
        mkdir -p {data_dir}/tmp && \
        biscuit align \
        -@ {params.threads} \
        -biscuit-ref {input.fasta} \
        {input.r1} {input.r2} \
        | samtools sort \
        -@ 8 \
        -m 2G \
        -T {data_dir}/tmp/{wildcards.library_id}_sorttmp \
        -o {output.bam} &>> {log}
        """

#+end_src
**** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
**** Pileup
#+begin_src snakemake
rule emseq_biscuit_pileup:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        bam = f"{config['emseq-dir']}/bams/{{library_id}}.{{ref_name}}.biscuit.coorsort.deduped.bam",
        fasta = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}.biscuit_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf",
    shell:
        """
        biscuit pileup \
        -@ 20 \
        -o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
#+begin_src snakemake
rule emseq_biscuit_post_pileup:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf.gz",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}_emseq_biscuit_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input.vcf} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark} &> {log}
        """
#+end_src

#+begin_src snakemake
rule make_single_biscuit_methylkit_obj:
    conda:
        "../config/methylkit-conda-env.yaml",
    input:
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_bismark_cov.bed",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}_make_single_biscuit_methylkit_obj.log",
    output:
        txt = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt",
        bgz = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt.bgz",
        tbi = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt.bgz.tbi",
    params:
        Rscript = f"{config['emseq-script-dir']}/make_single_biscuit_methylkit_obj.R",
        out_dir = f"{data_dir}/analysis/emseq/post-biscuit",
    shell:
        """
        Rscript {params.Rscript} \
          --bismark_cov_bed {input.bismark} \
          --library_id {wildcards.library_id} \
          --out_dir {params.out_dir} \
          &> {log}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_biscuit_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--bismark_cov_bed", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

myobj= methRead(args$bismark_cov_bed,
                sample.id = args$library_id,
                treatment = 1,
                context="CpG",
                pipeline="bismarkCoverage",
                mincov = 2,
                assembly= "hg38",
                dbtype = "tabix",
                dbdir = args$out_dir)

#+end_src



*** variant calling
- https:/pmc.ncbi.nlm.nih.gov/articles/PMC10072131/
