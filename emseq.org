* Enzymatic Methylation Sequencing Bioinformatics Processes
:PROPERTIES:
:ID:       cd9489fd-c6e7-4c64-8317-e3d9a283b36c
:END:
** [[id:bda70cff-0713-4e32-8da1-ee83924b8f00][README]]
** [[elisp:(let ((window-config (current-window-configuration))) (async-shell-command "bash ~/repos/mpnst/tools/shell/org_update.sh") (set-window-configuration window-config))][org update]]
** Repository setup and administration
*** Org update
#+begin_src bash :tangle ./tools/shell/org_update.sh
#!/usr/bin/env bash
set -euo pipefail

source ~/repos/basecamp/lib/basecamp_functions.sh

REPOS=(emseq)

# ---------- config ----------
REPO_DIR=~/repos/emseq
README_ORG="$REPO_DIR/emseq.org"
README_NODE=bda70cff-0713-4e32-8da1-ee83924b8f00
README_EXPORT=~/repos/emacs/scripts/emacs_export_header_to_markdown.py
# ----------------------------

save_in_emacs() {
  if command -v emacsclient >/dev/null 2>&1 && emacsclient -e "(progn t)" >/dev/null 2>&1; then
    emacsclient -e "(save-some-buffers t)" >/dev/null
    echo "ðŸ’¾ saved buffers via emacsclient"
  else
    echo "â„¹ï¸ no Emacs server; skipping save"
  fi
}

update_readme() {
  echo "ðŸ“ exporting README.md from $README_ORG"
  pushd "$REPO_DIR" >/dev/null
  python3 "$README_EXPORT" --org_file "$README_ORG" --node_id "$README_NODE"
  popd >/dev/null
}

tangle_repo_org() {
  local repo=$1
  local org_file=~/repos/"$repo"/"$repo".org

  echo "=== $repo ==="
  if [[ -f "$org_file" ]]; then
    echo "â³ tangling $repo..."
    tangle "$org_file" || { echo "âŒ tangle failed for $repo"; return 1; }
  else
    echo "âš ï¸  no $repo.org, skipping"
  fi
}

git_update_repo() {
  local repo=$1
  echo "ðŸ”„ updating $repo..."
  pushd ~/repos/"$repo" >/dev/null || { echo "âŒ cd failed for $repo"; return 1; }

  if ! output=$(git_wkflow_up 2>&1); then
    echo "âŒ git_wkflow_up failed in $repo"
    echo "$output"
  else
    echo -e "$(date)\n$output"
  fi

  popd >/dev/null
}

main() {
  save_in_emacs

  for repo in "${REPOS[@]}"; do
    tangle_repo_org "$repo" || true
  done

  update_readme
  save_in_emacs

  for repo in "${REPOS[@]}"; do
    git_update_repo "$repo" || true
  done
}

main "$@"
#+end_src

*** Tool to get in-repo test data
#+begin_src bash :tangle ./tools/get_test_data.sh
#!/usr/bin/env bash
# setup_test_data.sh â€” chr22 subset + lambda + pUC19 FASTA, plus 4 tiny paired WGBS FASTQs
# Paired-only; hard-fails if a run lacks _1/_2. Cleans tests/full/ before writing.
set -euo pipefail

# --- self-locate & cd to repo root (script is assumed to live one level below root, e.g., tools/) ---
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_DIR="$(dirname "$SCRIPT_DIR")"
cd "$REPO_DIR" || { echo "ERR: failed to cd to repo root: $REPO_DIR" >&2; exit 1; }

# --- config ---
R_EMSEQ="${R_EMSEQ:-$PWD}"
TEST_DIR="${R_EMSEQ}/tests/full"
OUT_DIR="${TEST_DIR}/inputs"
OUT_FA="${OUT_DIR}/chr22.test.fa.gz"
OUT_LAMBDA="${OUT_DIR}/lambda.fa.gz"
OUT_PUC19="${OUT_DIR}/pUC19.fa.gz"
OUT_BLK="${OUT_DIR}/hg38-blacklist.v2.bed.gz"

# NEW: bed outputs
KEEP_BED="${OUT_DIR}/chr22.keep.bed"
EXCL_BED="${OUT_DIR}/chr22.exclude.blacklist.bed.gz"

REF_URL="https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/chr22.fa.gz"
FA_HEAD_LINES=4000000

# full (small) references
LAMBDA_URL="https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id=9626243&db=nuccore&report=fasta&retmode=text"

# pUC19 via NCBI efetch (hard-coded tool/email)
PUC19_EFETCH="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=L09137.2&rettype=fasta&retmode=text&tool=emseq_setup&email=anon@example.com"

BLK_URL="https://raw.githubusercontent.com/Boyle-Lab/Blacklist/master/lists/hg38-blacklist.v2.bed.gz"

NREADS="${NREADS:-60000}"   # reads per mate for FASTQ clipping
FQ_HEAD_LINES=$((NREADS * 4))

# ENA WGBS runs (paired) â€” adjust as needed
ACCESSIONS=( "ERR022484" "ERR022487" "ERR022003" "ERR022483" )

# --- deps ---
need(){ command -v "$1" >/dev/null 2>&1 || { echo "Missing: $1" >&2; exit 1; }; }
need git; need wget; need curl; need zcat; need gzip; need wc; need head; need grep; need sed
# NEW: for beds
need samtools; need bedtools; need bgzip; need tabix; need awk; need sort; need cut

# --- ensure .gitignore rules: ignore tests/full/* but NOT tests/full/inputs/** ---
ensure_gitignore() {
  local gi="${REPO_DIR}/.gitignore"
  local req1='tests/full/*'
  local req2='!tests/full/inputs/'
  local req3='!tests/full/inputs/**'
  touch "$gi"
  local have1=0 have2=0 have3=0
  grep -Fxq "$req1" "$gi" && have1=1 || true
  grep -Fxq "$req2" "$gi" && have2=1 || true
  grep -Fxq "$req3" "$gi" && have3=1 || true
  if (( ! have1 || ! have2 || ! have3 )); then
    {
      echo ''
      echo '# --- test data (auto-managed by setup_test_data.sh) ---'
      (( have1 )) || echo "$req1"
      (( have2 )) || echo "$req2"
      (( have3 )) || echo "$req3"
    } >> "$gi"
    echo "[gitignore] ensured patterns for tests/full with inputs preserved"
  fi
}

# ENA dir that contains both _1/_2
ena_dir_for() {
  local acc="$1" first6="${acc:0:6}" last3="${acc: -3}"
  local candidates=(
    "https://ftp.sra.ebi.ac.uk/vol1/fastq/${first6}/${acc}/"
    "https://ftp.sra.ebi.ac.uk/vol1/fastq/${first6}/${last3}/${acc}/"
  )
  for d in "${candidates[@]}"; do
    if wget -q --spider "${d}${acc}_1.fastq.gz" && wget -q --spider "${d}${acc}_2.fastq.gz"; then
      echo "$d"; return 0
    fi
  done
  return 1
}

# wget stream â†’ zcat â†’ head â†’ gzip (silence SIGPIPE noise)
fetch_head() {
  ( set +o pipefail
    wget -qO- "$1" | zcat 2>/dev/null | head -n "$2" | gzip > "$3"
  ) || true
}

# download full compressed file (blacklist)
fetch_all_gz() { wget -qO "$2" "$1"; }

# --- add near fetch_puc19() ---
fetch_plain_fasta_gzip() {
  local url out tmp
  url="$1"
  out="$2"
  tmp="${out%.gz}.tmp"
  rm -f "$tmp" "$out"
  curl -fsSL "$url" -o "$tmp"
  [[ -s "$tmp" ]] || { echo "ERR: lambda fetch produced empty file"; exit 1; }
  head -n1 "$tmp" | grep -q '^>' || { echo "ERR: lambda FASTA header missing"; exit 1; }
  gzip -f "$tmp"
  mv "${tmp}.gz" "$out"
}

# robust pUC19: fetch plain FASTA to tmp with curl, validate header, then gzip
fetch_puc19() {
  local url out tmp
  url="$1"; out="$2"; tmp="${out%.gz}.tmp"
  rm -f "$tmp" "$out"
  curl -fsSL "$url" -o "$tmp"
  [[ -s "$tmp" ]] || { echo "ERR: pUC19 fetch produced empty file"; exit 1; }
  head -n1 "$tmp" | grep -q '^>' || { echo "ERR: pUC19 FASTA header missing"; exit 1; }
  gzip -f "$tmp"
  mv "${tmp}.gz" "$out"
}

check_fastq() {
  local f="$1"
  [[ -s "$f" ]] || { echo "ERR: empty $f" >&2; return 1; }
  local n; n=$(zcat "$f" 2>/dev/null | wc -l)
  (( n % 4 == 0 )) || echo "WARN: $f has $n lines (not multiple of 4)"
  echo "[ok] $(basename "$f"): $(( n / 4 )) reads"
}

# --- run ---
ensure_gitignore

echo "[clean] removing ${TEST_DIR}"
rm -rf "${TEST_DIR}"
mkdir -p "${OUT_DIR}"

# keep inputs dir tracked even if empty (optional helper file)
[[ -e "${OUT_DIR}/.gitkeep" ]] || : > "${OUT_DIR}/.gitkeep"

echo "[ref] chr22 subset â†’ ${OUT_FA}"
fetch_head "${REF_URL}" "${FA_HEAD_LINES}" "${OUT_FA}"
[[ -s "${OUT_FA}" ]] || { echo "ERR: failed to write ${OUT_FA}"; exit 1; }

echo "[ref] lambda (full) â†’ ${OUT_LAMBDA}"
fetch_plain_fasta_gzip "${LAMBDA_URL}" "${OUT_LAMBDA}"
[[ -s "${OUT_LAMBDA}" ]] || { echo "ERR: failed to write ${OUT_LAMBDA}"; exit 1; }

echo "[ref] pUC19 (NCBI efetch) â†’ ${OUT_PUC19}"
fetch_puc19 "${PUC19_EFETCH}" "${OUT_PUC19}"
[[ -s "${OUT_PUC19}" ]] || { echo "ERR: failed to write ${OUT_PUC19}"; exit 1; }

echo "[ref] hg38 blacklist â†’ ${OUT_BLK}"
fetch_all_gz "${BLK_URL}" "${OUT_BLK}"
[[ -s "${OUT_BLK}" ]] || { echo "ERR: failed to write ${OUT_BLK}"; exit 1; }


# --- tiny paired FASTQs ---
i=1
for acc in "${ACCESSIONS[@]}"; do
  dir="$(ena_dir_for "$acc")" || { echo "ERR: ${acc} is not paired on ENA" >&2; exit 1; }
  r1="${dir}${acc}_1.fastq.gz"
  r2="${dir}${acc}_2.fastq.gz"

  id=$(printf "lib%03d" "$i")
  out1="${OUT_DIR}/${id}.raw_R1.fastq.gz"
  out2="${OUT_DIR}/${id}.raw_R2.fastq.gz"
  echo "[fq] ${id} (${acc}) â†’ ${out1}, ${out2}"

  fetch_head "$r1" "${FQ_HEAD_LINES}" "$out1"
  fetch_head "$r2" "${FQ_HEAD_LINES}" "$out2"
  check_fastq "$out1"
  check_fastq "$out2"
  i=$((i+1))
done

# --- NEW: build keep/exclude BEDs in inputs/ from chr22.test.fa.gz + blacklist ---
echo "[beds] building keep/exclude from ${OUT_FA}"
FA_UNGZ="${OUT_DIR}/chr22.test.fa"
zcat "${OUT_FA}" > "${FA_UNGZ}"
samtools faidx "${FA_UNGZ}"

# KEEP: spans for all contigs present in the .fai (chr22-only here)
awk 'BEGIN{OFS="\t"} {print $1,0,$2}' "${FA_UNGZ}.fai" \
  | sort -k1,1 -k2,2n > "${KEEP_BED}" |

# EXCLUDE: clip blacklist to contigs present in .fai and bgzip
awk 'NR==FNR{ok[$1]=1; next} ok[$1]' <(cut -f1 "${FA_UNGZ}.fai") <(zcat "${OUT_BLK}") \
  | sort -k1,1 -k2,2n | bgzip > "${EXCL_BED}" |
tabix -p bed "${EXCL_BED}" || true
echo "[beds] keep=${KEEP_BED}  exclude=${EXCL_BED}"

echo "Done. Outputs in: ${OUT_DIR}"
echo "  - FASTA subset: ${OUT_FA} (+ ${FA_UNGZ} + .fai)"
echo "  - Keep BED:     ${KEEP_BED}"
echo "  - Exclude BED:  ${EXCL_BED}"
#+end_src
See [[id:93585550-c78e-45e1-8adc-92b4efbebbae][Generate test data test]]
*** README
:PROPERTIES:
:ID:       bda70cff-0713-4e32-8da1-ee83924b8f00
:export_file_name: README
:END:

The EM-seq repository contains modular workflows intended to be run from within a over-wrapping snakemake workflow.

[[file:resources/test_smk.png]]
**** Utilities                                                     :noexport:
[[file:README.md]]
#+begin_src bash
python3 ~/repos/emacs/scripts/emacs_export_header_to_markdown.py --org_file ~/repos/emseq/emseq.org --node_id bda70cff-0713-4e32-8da1-ee83924b8f00

#+end_src

**** Continuous Integration

#+begin_export md

[![test-data](https://img.shields.io/github/actions/workflow/status/jeszyman/emseq/test-data.yaml?branch=master&label=test-data)](https://github.com/jeszyman/emseq/actions/workflows/test-data.yaml)


[![smk-dry](https://img.shields.io/github/actions/workflow/status/jeszyman/emseq/smk-dry.yaml?branch=master&label=smk-dry)](https://github.com/jeszyman/emseq/actions/workflows/smk-dry.yaml)

[![smk-run](https://img.shields.io/github/actions/workflow/status/jeszyman/emseq/smk-run.yaml?branch=master&label=smk-run)](https://github.com/jeszyman/emseq/actions/workflows/smk-run.yaml)

#+end_export
**** Change Log
- Development since last tag
  - [ ] Added a full run CI test
- wf/emseq/v4.0.0
  - Minor testing updates
  - Fixed test.yaml file locations
  - Changed bam filtering step to remove duplicates marked by dupsifter. So rule emseq_dedup MARKS duplicates while rule emseq_filter_bam removes them as part of `samtools view -@ {threads} -u -f 2 -q 30 -F 3840 "{input.bam}`
  - Changed mosdepth to take filtered bam and quantify by keep.bed, ignoring filtered regions in depth calculation.
  - Conforms to [[https://github.com/jeszyman/basecamp/blob/v1.3.0/docs/snakemake-style-guide.md][v1.3 snakemake style guide]]
- wf/emseq/v3.1.0
  - [2025-09-19 Fri] Added a first github workflow test
  - [2025-09-19 Fri] Robust annotation of methylkit outputs validated as rscript
  - [2025-09-19 Fri] Added mature github tests for building in-repo test data and smk_dry
- [2025-09-19 Fri] Updated EM-seq main pipeline to wf/emseq/v3.0.0.
  - Includes in-repo small test data for a complete run of emseq.smk
  - Includes test.smk wrapper and corresponding test.yaml for in-repo small test run
  - emseq.smk expanded to include differential methylation from nested list map
  - Many small fixes for consistent naming and run condition optimization
- [2025-09-18 Thu] Updated EM-seq main pipeline to wf/emseq/v2.0.0. Mainly improved and simplified variable naming.
*** GitHub tests
**** Generate test data test
:PROPERTIES:
:ID:       93585550-c78e-45e1-8adc-92b4efbebbae
:END:

#+begin_src yaml :tangle ./.github/workflows/test-data.yaml
name: test-data

on:
  pull_request:
    paths:
      - "tools/get_test_data.sh"
      - "tests/**"
      - "config/emseq-conda-env.yaml"
      - ".github/workflows/test-data.yml"
  schedule:
    - cron: "0 4 * * 1"
  workflow_dispatch: {}

concurrency:
  group: test-data-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

defaults:
  run:
    shell: bash -l {0}   # login shell so conda works

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Verify env file exists
        run: |
          set -euo pipefail
          ls -lah
          ls -lah config || true
          test -f config/emseq-conda-env.yaml || { echo "Missing: config/emseq-conda-env.yaml"; exit 1; }
          sed -n '1,40p' config/emseq-conda-env.yaml

      - name: Setup Conda (Miniforge3)
        uses: conda-incubator/setup-miniconda@v3
        with:
          miniforge-variant: Miniforge3
          auto-activate-base: true
          use-mamba: true

      - name: Configure channels (strict)
        run: |
          set -euo pipefail
          conda config --set channel_priority strict
          # Ensure channels order matches your YAML
          conda config --remove-key channels || true
          conda config --add channels conda-forge
          conda config --add channels bioconda
          conda config --show
          conda info -a

      - name: Create/Update env (mamba, then conda fallback)
        run: |
          set -euo pipefail
          # if exists, update; else create
          if conda env list | awk '{print $1}' | grep -qx emseq; then
            echo "Updating existing env 'emseq'..."
            mamba env update -n emseq -f config/emseq-conda-env.yaml -vv || \
              conda env update -n emseq -f config/emseq-conda-env.yaml -vv
          else
            echo "Creating env 'emseq'..."
            mamba env create -n emseq -f config/emseq-conda-env.yaml -vv || \
              conda env create -n emseq -f config/emseq-conda-env.yaml -vv
          fi
          conda env list
          conda run -n emseq python -V || true
          conda run -n emseq samtools --version || true

      - name: Execute script + sanity checks (inside env)
        run: |
          set -euo pipefail
          conda activate emseq
          which samtools
          samtools --version
          chmod +x tools/get_test_data.sh
          ./tools/get_test_data.sh

          # Checks
          test -d tests/full || (echo "tests/full not created" >&2; exit 1)
          fq_count=$(find tests/full -type f -name "*fastq.gz" | wc -l)
          (( fq_count >= 4 )) || { echo "Expected â‰¥4 FASTQs, got ${fq_count}"; exit 1; }
          fasta_count=$(find tests/full -type f \( -name "*chr22*.fa*" -o -name "*lambda*.fa*" -o -name "*pUC19*.fa*" \) | wc -l)
          (( fasta_count >= 1 )) || { echo "Expected â‰¥1 reference FASTA"; exit 1; }
          echo "OK: test data present."
#+end_src
**** Dry run test
#+begin_src yaml :tangle ./.github/workflows/smk-dry.yaml
name: smk-dry

on:
  pull_request:
    paths:
      - "workflows/**"
      - "config/**"
      - "scripts/**"
      - ".github/workflows/ci-snakemake.yml"
  schedule:
    - cron: "0 4 * * 1"
  workflow_dispatch: {}

concurrency:
  group: ci-snakemake-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  smoke:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    steps:
      - uses: actions/checkout@v4

      # Install micromamba for fast, reliable environment management
      - name: Set up micromamba
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-file: config/emseq-conda-env.yaml
          environment-name: emseq
          cache-environment: true

      - name: Verify required files
        run: |
          set -euo pipefail
          test -f config/emseq-conda-env.yaml
          test -f workflows/test.smk
          test -f config/test.yaml

      - name: Show environment info
        run: |
          micromamba info
          micromamba list -n emseq
          micromamba run -n emseq python -V
          micromamba run -n emseq snakemake --version
          micromamba run -n emseq samtools --version || true

      - name: Snakemake dry-run
        run: |
          micromamba run -n emseq snakemake \
          -s workflows/test.smk \
          --configfile config/test.yaml \
          --cores 4 \
          --dry-run \
          --printshellcmds \
          --rerun-incomplete \
          --resources concurrency=50

#+end_src

**** Full test run
#+begin_src yaml :tangle ./.github/workflows/smk-run.yaml
name: smk-run
on:
  pull_request:
    paths:
      - "workflows/**"
      - "config/**"
      - "scripts/**"
      - ".github/workflows/smk-run.yaml"
  schedule:
    - cron: "0 5 * * 1"
  workflow_dispatch: {}
concurrency:
  group: smk-run-${{ github.ref }}
  cancel-in-progress: true
permissions:
  contents: read
jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v4
      - name: Set up micromamba
        uses: mamba-org/setup-micromamba@v1
        with:
          environment-file: config/emseq-conda-env.yaml
          environment-name: emseq
          cache-environment: true
      - name: Verify required files
        run: |
          set -euo pipefail
          test -f config/emseq-conda-env.yaml
          test -f workflows/test.smk
          test -f config/test.yaml
      - name: Snakemake run
        run: |
          micromamba run -n emseq snakemake \
            -s workflows/test.smk \
            --configfile config/test.yaml \
            --cores 4 \
            --printshellcmds \
            --rerun-incomplete \
            --use-conda \
            --resources concurrency=50
#+end_src

** Conda environmental YAMLs
*** EM-seq
#+begin_src yaml :tangle ./config/emseq-conda-env.yaml
name: emseq
channels:
  - conda-forge
  - bioconda

dependencies:
  - fastp
  - fastqc
  - bedtools
  - samtools
  - bioconductor-genomeinfodbdata=1.2.7
  - bismark
  - bwa
  - bwameth
  - methyldackel
  - mosdepth
  - multiqc
  - r-argparse
  - r-data.table
  - r-ggplot2
  - r-cairo
  - r-scales
  - r-patchwork
  - r-matrixstats
  - biscuit=1.7.1.20250908
  - dupsifter=1.3.0.20241113
  - libdeflate=1.22
  - bedtools
  - snakemake
#+end_src
*** MethylKit
#+begin_src yaml :tangle ./config/methylkit-conda-env.yaml
name: methylkit
channels:
  - conda-forge
  - bioconda

dependencies:
  - htslib
  - r-argparse
  - bioconductor-methylkit
  - r-data.table=1.15.4
  - r-tidyverse
  - bioconductor-genomicranges
  - bioconductor-annotatr
  - bioconductor-txdb.hsapiens.ucsc.hg38.knowngene
  - bioconductor-org.hs.eg.db
  - bioconductor-genomation
  - r-arrow
#+end_src
*** Mosdepth
#+begin_src yaml :tangle ./config/mosdepth-conda-env.yaml
name: mosdepth
channels:
  - conda-forge
  - bioconda

dependencies:
  - samtools
  - bioconductor-genomeinfodbdata=1.2.7
  - mosdepth
  - r-argparse
  - r-data.table
  - r-ggplot2
  - r-cairo
  - jpeg
  - r-scales
  - r-patchwork
  - r-matrixstats
  - r-r.utils
#+end_src

** Methylation sequence processing
:PROPERTIES:
:ID:       92e64b67-c219-4146-a89b-a8710d91a634
:header-args:snakemake: :tangle ./workflows/emseq.smk
:END:
- https://chatgpt.com/c/69161244-a164-832f-9b06-598bd9ae3556

[[file:workflows/emseq.smk]]
[[file:resources/test_smk.png]]
#+begin_src python :results output replace
import re
from pathlib import Path

snakefile = Path("./workflows/emseq.smk").read_text()

# Matches: config["..."] or config['...']
matches = re.findall(r"config\[['\"]([^'\"]+)['\"]\]", snakefile)

# Deduplicate and sort
unique_keys = sorted(set(matches))

print("Config keys required:")
for key in unique_keys:
    print(f"- {key}")

#+end_src

#+RESULTS:
: Config keys required:
: - emseq_ref_assemblies


The BWA-meth and biscuit workflows requires a reference gzipped fasta in $data_dir/inputs, specified in the config yaml like:
#+begin_src yaml
emseq_ref_assemblies:
  ensembl_hg38:
    url: https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
    name: ensembl_hg38
    input: Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
#+end_src

This will be indexed and used for alignment.

*** Writeup

- Sample preparation and sequencing.
  Cell-free DNA was extracted and prepared using the NEBNextÂ® Enzymatic Methyl-seq (EM-seq) Kit following the manufacturer's protocol. Libraries were sequenced on an Illumina platform using paired-end 150 bp reads.

- Sequencing read pre-processing and quality control.
  Raw sequencing reads were processed with fastp using default parameters, with adapter detection enabled and quality filtering disabled. FastQC was used to assess read quality before and after trimming.

- Alignment and de-duplication.
  Reads were aligned to reference genome(s) using BWA-meth with default parameters. Resulting BAMs were coordinate-sorted and deduplicated using dupsifter (https://github.com/brentp/dupsifter), which performs read name-aware de-duplication optimized for bisulfite-style alignments. Only properly paired reads (SAM flag 0x2) were retained prior to deduplication.

- Methylation calling.
  Methylation calls were made on deduplicated BAMs using MethylDackel (v0.6.1), with CpG-context methylation extracted in methylKit-compatible format (--methylKit). Calls were further processed using methylKit (v1.22.0) for filtering, tabix compression, and downstream differential methylation analysis. For each sample, methylation calls were filtered using a minimum coverage threshold of 10Ã—.

- Quality Control
  - Depth estimation.
    Coverage profiles were generated using mosdepth (v0.3.3) on deduplicated BAMs. Runs were performed in fast mode with 1 kb windows and median depth calculation enabled. Per-sample coverage threshold summaries and quantization tracks were generated and aggregated using a custom R script, which also calculated autosomal median depth and generated multi-panel PDF plots showing coverage distribution across user-defined thresholds.

  - Spike-in controls and conversion rate estimation.
    Each EM-seq library included unmethylated Lambda and fully methylated CpG pUC19 spike-ins. Reads were aligned to spike-in references using BWA-meth, and methylation levels were quantified using MethylDackel. Conversion efficiency was estimated from Lambda (expected methylation <1%), and methylation completeness from pUC19 (expected >90% CpG methylation) [@vaisvila2021; @chauhan2024; @emseq2023manual].

  - M-bias detection.
    To detect potential position-dependent biases in methylation calls, MethylDackel's mbias mode was used on deduplicated BAMs. Reads were assessed for strand-specific methylation bias across read positions, and results were reviewed to ensure negligible systematic error.

- Pipeline orchestration.
  All steps were executed using a reproducible Snakemake (v7.x) workflow with conda-based environment isolation. Logging was performed at each rule level, and intermediate files were tracked and retained as needed.

*** Preamble
#+begin_src snakemake
############################
###   EM-Seq Snakefile   ###
############################

#########1#########2#########3#########4#########5#########6#########7#########8
#
# A snakefile for basic processing of EM-seq sequencing data
#+end_src

*** Spike workflow

The EM-seq kit includes two control DNA spike-ins, unmethylated Lambda and CpG methylated pUC19.

"Regardless of sequencing depth, a minimum of 5,000 paired end reads with a read length of 76 bases, for unmethylated Lambda DNA, and 500 paired end reads with a read length of 76 bases, for CpG methylated pUC19, are needed to give enough coverage for accurate conversion estimates." [cite:@emseq2023manual].

We expect Lambda methylation rates below 1% as shown in [cite:@vaisvila2021]

and we expect above 90% methylation of exclusively CpG sites for pUC19

#+CAPTION: vaisvila2021figs7c.png
#+NAME: fig:vaisvila2021fig7c
#+ATTR_ORG: :width 800
[[file:./resources/vaisvila2021figs7c.png]]

The spike workflow uses bwa-meth to quickly align to phage reference genomes. Coordinate-sorted BAM output is limited to only reads matching the phage index (-F 4). CpG methylation is called in methyldackel, allowing duplicates,

- [cite:@vaisvila2021]
- [cite:@chauhan2024]
- [cite:@emseq2023manual]

**** Align
#+begin_src snakemake
rule emseq_align_bwameth_spike:
    message: "EM-seq bwameth on spike-in reference with simple samtools piping and no duplicate calls"
    conda: ENV_EMSEQ
    input:
        r1  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        ref = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth_spike.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth_spike.tsv"
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}"
    threads: 48
    resources:
        concurrency = 50
    output:
        bam = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.bwa_meth.coorsort.bam",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[bwameth-spike] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} threads={threads}"
        bwameth.py --threads {threads} \
          --reference "{input.ref}" \
          "{input.r1}" "{input.r2}" \
        | samtools view -@ 8 -u -F 4 - \
        | samtools sort -@ 8 -T "{params.temp_prefix}" -o "{output.bam}"
        """
#+end_src

**** Call methylation
#+begin_src snakemake
rule emseq_methyldackel_spike:
    message: "MethylDackel CpG extraction on spike-in alignments, allowing duplicates"
    conda: ENV_EMSEQ
    input:
        bam   = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.bam",
        fasta = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel_spike.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel_spike.tsv"
    params:
        out_prefix = lambda wc, input, output: output.bed.rsplit("_CpG.methylKit", 1)[0]
    threads: 8
    output:
        bed = f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methyldackel-spike] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        mkdir -p "$(dirname "{params.out_prefix}")"
        MethylDackel extract \
          -@ {threads} \
          --methylKit \
          "{input.fasta}" \
          "{input.bam}" \
          -o "{params.out_prefix}"
        """
#+end_src

*** BWA-Meth

BWA-meth alignment is much faster than biscuit.

BWA-meth output is a duplicated, coordinate sorted BAM. This is de-duplicated during methylation calls by methyldackel.

Reference
- https:/github.com/brentp/bwa-meth

**** Index

#+begin_src snakemake
rule emseq_bwa_meth_index:
    message: "Build bwa-meth bisulfite index from reference FASTA"
    conda: ENV_EMSEQ
    input:
        lambda wc: f"{D_INPUTS}/{EMSEQ_REF_INPUTS[wc.emseq_ref_name]}"
    log:
        cmd = f"{D_LOGS}/{{emseq_ref_name}}_emseq_bwa_meth_index.log",
    benchmark:
        f"{D_BENCHMARK}/{{emseq_ref_name}}_emseq_bwa_meth_index.tsv"
    params:
        fasta_target = lambda wc: f"{D_REF}/bwa_meth/{wc.emseq_ref_name}/{wc.emseq_ref_name}.fa"
    threads: 1
    output:
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.0123",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.amb",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.ann",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.bwt.2bit.64",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t.pac",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[bwa-meth-index] $(date) ref={wildcards.emseq_ref_name} threads={threads}"
        if file -b "{input}" | grep -qi gzip; then
            zcat "{input}" > "{params.fasta_target}"
        else
            cat "{input}" > "{params.fasta_target}"
        fi
        samtools faidx "{params.fasta_target}"
        bwameth.py index-mem2 "{params.fasta_target}"
        """
#+end_src

**** Align

#+begin_src snakemake
rule emseq_align_bwameth:
    message: "BWA-meth bisulfite alignment to human reference with coordinate-sorted BAM output"
    conda: ENV_EMSEQ
    input:
        r1  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2  = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        ref = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        c2t = f"{D_REF}/bwa_meth/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.bwameth.c2t",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}_emseq_align_bwameth.tsv"
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}",
    threads: min(workflow.cores, 48)
    resources:
        concurrency = 50,
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.bwa_meth.coorsort.bam",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[bwameth] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} threads={threads}"
        mkdir -p "$(dirname "{params.temp_prefix}")"
        bwameth.py --threads {threads} \
          --reference "{input.ref}" \
          "{input.r1}" "{input.r2}" \
        | samtools view -u - \
        | samtools sort -@ 8 -T "{params.temp_prefix}" -o "{output.bam}"
        """
#+end_src

**** Post-align
***** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
***** [[id:6a1d8806-5649-42e9-977d-c681a3106784][Filter]]
***** [[id:e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c][Call methylation]]
*** Biscuit
**** Index
#+begin_src snakemake
rule emseq_biscuit_index:
    message: "Build BISCUIT bisulfite index from reference FASTA"
    conda: ENV_EMSEQ
    input:
        lambda wc: f"{D_INPUTS}/{EMSEQ_REF_INPUTS[wc.emseq_ref_name]}"
    log:
        cmd = f"{D_LOGS}/{{emseq_ref_name}}_emseq_biscuit_index.log"
    benchmark:
        f"{D_BENCHMARK}/{{emseq_ref_name}}_emseq_biscuit_index.tsv"
    threads: 1
    output:
        fasta = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        fai = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",
        index = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.par.sa",
        biscuit_index_done = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.biscuit.index.done"
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[biscuit-index] $(date) ref={wildcards.emseq_ref_name} threads={threads}"
        mkdir -p "$(dirname "{output.fasta}")"
        zcat "{input}" > "{output.fasta}"
        samtools faidx "{output.fasta}"
        biscuit index "{output.fasta}"
        touch "{output.biscuit_index_done}"
        """
#+end_src
**** Align
#+begin_src snakemake
rule emseq_align_biscuit:
    message: "BISCUIT bisulfite alignment to human reference with coordinate-sorted BAM output"
    conda: ENV_EMSEQ
    input:
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        fasta = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
        index = f"{D_REF}/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.par.sa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}_emseq_align_biscuit.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}_emseq_align_biscuit.tsv"
    params:
        tmp_dir = D_DATA,
    threads: min(workflow.cores, 48)
    resources:
        concurrency = 100
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.biscuit.coorsort.bam",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[biscuit-align] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} threads={threads}"
        mkdir -p "{params.tmp_dir}/tmp"
        biscuit align -@ {threads} "{input.fasta}" "{input.r1}" "{input.r2}" \
        | samtools sort -@ {threads} -m 2G \
            -T "{params.tmp_dir}/tmp/{wildcards.library_id}_sorttmp" \
            -o "{output.bam}"
        """
#+end_src

**** Post-align
***** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
***** [[id:6a1d8806-5649-42e9-977d-c681a3106784][Filter]]
***** [[id:e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c][Call methylation]]
*** Common Steps
**** Common fastq
***** Fastp
#+begin_src snakemake
rule emseq_fastp:
    message: "Adapter trimming and QC metrics with fastp for EM-seq reads"
    conda: ENV_EMSEQ
    input:
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R2.fastq.gz",
    log:
        cmd = f"{D_LOGS}/{{library_id}}_emseq_fastp.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}_emseq_fastp.tsv"
    params:
        extra = FASTP_EXTRA,
    threads: 8
    output:
        failed = f"{D_EMSEQ}/fastqs/{{library_id}}.failed.fastq.gz",
        html = f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.html",
        json = f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.json",
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[fastp] $(date) lib={wildcards.library_id} threads={threads}"
        fastp \
          --detect_adapter_for_pe \
          --disable_quality_filtering \
          --in1 "{input.r1}" --in2 "{input.r2}" \
          --out1 "{output.r1}" --out2 "{output.r2}" \
          --failed_out "{output.failed}" \
          --json "{output.json}" --html "{output.html}" \
          --thread {threads} \
          {params.extra}
        """
#+end_src

***** FastQC
#+begin_src snakemake
rule emseq_fastqc:
    message: "FastQC quality assessment on raw or trimmed FASTQ files"
    conda: ENV_EMSEQ
    input:
        fq = f"{D_EMSEQ}/fastqs/{{library_id}}.{{processing}}_{{read}}.fastq.gz",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{processing}}_{{read}}_emseq_fastqc.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{processing}}_{{read}}_emseq_fastqc.tsv"
    threads: 4
    resources:
        concurrency = 25
    output:
        html = f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.html",
        zip  = f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[fastqc] $(date) lib={wildcards.library_id} proc={wildcards.processing} read={wildcards.read} threads={threads}"
        fastqc \
          --outdir "$(dirname "{output.html}")" \
          --quiet \
          --threads {threads} \
          "{input.fq}"
        """
#+end_src
**** Common alignment processing
***** Depth
#+begin_src snakemake
rule emseq_mosdepth:
    message: "Coverage depth profiling with mosdepth on filtered BAM"
    conda: ENV_EMSEQ
    input:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        index = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam.bai",
        regions_bed = KEEP_BED,
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mosdepth.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mosdepth.tsv"
    params:
        script       = f"{R_EMSEQ}/scripts/emseq_mosdepth.sh",
        quant_levels = MOSDEPTH_QUANT_LEVELS,
    threads: 8
    resources:
        concurrency = 20
    output:
        summary       = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
        global_dist   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.global.dist.txt",
        region_dist   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.region.dist.txt",
        regions       = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.regions.bed.gz",
        regions_idx   = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.regions.bed.gz.csi",
        quantized     = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.quantized.bed.gz",
        quantized_idx = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.quantized.bed.gz.csi",
        thresholds    = f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.thresholds.bed.gz",
        thresholds_idx= f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.thresholds.bed.gz.csi",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[mosdepth] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        "{params.script}" \
        "{input.bam}" \
        "$(dirname "{output.summary}")" \
        "{wildcards.library_id}.{wildcards.emseq_ref_name}.{wildcards.align_method}" \
        '{params.quant_levels}' \
        "{input.regions_bed}" \
        {threads}
        """
#+end_src

#+begin_src bash :tangle ./scripts/emseq_mosdepth.sh :tangle-mode (identity #o755)
#!/usr/bin/env bash
# -----------------------------------------------------------------------------
# mosdepth-wrapper.sh
#
# This script wraps the `mosdepth` tool to compute read depth over a BAM file,
# optimized for EM-seq cfDNA data. It configures the run to:
#   - use median depth (`--use-median`)
#   - run in fast mode (no per-base depth)
#   - report thresholds and quantized bins
#   - restrict to user-provided target regions
#
# Output files are written using a prefix of "mosdepth_<OUT_PREFIX>" in <OUT_DIR>.
# Designed for use in explicit I/O workflows like Snakemake or manual batch calls.
# -----------------------------------------------------------------------------
print_usage() {
    cat <<EOF
USAGE: mosdepth-wrapper.sh <BAM> <OUT_DIR> <OUT_PREFIX> <QUANT_LEVELS> <REGIONS_BED> [THREADS]
DESCRIPTION:
  Run mosdepth on a BAM file with EM-seq-appropriate settings.
  QUANT_LEVELS is a comma-separated string of coverage cutoffs (e.g. 1,5,10,20).
  REGIONS_BED is a BED file defining target regions (e.g. autosomes minus blacklist).
  The OUT_PREFIX will be prepended with 'mosdepth_' before being passed to mosdepth.
  Output files (e.g. mosdepth_<OUT_PREFIX>.summary.txt) will be written to OUT_DIR.
  THREADS is optional (default: 8).
EOF
}
main() {
    parse_args "$@"
    run_mosdepth
}
parse_args() {
    if [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]]; then
        print_usage
        exit 0
    fi
    if [[ $# -lt 5 ]]; then
        echo "Error: Missing required arguments." >&2
        print_usage
        exit 1
    fi
    declare -g bam_file="$1"
    declare -g out_dir="$2"
    declare -g user_prefix="$3"
    declare -g quant_levels="$4"
    declare -g regions_bed="$5"
    declare -g threads="${6:-8}"
    [[ -f "$bam_file" ]] || { echo "Error: BAM file not found: $bam_file" >&2; exit 1; }
    [[ -f "$regions_bed" ]] || { echo "Error: Regions BED not found: $regions_bed" >&2; exit 1; }
    mkdir -p "$out_dir"
    declare -g out_prefix="mosdepth_${user_prefix}"
    declare -g out_path="${out_dir%/}/${out_prefix}"
    declare -g quant_str="0:${quant_levels/,/:}"
}
run_mosdepth() {
    echo "[INFO] PID $$ running mosdepth on $bam_file" >&2
    echo "[INFO] Output prefix: $out_path" >&2
    echo "[INFO] Regions BED: $regions_bed" >&2
    echo "[INFO] Quantize string: $quant_str" >&2
    echo "[INFO] Threads: $threads" >&2
    mosdepth \
        --threads "$threads" \
        --no-per-base \
        --fast-mode \
        --use-median \
        --quantize "$quant_str" \
        --by "$regions_bed" \
        --thresholds "$quant_levels" \
        "$out_path" "$bam_file"
    echo "[INFO] mosdepth complete for PID $$" >&2
}
main "$@"
#+end_src

***** M-bias
#+begin_src snakemake
rule emseq_mbias:
    message: "MethylDackel M-bias detection for position-dependent methylation artifacts"
    conda: ENV_EMSEQ
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.tsv"
    threads: 10
    output:
        txt = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[mbias] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        MethylDackel mbias \
          -@ {threads} \
          --noSVG \
          "{input.fasta}" "{input.bam}" > "{output.txt}"
        """
#+end_src
***** Call duplicates
:PROPERTIES:
:ID:       4ac48779-f505-4291-b7bf-cc950d3339e6
:END:
#+begin_src snakemake
rule emseq_dedup:
    message: "Mark duplicates with dupsifter (marks only, does not remove) on bisulfite-aligned BAM"
    conda: ENV_EMSEQ
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_dedup.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_dedup.tsv"
    params:
        temp_prefix = lambda wc: f"{D_DATA}/tmp/{wc.library_id}.{wc.emseq_ref_name}.{wc.align_method}.coorsort"
    threads: 8
    resources:
        concurrency = 25
    output:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        index = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
    shell:
        """
        exec >> "{log.cmd}" 2>&1
        echo "[dedup] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        mkdir -p "$(dirname "{params.temp_prefix}")"
        rm -f {params.temp_prefix}.tmp.*
        samtools view -bh -f 0x2 "{input.bam}" \
        | samtools sort -n -@ {threads} -O BAM -T "{params.temp_prefix}.tmp" -o - \
        | dupsifter \
        --add-mate-tags \
        --stats-output "{log.cmd}.dupsifter.tsv" \
        "{input.fasta}" - \
        | samtools sort -@ {threads} -O BAM -T "{params.temp_prefix}.tmp" -o "{output.bam}"
        samtools index -@ {threads} "{output.bam}"
        """
#+end_src

***** Filter
:PROPERTIES:
:ID:       6a1d8806-5649-42e9-977d-c681a3106784
:END:
#+begin_src snakemake
rule emseq_filter_bam:
    message: "Filter BAM to proper pairs, MAPQ>=30, autosomes, excluding blacklist and duplicates"
    conda: ENV_EMSEQ
    input:
        bam   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam",
        bai   = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.deduped.bam.bai",
        keep_bed    = KEEP_BED,
        exclude_bed = EXCL_BED,
        fai   = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa.fai",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_filter_bam.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_filter_bam.tsv"
    threads: 16
    output:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        bai = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam.bai",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[filter-bam] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        samtools view -@ {threads} -u -f 2 -q 30 -F 3840 "{input.bam}" \
          | bedtools intersect -sorted -g "{input.fai}" -a stdin -b "{input.exclude_bed}" -v -ubam \
          | bedtools intersect -sorted -g "{input.fai}" -a stdin -b "{input.keep_bed}" -ubam \
          > "{output.bam}"
        samtools index -@ {threads} "{output.bam}" "{output.bai}"
        """
#+end_src
***** Samstats
#+begin_src snakemake
rule emseq_samtools_stats:
    message: "Samtools stats and flagstat on filtered BAM for alignment QC metrics"
    conda: ENV_EMSEQ
    input:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_samtools_stats.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_samtools_stats.tsv"
    threads: 8
    resources:
        concurrency = 40
    output:
        stats    = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.stats.txt",
        flagstat = f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.flagstat.txt",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[samtools-stats] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        samtools stats -@ {threads} "{input.bam}" > "{output.stats}"
        samtools flagstat -@ {threads} "{input.bam}" > "{output.flagstat}"
        """
#+end_src

**** Call methylation
:PROPERTIES:
:ID:       e645e8fb-1d2b-4d3c-9d6c-edcd8bf0d02c
:END:
#+begin_src snakemake
rule emseq_methyldackel:
    message: "MethylDackel CpG methylation extraction in methylKit format from filtered BAM"
    conda: ENV_EMSEQ
    input:
        bam = f"{D_EMSEQ}/bams/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.coorsort.filt.bam",
        fasta = f"{D_REF}/{{align_method}}/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_methyldackel.tsv"
    params:
        out_prefix = lambda wc, input, output: output.bed.rsplit("_CpG.methylKit", 1)[0]
    threads: 20
    resources:
        concurrency = 25
    output:
        bed = f"{D_EMSEQ}/meth/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methyldackel] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        MethylDackel extract \
          -@ {threads} \
          --methylKit \
          "{input.fasta}" \
          "{input.bam}" \
          -o "{params.out_prefix}"
        """
#+end_src
#+begin_src snakemake
rule emseq_make_single_methylkit_amp_obj:
    message: "Build tabix-backed methylKit object from MethylDackel AMP output"
    conda: ENV_METHYLKIT
    input:
        amp = f"{D_EMSEQ}/meth/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
    log:
        cmd = f"{D_LOGS}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_make_single_methylkit_amp_obj.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_make_single_methylkit_amp_obj.tsv"
    params:
        Rscript   = f"{R_EMSEQ}/scripts/make_single_amp_methylkit_obj.R",
        mincov    = EMSEQ_MINCOV,
        build     = lambda wc: wc.emseq_ref_name,
        treatment = 1,
    threads: 1
    output:
        bgz = f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
        tbi = f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz.tbi",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methylKit-amp] $(date) lib={wildcards.library_id} ref={wildcards.emseq_ref_name} aln={wildcards.align_method} threads={threads}"
        Rscript "{params.Rscript}" \
          --amp_file "{input.amp}" \
          --library_id "{wildcards.library_id}.{wildcards.emseq_ref_name}.{wildcards.align_method}.methyldackel" \
          --mincov {params.mincov} \
          --out_dir "$(dirname "{output.bgz}")" \
          --treatment {params.treatment} \
          --build {params.build}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_amp_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--amp_file", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--mincov", required = TRUE)
parser$add_argument("--build", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

obj <- methRead(
  location = args$amp_file,
  sample.id = args$library_id,
  assembly = args$build,
  treatment = args$treatment,
  pipeline = "amp",
  context = "CpG",
  resolution = "base",
  header = TRUE,
  mincov = args$mincov,
  dbtype = "tabix",
  dbdir = args$out_dir
)

#+end_src
**** MultiQC
#+begin_src snakemake
rule emseq_multiqc:
    message: "Aggregate QC metrics into MultiQC report for EM-seq workflow"
    conda: ENV_EMSEQ
    input:
        fastqc = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
            library_id=emseq_library_ids,
            processing=["raw","trimmed"],
            read=["R1","R2"],
            allow_missing=True,
        ),
        fastp_html = expand(
            f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.html",
            library_id=emseq_library_ids,
            allow_missing=True,
        ),
        fastp_json = expand(
            f"{D_EMSEQ}/qc/{{library_id}}_emseq_fastp.json",
            library_id=emseq_library_ids,
            allow_missing=True,
        ),
        mbias = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            allow_missing=True,
        ),
        mosdepth_summary = expand(
            f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            allow_missing=True,
        ),
        mosdepth_dists = expand(
            f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.{{dist}}.dist.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            dist=["global","region"],
            allow_missing=True,
        ),
        samstats = expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.samtools.{{stat}}.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["biscuit","bwa_meth"],
            stat=["stats","flagstat"],
        ),
    log:
        cmd = f"{D_LOGS}/emseq_multiqc.log",
    benchmark:
        f"{D_BENCHMARK}/emseq_multiqc.tsv"
    params:
        extra = "--force",
    threads: 4
    resources:
        concurrency = 20
    output:
        html = f"{D_EMSEQ}/qc/multiqc.html",
        data = directory(f"{D_EMSEQ}/qc/multiqc_data"),
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[multiqc] $(date) threads={threads}"
        mkdir -p "$(dirname "{output.html}")"
        multiqc \
            {input} \
            {params.extra} \
            --outdir "$(dirname "{output.html}")" \
            --filename "$(basename "{output.html}")" \
        """
#+end_src
*** Methylkit
Methylkit DMR requires EXACT same genome - can't mix e.g. hg38 / hg38 decoy
See for stranding https://claude.ai/chat/c39b78cc-5b2f-49ed-9f02-ed349824a07a
**** Per base
***** United per sample
#+begin_src snakemake
rule emseq_make_methylkit_unite_db:
    message: "Unite per-sample methylKit tabix databases into single methylBase for differential analysis"
    conda: ENV_METHYLKIT
    input:
        mkit_lib_db = lambda wc: expand(
            f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
            library_id=meth_map[wc.experiment]["libs"],
            emseq_ref_name=meth_map[wc.experiment]["emseq_ref_name"],
            align_method=meth_map[wc.experiment]["align_method"],
        ),
    log:
        cmd = f"{D_LOGS}/{{experiment}}_emseq_make_methylkit_unite_db.log",
    benchmark:
        f"{D_BENCHMARK}/{{experiment}}_emseq_make_methylkit_unite_db.tsv"
    params:
        library_id = lambda wc: " ".join(meth_map[wc.experiment]["libs"]),
        treatment_list = lambda wc: " ".join(map(str, meth_map[wc.experiment]["tx"])),
        script = f"{R_EMSEQ}/scripts/make_methylkit_unite_db.R",
        mincov = lambda wc: meth_map[wc.experiment]["mincov"],
        min_per_group = lambda wc: meth_map[wc.experiment]["mingroup"],
        chunk_size = lambda wc: meth_map[wc.experiment]["chunksize"],
    threads: 32
    output:
        mbase = f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methylkit-unite] $(date) experiment={wildcards.experiment} threads={threads}"
        rm -f "{output.mbase}"*
        Rscript "{params.script}" \
          --lib_db_list "{input.mkit_lib_db}" \
          --lib_id_list "{params.library_id}" \
          --treatment_list "{params.treatment_list}" \
          --cores {threads} \
          --out_dir "$(dirname "{output.mbase}")" \
          --suffix {wildcards.experiment} \
          --assembly "hg38" \
          --mincov {params.mincov} \
          --min_per_group {params.min_per_group} \
          --chunk_size {params.chunk_size}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_unite_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
split_ws <- function(x) trimws(unlist(strsplit(x, "\\s+")))
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num_chunk <- function(x, nm="chunk_size") {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (accepts forms like 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--lib_db_list", required=TRUE, help="Space-separated tabix files")
parser$add_argument("--lib_id_list", required=TRUE, help="Space-separated sample IDs")
parser$add_argument("--treatment_list", required=TRUE, help="Space-separated 0/1 indicators")
parser$add_argument("--cores", default="4", help="Parallel workers (default: 4)")
parser$add_argument("--out_dir", required=TRUE, help="Output directory for methylKit DBs")
parser$add_argument("--suffix", required=TRUE, help="Suffix for DB files (e.g., 'test')")
parser$add_argument("--assembly", default="hg38", help="Genome assembly (default: hg38)")
parser$add_argument("--mincov", default="10", help="Minimum coverage per CpG (integer; default: 10)")
parser$add_argument("--min_per_group", default="1", help="Min samples per group per CpG (integer; default: 1)")
parser$add_argument("--chunk_size", default="1e9", help="Chunk size (accepts '1e9' style; default: 1e9)")

args <- parser$parse_args()

# --- parse & validate ---
lib_db_list    <- split_ws(args$lib_db_list)
lib_id_list    <- split_ws(args$lib_id_list)
treatment_list <- as.numeric(split_ws(args$treatment_list))

if (length(lib_db_list) != length(lib_id_list) ||
    length(lib_id_list) != length(treatment_list)) {
  stop(sprintf("Length mismatch: lib_db_list=%d, lib_id_list=%d, treatment_list=%d",
               length(lib_db_list), length(lib_id_list), length(treatment_list)))
}

cores        <- as_int(args$cores, "cores")
mincov       <- as_int(args$mincov, "mincov")
min_per_grp  <- as_int(args$min_per_group, "min_per_group")
chunk_size   <- as_num_chunk(args$chunk_size, "chunk_size")

# destructive overwrite of methylBase only
mbase_path <- file.path(args$out_dir, sprintf("methylBase_%s.txt.bgz", args$suffix))
suppressWarnings(file.remove(mbase_path, paste0(mbase_path, ".tbi")))

# --- Read (tabix + CpG only) ---
merged_obj <- methRead(
  location   = as.list(lib_db_list),
  sample.id  = as.list(lib_id_list),
  treatment  = treatment_list,
  context    = "CpG",
  assembly   = args$assembly,
  dbtype     = "tabix",
  mincov     = mincov
)

# --- Unite (destrand hardcoded TRUE, save.db always TRUE) ---
meth <- unite(
  merged_obj,
  destrand      = TRUE,
  chunk.size    = chunk_size,
  mc.cores      = cores,
  save.db       = TRUE,
  min.per.group = min_per_grp,
  suffix        = args$suffix,
  dbdir         = args$out_dir
)

message("Done. methylBase: ", mbase_path)

#+end_src

***** Run differential methylation calling
#+begin_src snakemake
rule emseq_make_methylkit_diff_db:
    message: "Calculate differential methylation from united methylBase using methylKit"
    conda: ENV_METHYLKIT
    input:
        mbase = f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    log:
        cmd = f"{D_LOGS}/{{experiment}}_emseq_make_methylkit_diff_db.log",
    benchmark:
        f"{D_BENCHMARK}/{{experiment}}_emseq_make_methylkit_diff_db.tsv"
    params:
        script     = f"{R_EMSEQ}/scripts/make_methylkit_diff_db.R",
        chunk_size = lambda wc: meth_map[wc.experiment]["chunksize"],
    threads: 32
    output:
        mdiff = f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methylkit-diff] $(date) experiment={wildcards.experiment} threads={threads}"
        rm -f "{output.mdiff}" "{output.mdiff}.tbi"
        Rscript "{params.script}" \
          --mbase "{input.mbase}" \
          --cores {threads} \
          --out_dir "$(dirname "{output.mdiff}")" \
          --suffix {wildcards.experiment} \
          --chunk_size {params.chunk_size}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_diff_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num_chunk <- function(x, nm="chunk_size") {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (accepts forms like 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--mbase", required=TRUE,
                    help="Path to methylBase_*.txt.bgz from unite step")
parser$add_argument("--cores", default="4",
                    help="Parallel workers (default: 4)")
parser$add_argument("--out_dir", required=TRUE,
                    help="Output directory for methylKit DBs")
parser$add_argument("--suffix", required=TRUE,
                    help="Suffix for DB files (e.g., 'test')")
parser$add_argument("--chunk_size", default="1e9",
                    help="Chunk size (accepts '1e9' style; default: 1e9)")

args <- parser$parse_args()

cores      <- as_int(args$cores, "cores")
chunk_size <- as_num_chunk(args$chunk_size, "chunk_size")

# --- load methylBase (tabix backend) ---

meth <- methylKit:::readMethylDB(args$mbase)

# --- Differential methylation ---
diff <- calculateDiffMeth(
  meth,
  mc.cores   = cores,
  chunk.size = chunk_size,
  save.db    = TRUE,
  dbdir      = args$out_dir
)

diff_path <- file.path(args$out_dir, sprintf("methylDiff_%s.txt.bgz", args$suffix))
message("Done. methylDiff: ", diff_path)
#+end_src
**** Tiled

#+begin_src snakemake
rule emseq_make_methylkit_diff_db_tiled:
    message: "Tile methylation data into windows and calculate differential methylation with methylKit"
    conda: ENV_METHYLKIT
    input:
        mkit_lib_db = lambda wc: expand(
            f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
            library_id=meth_map[wc.experiment]['libs'],
            emseq_ref_name=meth_map[wc.experiment]['emseq_ref_name'],
            align_method=meth_map[wc.experiment]['align_method'],
        ),
    log:
        cmd = f"{D_LOGS}/{{experiment}}_emseq_make_methylkit_diff_db_tiled.log",
    benchmark:
        f"{D_BENCHMARK}/{{experiment}}_emseq_make_methylkit_diff_db_tiled.tsv"
    params:
        library_id = lambda wc: " ".join(meth_map[wc.experiment]['libs']),
        treatment_list = lambda wc: " ".join(map(str, meth_map[wc.experiment]['tx'])),
        script = f"{R_EMSEQ}/scripts/make_methylkit_diff_tiled_db.R",
        mincov = lambda wc: meth_map[wc.experiment]["mincov"],
        chunk_size = lambda wc: meth_map[wc.experiment]["chunksize"],
        min_per_group = lambda wc: meth_map[wc.experiment]["mingroup"],
        win_size = lambda wc: meth_map[wc.experiment]["win_size"],
    threads: 32
    output:
        unite = f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.tiled.txt.bgz",
        diff = f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}.tiled.txt.bgz",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[methylkit-diff-tiled] $(date) experiment={wildcards.experiment} threads={threads}"
        rm -f "{output.unite}"* "{output.diff}"*
        Rscript "{params.script}" \
          --lib_db_list "{input.mkit_lib_db}" \
          --lib_id_list "{params.library_id}" \
          --treatment_list "{params.treatment_list}" \
          --cores {threads} \
          --out_dir "$(dirname "{output.unite}")" \
          --suffix {wildcards.experiment} \
          --assembly "hg38" \
          --mincov {params.mincov} \
          --win_size {params.win_size} \
          --min_per_group {params.min_per_group} \
          --chunk_size {params.chunk_size}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_methylkit_diff_tiled_db.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
})

# --- helpers ---
split_ws <- function(x) trimws(unlist(strsplit(x, "\\s+")))
as_int <- function(x, nm) {
  xi <- suppressWarnings(as.integer(x))
  if (is.na(xi)) stop(sprintf("'%s' must be an integer (got: %s)", nm, x))
  xi
}
as_num <- function(x, nm) {
  xn <- suppressWarnings(as.numeric(x))
  if (is.na(xn)) stop(sprintf("'%s' must be numeric (e.g., 1e9 or 1000000000; got: %s)", nm, x))
  xn
}

# --- args ---
parser <- ArgumentParser()
parser$add_argument("--lib_db_list", required = TRUE)
parser$add_argument("--lib_id_list", required = TRUE)
parser$add_argument("--treatment_list", required = TRUE)
parser$add_argument("--cores", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)
parser$add_argument("--suffix", required = TRUE)
parser$add_argument("--assembly", required = TRUE)
parser$add_argument("--mincov", required = TRUE)
parser$add_argument("--win_size", required = TRUE)
parser$add_argument("--chunk_size", required = TRUE)
parser$add_argument("--min_per_group", default="1", help="Min samples per group per CpG (integer; default: 1)")
args <- parser$parse_args()

dir.create(args$out_dir, recursive = TRUE, showWarnings = FALSE)

# --- parse ---
lib_db_list    <- split_ws(args$lib_db_list)
lib_id_list    <- split_ws(args$lib_id_list)
treatment_list <- as.numeric(split_ws(args$treatment_list))

if (length(lib_db_list) != length(lib_id_list) ||
    length(lib_id_list) != length(treatment_list)) {
  stop(sprintf("Length mismatch: lib_db_list=%d, lib_id_list=%d, treatment_list=%d",
               length(lib_db_list), length(lib_id_list), length(treatment_list)))
}

cores      <- as_int(args$cores, "cores")
mincov     <- as_int(args$mincov, "mincov")
win_size   <- as_int(args$win_size, "win_size")      # FIX: was args$winsize â†’ numeric(0)
min_per_grp  <- as_int(args$min_per_group, "min_per_group")
chunk_size <- as_num(args$chunk_size, "chunk_size")

# --- destructive cleanup: only *_tiled* (both base & diff) ---
tiled_patterns <- c(
  file.path(args$out_dir, sprintf("methylBase_%s_tiled*.txt.bgz*", args$suffix)),
  file.path(args$out_dir, sprintf("methylDiff_%s_tiled*.txt.bgz*", args$suffix))
)
tiled_paths <- unlist(lapply(tiled_patterns, Sys.glob))
if (length(tiled_paths) > 0) suppressWarnings(file.remove(tiled_paths))

# --- read methylation DBs ---
merged_obj <- methRead(
  location  = as.list(lib_db_list),
  sample.id = as.list(lib_id_list),
  treatment = treatment_list,
  context   = "CpG",
  assembly  = args$assembly,
  dbtype    = "tabix",
  mincov    = mincov
)

# --- tile per sample ---
tiled_raw <- tileMethylCounts(
  merged_obj,
  win.size   = win_size,
  step.size  = win_size,
  cov.bases  = 1,
  save.db    = TRUE,
  suffix     = args$suffix,
  dbdir      = args$out_dir,
  mc.cores   = cores
)

# --- unite tiles into methylBaseDB ---
tiled_obj <- unite(
  tiled_raw,
  destrand = FALSE,
  save.db  = TRUE,
  suffix   = paste0(args$suffix, ".tiled"),
  dbdir    = args$out_dir,
  min.per.group = min_per_grp,
  mc.cores = cores
)

# --- differential methylation on tiles ---
diff <- calculateDiffMeth(
  tiled_obj,
  mc.cores   = cores,
  chunk.size = chunk_size,   # FIX: missing comma previously
  save.db    = TRUE,
  dbdir      = args$out_dir,
)
#+end_src

https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html



*** Ideas
:PROPERTIES:
:ID:       f6cfad3a-21c6-4c33-94e2-0a6cb53a5fe3
:header-args:snakemake: :tangle no
:END:
- note that multicq inputs cannot promp new runs
- push methmap to config
#+begin_src snakemake
rule all_experiment_tiled_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}_tiled.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_tiled_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src

**** biscuit Pileup
#+begin_src snakemake
rule emseq_biscuit_pileup:
    conda:
        "../config/emseq-conda-env.yaml",
    input:
        bam = f"{data_dir}/emseq/bams/{{library_id}}.{{emseq_ref_name}}.biscuit.coorsort.deduped.bam",
        fasta = f"{data_dir}/ref/biscuit/{{emseq_ref_name}}/{{emseq_ref_name}}.fa",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}.biscuit_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf",
    shell:
        """
        biscuit pileup \
        -@ 20 \
        -o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
#+begin_src snakemake
rule emseq_biscuit_post_pileup:
    conda:
        "../config/emseq-conda-env.yaml",
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}.biscuit_pileup.vcf.gz",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}_emseq_biscuit_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input.vcf} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark} &> {log}
        """
#+end_src

#+begin_src snakemake
rule make_single_biscuit_methylkit_obj:
    conda: ENV_METHYLKIT
    input:
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{emseq_ref_name}}_bismark_cov.bed",
    log:
        f"{data_dir}/logs/{{library_id}}.{{emseq_ref_name}}_make_single_biscuit_methylkit_obj.log",
    output:
        txt = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt",
        bgz = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt.bgz",
        tbi = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{emseq_ref_name}}_biscuit.txt.bgz.tbi",
    params:
        Rscript = f"{emseq_script_dir}/make_single_biscuit_methylkit_obj.R",
        out_dir = f"{data_dir}/analysis/emseq/post-biscuit",
    shell:
        """
        Rscript {params.Rscript} \
          --bismark_cov_bed {input.bismark} \
          --library_id {wildcards.library_id} \
          --out_dir {params.out_dir} \
          &> {log}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_biscuit_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--bismark_cov_bed", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

myobj= methRead(args$bismark_cov_bed,
                sample.id = args$library_id,
                treatment = 1,
                context="CpG",
                pipeline="bismarkCoverage",
                mincov = 2,
                assembly= "hg38",
                dbtype = "tabix",
                dbdir = args$out_dir)

#+end_src


***** OLD Methylation sequence processing
:PROPERTIES:
:ID:       c3bdbbcc-5a4c-475a-8ab1-33884ab14ef5
:header-args:snakemake: :tangle no
:END:
****** methylKit per experiment
******* Grouped objects and differential methylation
******** Per-position
#+begin_src snakemake
rule make_methylkit_diff_db:
    input:
        mkit_lib_db = lambda wildcards: expand(
            f"{emseq_dir}/dmr/tabix/{{library_id}}.txt.bgz",
            library_id = meth_map[wildcards.experiment]['libs']
        ),
    log:
        f"{log_dir}/{{experiment}}_make_methylkit_diff_db.log",
    output:
        unite = f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
        diff = f"{emseq_dir}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
    params:
        library_id = lambda wildcards: " ".join(meth_map[wildcards.experiment]['libs']),
        treatment_list = lambda wildcards: meth_map[wildcards.experiment]['tx'],
        out_dir = f"{emseq_dir}/dmr/diff",
        script = f"{emseq_script_dir}/make_methylkit_diff_db.R",
    shell:
        """
        Rscript {params.script} \
        --lib_db_list "{input.mkit_lib_db}" \
        --lib_id_list "{params.library_id}" \
        --treatment_list "{params.treatment_list}" \
        --cores 32 \
        --out_dir {params.out_dir} \
        --suffix {wildcards.experiment} > {log} 2>&1
        """
#+end_src



#+begin_src snakemake
rule all_experiment_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_pos_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src


#+begin_src R :tangle ./scripts/all_experiment_methylation.R
library(argparse)
library(methylKit)
library(tidyverse)

# --- Argument Parsing ---
parser <- ArgumentParser()
parser$add_argument("--db_file", required = TRUE, help = "Path to tabix-indexed methylBase file")
parser$add_argument("--out_file", required = TRUE, help = "Output TSV path for percent methylation matrix")
parser$add_argument("--chunk_size", type = "double", default = 1e9, help = "Chunk size for methylKit operations")
args <- parser$parse_args()

# --- Check Header and Load Object ---
methylKit:::checkTabixHeader(args$db_file)
meth <- methylKit:::readMethylDB(args$db_file)

# --- Extract Percent Methylation Matrix ---
meth_matrix <- percMethylation(meth, rowids = TRUE, chunk.size = args$chunk_size)

# --- Write Output ---
write_tsv(
  as.data.frame(meth_matrix) %>% rownames_to_column(var = "coord"),
  args$out_file
)

#+end_src

******** Tiled

#+begin_src snakemake
rule make_methylkit_diff_db_tiled:
    input:
        mkit_lib_db = lambda wildcards: expand(
            f"{emseq_dir}/dmr/tabix/{{library_id}}.txt.bgz",
            library_id = meth_map[wildcards.experiment]['libs']
        ),
    log:
        f"{log_dir}/{{experiment}}_make_methylkit_diff_tiled_db.log",
    output:
        unite = f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
        diff = f"{emseq_dir}/dmr/diff/methylDiff_{{experiment}}_tiled.txt.bgz",
    params:
        library_id = lambda wildcards: " ".join(meth_map[wildcards.experiment]['libs']),
        treatment_list = lambda wildcards: meth_map[wildcards.experiment]['tx'],
        out_dir = f"{emseq_dir}/dmr/diff",
        script = f"{emseq_script_dir}/make_methylkit_diff_tiled_db.R",
        win_size = 1000000,
        step_size= 1000000,
    shell:
        """
        Rscript {params.script} \
        --lib_db_list "{input.mkit_lib_db}" \
        --lib_id_list "{params.library_id}" \
        --treatment_list "{params.treatment_list}" \
        --cores 32 \
        --out_dir {params.out_dir} \
        --win_size {params.win_size} \
        --step_size {params.step_size} \
        --suffix {wildcards.experiment} \
        > {log} 2>&1
        """
#+end_src



#+begin_src snakemake
rule all_experiment_tiled_methylation:
    input:
        f"{emseq_dir}/dmr/diff/methylBase_{{experiment}}_tiled.txt.bgz",
    log:
        f"{log_dir}/all_experiment_methylation_{{experiment}}_tiled.log",
    output:
        f"{emseq_dir}/dmr/diff/{{experiment}}_tiled_meth.tsv",
    params:
        script = f"{emseq_script_dir}/all_experiment_methylation.R",
    shell:
        """
        Rscript {params.script} \
        --db_file {input} \
        --out_file {output} > {log} 2>&1
        """
#+end_src

******** Exploratory data analysis

#+begin_src R
# Compute global methylation (mean per sample)

library(tidyverse)
library(methylKit)

db_file = "/mnt/data/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz"

methylKit:::checkTabixHeader(db_file)

meth = methylKit:::readMethylDB(db_file)

# Extract percent methylation matrix
meth_matrix <- percMethylation(
  meth,
  rowids = TRUE,
  chunk.size = 1e+09)


ls()

global_df <- data.frame(
  library_id = colnames(meth_matrix),
  global_methylation = colMeans(meth_matrix, na.rm = TRUE)
)

global_df = meth_matrix %>% as.data.frame() %>% as_tibble()

global_df <- meth_matrix %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE))

global_df


binMeth <- tileMethylCounts(
  meth,
  win.size = 1000,      # bin/window size in bp
  step.size = 1000,     # step size (same as win.size for non-overlapping bins)
  cov.bases = 5,
  mc.cores = 4          # optional parallelization
)

binMeth <- tileMethylCounts(
  meth,
  win.size = 1000,
  step.size = 1000,  # Distance shift (>win is gap, <win is overlap)
  cov.bases = 5,                    # minimum number of CpGs per bin
  sample.ids = meth@sample.ids,     # explicit sample IDs
  treatment = meth@treatment,       # explicit treatment vector
  mc.cores = 12
)

#########1#########2#########3#########4#########5#########6#########7#########8


full = full %>% mutate(library_id = sample)

full = full %>%
  mutate(group = case_when(
    str_starts(library_id, "NH") ~ "healthy",
    str_starts(library_id, "PRO") ~ "cancer",
    TRUE ~ NA_character_
  ))

global_df = global_df %>% left_join(full, by = "library_id")


# Violin plot (one point per library, jittered for clarity)
ggplot(global_df, aes(x = group, y = global_methylation, fill = group)) +
  geom_violin(width = 1.0, trim = TRUE, alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(title = "Global Methylation per Library",
       y = "Mean % Methylation",
       x = "Group")


str(global_df)

prog = global_df %>% filter(group == "cancer")

prog$interval_progression

ggplot(prog, aes(x = interval_progression, y = global_methylation)) + geom_point()


#########1#########2#########3#########4#########5#########6#########7#########8

library(methylKit)
library(tidyverse)
library(patchwork)

# Load methylation data
db_file <- "/mnt/data/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz"
meth <- methylKit:::readMethylDB(db_file)

# Calculate global methylation per library
global_df <- percMethylation(meth) %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE), .groups = "drop")

# Annotate with metadata
global_df <- global_df %>%
  left_join(full %>% mutate(library_id = sample), by = "library_id") %>%
  mutate(group = case_when(
    str_starts(library_id, "NH") ~ "Healthy",
    str_starts(library_id, "PRO") ~ "Cancer",
    TRUE ~ NA_character_
  )) %>%
  mutate(group = factor(group, levels = c("Healthy", "Cancer")))

# Plot 1: Violin plot
p1 <- ggplot(global_df, aes(x = group, y = global_methylation, fill = group)) +
  geom_violin(width = 0.9, alpha = 0.4, color = NA) +
  geom_jitter(width = 0.1, size = 2, color = "black") +
  labs(x = NULL, y = "Global % Methylation") +
  scale_fill_manual(values = c("Healthy" = "#1B9E77", "Cancer" = "#D95F02")) +
  theme_minimal(base_size = 16) +
  theme(legend.position = "none")

# Plot 2: Scatter vs interval_progression
p2 <- global_df %>%
  filter(group == "Cancer", !is.na(interval_progression)) %>%
  ggplot(aes(x = interval_progression, y = global_methylation)) +
  geom_point(size = 3, color = "#D95F02", stroke = 1, shape = 21, fill = "#D95F02") +
  labs(x = "Progression-Free Survival (days)", y = "Global % Methylation") +
  theme_minimal(base_size = 16)

p2 <- global_df %>%
  filter(group == "Cancer", !is.na(interval_progression)) %>%
  ggplot(aes(x = interval_progression, y = global_methylation)) +
  geom_point(size = 3, color = "#D95F02", stroke = 1, shape = 21, fill = "#D95F02") +
  geom_smooth(method = "lm", se = FALSE, color = "black", linewidth = 1, linetype="dotted") +
  labs(x = "Progression-Free Survival (days)", y = "Global % Methylation") +
  theme_minimal(base_size = 16)

# Combine side by side
p1 + p2 + plot_layout(widths = c(1, 1))

ggsave("/tmp/global_meth.png", p1 + p2, width = 12, height = 5, dpi = 300)
#+end_src

- global methylation
- tiled methylation beta heatmap
-
****** Dev
:properties:
:header-args:snakemake: :tangle no
:end:

- dmr heatmap
  #+begin_src R
library(methylKit)
ls()

methylKit:::checkTabixHeader("/mnt/data/jeszyman/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz")

test= methylKit:::readMethylDB("/mnt/data/jeszyman/projects/breast/analysis/emseq/dmr/diff/methylBase_pro_vs_nh.txt.bgz")


#########1#########2#########3#########4#########5#########6#########7#########8

rm(baseDB.obj)

methylKit:::checkTabixHeader(mydbpath)
readMethylDB(mydbpath)


methylBase_PRO_5_vs_NH_54.txt.bgz", dbtype = "tabix")

meth = test
meth_mat <- percMethylation(meth)
library(matrixStats)

variances <- rowVars(meth_mat, na.rm = TRUE)
top_idx <- order(variances, decreasing = TRUE)[1:500]  # or 1000
top_meth <- meth_mat[top_idx, ]

top_meth_z <- t(scale(t(top_meth)))  # mean-center and scale each CpG row

library(pheatmap)

pheatmap(top_meth_z,
         cluster_rows = TRUE,
         cluster_cols = TRUE,
         show_rownames = FALSE,
         main = "Top Variable CpG Sites")

#+end_src
- dmr pca
  #+begin_src R
# From full matrix
meth_mat <- percMethylation(meth)
meth_mat[is.na(meth_mat)] <- 0

# Select top variable rows
library(matrixStats)
vars <- rowVars(meth_mat)
top_idx <- order(vars, decreasing = TRUE)[1:1000]  # adjust as needed
meth_mat_top <- meth_mat[top_idx, ]

# Z-score normalize
meth_z <- t(scale(t(meth_mat_top)))

# PCA
pca <- prcomp(t(meth_z), scale. = FALSE)

#+end_src
- dmr global
  #+begin_src R
meth_mat <- percMethylation(meth)
sample_means <- colMeans(meth_mat, na.rm = TRUE)
df <- data.frame(
  sample = colnames(meth_mat),
  treatment = factor(c(1, 1, 0, 0)),  # adjust as needed
  global_methylation = sample_means
)
library(ggplot2)

ggplot(df, aes(x = treatment, y = global_methylation)) +
  geom_violin(trim = FALSE, fill = "gray80", color = "black") +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(x = "Treatment", y = "Global % Methylation", title = "Global Methylation per Sample")

#+end_src

******* Depth
#+begin_src bash

ls /tmp/breast/analysis/emseq/bams-merged/PRO_13_deduped.bam

mosdepth \
    --threads 8 \
    --no-per-base \
    --fast-mode \
    --use-median \
    --quantize 0:5:10:20 \
    /tmp/breast/qc/PRO_13_emseq_mosdepth \
    /tmp/breast/analysis/emseq/bams-merged/PRO_13_deduped.bam

#+end_src

******* EM-seq methylation
- Consider reference w/ decoys https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369
******** Biscuit index
#+begin_src bash
source ~/repos/breast/config/bash-env.sh
Y


if [ -e "$data_dir/inputs/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz" ]; then
    echo "File exists, skipping download."
else
    aria2c -c -x 10 -s 10 -m 5 -d $data_dir/inputs/ \
	   -o Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \
	   https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz

fi


if [ -e "$data_dir/inputs/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz" ]; then
    echo "File exists, skipping download."
else
    aria2c -c -x 10 -s 10 -m 5 -d $data_dir/inputs/ \
	   -o GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz \
	   https:/ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
fi

#+end_src


#+begin_src bash
source ~/repos/breast/config/bash-env.sh

# Ensembl primary assembly
ensembl_dir="$data_dir/ref/biscuit-ensembl-hg38"
ensembl_input="$data_dir/inputs/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz"
ensembl_fa="$ensembl_dir/Homo_sapiens.GRCh38.dna.primary_assembly.fa"

mkdir -p "$ensembl_dir"
gunzip -c "$ensembl_input" > "$ensembl_fa"
samtools faidx "$ensembl_fa"
nohup biscuit index "$ensembl_fa" & disown

# NCBI decoy set
ncbi_dir="$data_dir/ref/biscuit-ncbi-decoy-hg38"
ncbi_input="$data_dir/inputs/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz"
ncbi_fa="$ncbi_dir/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna"

mkdir -p "$ncbi_dir"
gunzip -c "$ncbi_input" > "$ncbi_fa"
samtools faidx "$ncbi_fa"
#

nohup biscuit index "$ncbi_fa" & disown
#+end_src
******** Make methylation position calls

#+begin_src bash
biscuit pileup \
	-@ 8 \
	-o /tmp/test/post/pileup.vcf \
	"$data_dir/ref/biscuit/Homo_sapiens.GRCh38.dna.primary_assembly.fa" \
	/tmp/test/post/pos-sorted.bam

bgzip -@ 8 /tmp/test/post/pileup.vcf

tabix -p vcf /tmp/test/post/pileup.vcf.gz

biscuit vcf2bed \
	-t cg \
	/tmp/test/post/pileup.vcf.gz \
	> /tmp/test/post/pileup.bed


head /tmp/test/post/pileup.vcf_meth_average.tsv
#+end_src
- snakemake, inline
  #+begin_src snakemake
rule emseq_pileup:
    input:
        bam = f"{emseq_bam_dir}/{{library_id}}_deduped.bam",
        fasta = f"{ref_dir}/biscuit/{emseq_ref_fasta}",
    log:
        f"{log_dir}/{{library_id}}_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf",
    shell:
        """
        biscuit pileup \
	-@ 8 \
	-o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
- snakemake, inline
  #+begin_src snakemake
rule emseq_post_pileup:
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz",
    log:
        f"{log_dir}/{{library_id}}_emseq_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark}
        """
#+end_src

******** DMR
https:/www.bioconductor.org/packages/release/bioc/vignettes/dmrseq/inst/doc/dmrseq.html
https:/huishenlab.github.io/biscuit/docs/methylextraction.html
https:/bioconductor.org/packages/release/bioc/html/DSS.html
https:/ziemann-lab.net/public/guppy_methylseq/PCAanalysis.html


#+begin_src python
from pathlib import Path
import pandas as pd

pileup_dir = Path("/tmp/breast/analysis/emseq/pileup")
out_suffix = "_methylkit.tsv"

for bedfile in pileup_dir.glob("*_pileup.bed"):
    df = pd.read_csv(bedfile, sep="\t", header=None,
                     names=["chr", "start", "end", "meth_ratio", "coverage"])
    df["pos"] = df["start"] + 1  # methylKit expects 1-based coordinate
    df["strand"] = "+"
    df["num_mC"] = (df["meth_ratio"] * df["coverage"]).round().astype(int)
    df["num_C"] = df["coverage"] - df["num_mC"]

    out_df = df[["chr", "pos", "strand", "coverage", "num_mC", "num_C"]]

    outfile = bedfile.with_name(bedfile.stem.replace("_pileup", "") + out_suffix)
    out_df.to_csv(outfile, sep="\t", header=False, index=False)

#+end_src

#+begin_src snakemake
rule methylkit_dmr_obj:
    input:
        bismark_cov lambda wildcards: expand(f"{emseq_dir}/pileup/{{library_id}}_bismark_cov.bed",
                                             library = emseq_map[wildcards.experiment]['libs']),
    log:
    output:
        f"{}
#+end_src

#+begin_src R
# biscuit vcf2bed -k 2 -c PRO_13_pileup.vcf.gz > my_beta_m_u.bed

library(methylKit)

myobj = methRead("/tmp/breast/analysis/emseq/pileup/my_beta_m_u.bed",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 sample.id = "TEST",
                 assembly="hg38")


myobj

getMethylationStats(myobj,plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj,plot=TRUE,both.strands=FALSE)

filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)

filtered.myobj

obj=read("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",sample.id="test",assembly="hg38",header=FALSE, context="CpG", resolution="base",
          pipeline=list(fraction=TRUE,chr.col=1,start.col=2,end.col=2,
                        coverage.col=4,strand.col=3,freqC.col=5 )
        )

obj

methRead()

library(methylKit)

help(methRead)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = TRUE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    freqC.col = 5
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv", header = FALSE)
str(df)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = FALSE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


file.list <- list(
  "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  "/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit.tsv"
)

# read the files to a methylRawList object: myobj
myobj=methRead(file.list,
           sample.id=list("test1","ctrl1"),
           assembly="hg38",
           treatment=c(1,0),
           context="CpG",
           mincov = 2
           )


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "generic",
  header = FALSE
)


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "bismarkCoverage",
  header = FALSE
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    context.col = NULL,
    context.filter = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    fraction = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    column.names = c("chr", "start", "strand", "coverage", "numCs", "numTs")
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

library(methylKit)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_like.tsv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
str(df)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                 sep = "\t", header = FALSE, colClasses = c("character", "integer", "integer", "integer", "integer", "character"))

obj <- methRead(df,
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  resolution = "base"
)


write.table(df, "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean2.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)

obj <- methRead(
  location = "NH22_bismark_clean2.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

head(df)


obj=methRead("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
         sample.id="test",
         assembly="hg38",
         header=FALSE,
         context="CpG",
         resolution="base",
         pipeline=list(fraction=FALSE,
                       chr.col=1,
                       start.col=2,
                       end.col=3,
                       coverage.col=4,
                       strand.col=6,
                       freqC.col=5 )
        )


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  context = "CpG",
  resolution = "base",
  treatment = 0,
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    meth.col = 4,
    unmeth.col = 5,
    strand.col = 6
  )
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  pipeline = "bismark"
)

# Read in your original data
data <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                  header = FALSE,
                  col.names = c("chr", "start", "end", "meth", "unmeth", "strand"))

# Calculate total coverage and methylation percentage
data$coverage <- data$meth + data$unmeth
data$methPercent <- round(data$meth / data$coverage * 100, 2)

# Write to a new file in methylKit-compatible format
write.table(data[, c("chr", "start", "end", "strand", "coverage", "methPercent")],
            file = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  resolution = "base",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    strand.col = 4,
    coverage.col = 5,
    freqC.col = 6
  )
)


generic.file=system.file("extdata", "generic1.CpG.txt",package = "methylKit")
read.table(generic.file,header=TRUE)

test= read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=T)

head(test)

# And this is how you can read that generic file as a methylKit object
myobj=methRead(test,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj

nrow(read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=TRUE))  # should match wc -l minus 1

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

# And this is how you can read that generic file as a methylKit object
myobj=methRead( generic.file,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj
# This creates tabix files that save methylation

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_patched.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")
myobj



myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1",
                 mincov = 1,
                 assembly="hg38")




myobj = methRead("/tmp/breast/analysis/emseq/pileup/test.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

#+end_src

******** Reference
- Alignment reference choice
  - discussion [[https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369][gtp]]
  - see [[id:326ecd60-8cd4-4815-a389-967b2c3fef0a][Nucleic acid sequence alignment]]
- [cite:@chauhan2024]
- [[id:5e9e8bfa-ac9e-4103-9cc5-7123337b4e24][biscuit]]

******** Ideas
- for qc https:/www.google.com/search?sca_esv=45e5c8ab8ae118cf&sxsrf=AHTn8zrPW-wtm7PgHxohfizFJXC9p5Qtlw:1742500238525&q=m-bias+plots&udm=2&fbs=ABzOT_CWdhQLP1FcmU5B0fn3xuWpA-dk4wpBWOGsoR7DG5zJBtmuEdhfywyzhendkLDnhcrUz6wxBwARHD96EKWkSbZoQZGasaHPJ9csj0AVVVUDNHqfR7gd1arUfaOpw1v5Icccwayh65rdsqdiyPvxAA9gXK95YqgoHnUzfZ5jo9jiMl2Q8DaMUR4I1U0kl1-ho1NSBjy_chexdcGuJmvrFewYJaqjljog&sa=X&ved=2ahUKEwj90vOdt5mMAxXLGlkFHdQWG7IQtKgLegQIExAB&biw=1745&bih=908&dpr=1.1
- https:/sequencing.qcfail.com/articles/mispriming-in-pbat-libraries-causes-methylation-bias-and-poor-mapping-efficiencies/
- consider https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html#6_Frequently_Asked_Questions

******* EM-seq cfDNA copy number alteration
EM-seq protects 5mC and 5hmC from damination with TET2 enzymatic oxidation. Unprotected cytosines are deaminated to uracils.

******* DMR
https:/www.bioconductor.org/packages/release/bioc/vignettes/dmrseq/inst/doc/dmrseq.html
https:/huishenlab.github.io/biscuit/docs/methylextraction.html
https:/bioconductor.org/packages/release/bioc/html/DSS.html
https:/ziemann-lab.net/public/guppy_methylseq/PCAanalysis.html


#+begin_src python
from pathlib import Path
import pandas as pd

pileup_dir = Path("/tmp/breast/analysis/emseq/pileup")
out_suffix = "_methylkit.tsv"

for bedfile in pileup_dir.glob("*_pileup.bed"):
    df = pd.read_csv(bedfile, sep="\t", header=None,
                     names=["chr", "start", "end", "meth_ratio", "coverage"])
    df["pos"] = df["start"] + 1  # methylKit expects 1-based coordinate
    df["strand"] = "+"
    df["num_mC"] = (df["meth_ratio"] * df["coverage"]).round().astype(int)
    df["num_C"] = df["coverage"] - df["num_mC"]

    out_df = df[["chr", "pos", "strand", "coverage", "num_mC", "num_C"]]

    outfile = bedfile.with_name(bedfile.stem.replace("_pileup", "") + out_suffix)
    out_df.to_csv(outfile, sep="\t", header=False, index=False)

#+end_src
        bismark = lambda wildcards: expand(f"{emseq_dir}/pileup/{{library_id}}_bismark_cov.bed",
                                           library = meth_map[wildcards.experiment]['libs']),


#+begin_src bash
Rscript ~/repos/emseq/scripts/make_single_methylkit_obj.R \
	--bismark_cov_bed "/tmp/breast/analysis/emseq/pileup/NH_11_bismark_cov.bed" \
	--library_id "NH_11" \
	--treatment 0 \
	--mincov 2 \
	--out_dir "/tmp/breast/analysis/emseq/dmr/tabix"

#+end_src


#+begin_src R
file.list = list()

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_bismark_cov.bed",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 sample.id = "TEST",
                 assembly="hg38")

file.list =list(
  "/tmp/breast/analysis/emseq/pileup/PRO_13_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/NH_11_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/PRO_10_bismark_cov.bed",
  "/tmp/breast/analysis/emseq/pileup/NH_13_bismark_cov.bed")


myobj = methRead(file.list,
                 sample.id=list("test1","ctrl1","test2","ctrl2"),
                 treatment=c(1,0,1,0),
                 context="CpG",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 assembly="hg38")

myobj

myobj = methRead(file.list,
                 sample.id=list("test1","ctrl1","test2","ctrl2"),
                 treatment=c(1,0,1,0),
                 context="CpG",
                 pipeline="bismarkCoverage",
                 mincov = 2,
                 assembly="hg38",
                 dbtype = "tabix",
                 dbdir = "/tmp/breast/analysis/emseq/pileup")

print(myobj[[1]]@dbpath)

#########1#########2#########3#########4#########5#########6#########7#########8

library(methylKit)

myobj = methRead(
  location = list("/tmp/breast/analysis/emseq/dmr/tabix/NH_11.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/NH_13.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/PRO_10.txt.bgz",
                  "/tmp/breast/analysis/emseq/dmr/tabix/PRO_13.txt.bgz"),
  sample.id = list("NH_11", "NH_13", "PRO_10", "PRO_13"),
  treatment = c(1, 1, 0, 0),
  context = "CpG",
  assembly = "hg38",
  dbtype = "tabix",
)

myobj[1]

getMethylationStats(myobj[[2]],plot=FALSE,both.strands=FALSE)


getMethylationStats(myobj[[2]],plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj[[2]],plot=TRUE,both.strands=FALSE)

#
filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)
# ERRORS if no reads match

meth=unite(myobj, destrand = F)

head(meth)

getCorrelation(meth, plot = T)

clusterSamples(meth, dist="correlation", method="ward", plot=TRUE)

hc = clusterSamples(meth, dist="correlation", method="ward", plot=FALSE)

PCASamples(meth)
myobj

myDiff=calculateDiffMeth(meth)

diffMethPerChr(myDiff,plot=T, qvalue.cutoff=.5, meth.cutoff=3)

myDiff=calculateDiffMeth(meth,mc.cores=2)

library(tibble)

pvals_tbl <- getData(myDiff) |>
  as_tibble()

pvals_tbl %>% sort(qvalue)

|>
  select(pvalue)

# read the files to a methylRawListDB object: myobjDB
# and save in databases in folder methylDB


myobjDB=methRead(file.list,
           sample.id=list("test1","ctrl1","test2","ctrl2"),
           assembly="hg38",
           treatment=c(1,0,1,0),
           context="CpG",
           dbtype = "tabix",
           dbdir = "/tmp/breast/analysis/emseq/pileup"
           )

print(myobjDB[[1]]@dbpath)

getMethylationStats(myobj,plot=TRUE,both.strands=FALSE)


getCoverageStats(myobj,plot=TRUE,both.strands=FALSE)

filtered.myobj=filterByCoverage(myobj,lo.count=10,lo.perc=NULL,
                                hi.count=NULL,hi.perc=99.9)

filtered.myobj

obj=read("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",sample.id="test",assembly="hg38",header=FALSE, context="CpG", resolution="base",
          pipeline=list(fraction=TRUE,chr.col=1,start.col=2,end.col=2,
                        coverage.col=4,strand.col=3,freqC.col=5 )
        )

obj

methRead()

library(methylKit)

help(methRead)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = TRUE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    freqC.col = 5
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv", header = FALSE)
str(df)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    fraction = FALSE,
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    coverage.col = 4,
    strand.col = 3,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


file.list <- list(
  "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  "/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit.tsv"
)

# read the files to a methylRawList object: myobj
myobj=methRead(file.list,
           sample.id=list("test1","ctrl1"),
           assembly="hg38",
           treatment=c(1,0),
           context="CpG",
           mincov = 2
           )


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "generic",
  header = FALSE
)


samples <- methRead(
  file.list,
  sample.id = c("NH22", "PRO_13"),
  assembly = "hg38",
  treatment = c(0, 1),
  context = "CpG",
  pipeline = "bismarkCoverage",
  header = FALSE
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    context.col = NULL,
    context.filter = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    fraction = FALSE
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_methylkit.tsv",
  sample.id = "test",
  assembly = "hg38",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 2,
    strand.col = 3,
    coverage.col = 4,
    numCs.col = 5,
    numTs.col = 6,
    column.names = c("chr", "start", "strand", "coverage", "numCs", "numTs")
  ),
  header = FALSE,
  context = "CpG",
  resolution = "base"
)

library(methylKit)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_like.tsv", header=FALSE, sep="\t", stringsAsFactors=FALSE)
str(df)

df <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                 sep = "\t", header = FALSE, colClasses = c("character", "integer", "integer", "integer", "integer", "character"))

obj <- methRead(df,
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  resolution = "base"
)


write.table(df, "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean2.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)

obj <- methRead(
  location = "NH22_bismark_clean2.tsv",
  sample.id = "NH22",
  assembly = "hg38",
  treatment = 0,
  context = "CpG",
  pipeline = "bismark",
  header = FALSE,
  resolution = "base"
)

head(df)


obj=methRead("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
         sample.id="test",
         assembly="hg38",
         header=FALSE,
         context="CpG",
         resolution="base",
         pipeline=list(fraction=FALSE,
                       chr.col=1,
                       start.col=2,
                       end.col=3,
                       coverage.col=4,
                       strand.col=6,
                       freqC.col=5 )
        )


obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  context = "CpG",
  resolution = "base",
  treatment = 0,
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    meth.col = 4,
    unmeth.col = 5,
    strand.col = 6
  )
)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  pipeline = "bismark"
)

# Read in your original data
data <- read.table("/tmp/breast/analysis/emseq/pileup/NH22_bismark_clean.tsv",
                  header = FALSE,
                  col.names = c("chr", "start", "end", "meth", "unmeth", "strand"))

# Calculate total coverage and methylation percentage
data$coverage <- data$meth + data$unmeth
data$methPercent <- round(data$meth / data$coverage * 100, 2)

# Write to a new file in methylKit-compatible format
write.table(data[, c("chr", "start", "end", "strand", "coverage", "methPercent")],
            file = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
            quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

obj <- methRead(
  location = "/tmp/breast/analysis/emseq/pileup/NH22_converted.tsv",
  sample.id = "test",
  assembly = "hg38",
  header = FALSE,
  treatment = 0,
  context = "CpG",
  resolution = "base",
  pipeline = list(
    chr.col = 1,
    start.col = 2,
    end.col = 3,
    strand.col = 4,
    coverage.col = 5,
    freqC.col = 6
  )
)


generic.file=system.file("extdata", "generic1.CpG.txt",package = "methylKit")
read.table(generic.file,header=TRUE)

test= read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=T)

head(test)

# And this is how you can read that generic file as a methylKit object
myobj=methRead(test,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj

nrow(read.table("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv", header=TRUE))  # should match wc -l minus 1

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

# And this is how you can read that generic file as a methylKit object
myobj=methRead( generic.file,
               pipeline=list(fraction=FALSE,
                             chr.col=1,
                             start.col=2,
                             end.col=2,
                             coverage.col=4,
                             strand.col=3,
                             freqC.col=5),
               sample.id="test1",assembly="hg38")


myobj
# This creates tabix files that save methylation

myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_patched.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")
myobj



myobj = methRead("/tmp/breast/analysis/emseq/pileup/PRO_13_methylkit_formatted.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1",
                 mincov = 1,
                 assembly="hg38")




myobj = methRead("/tmp/breast/analysis/emseq/pileup/test.tsv",
                 pipeline=list(fraction=FALSE,
                               chr.col=1,
                               start.col=2,
                               end.col=2,
                               coverage.col=4,
                               strand.col=3,
                               freqC.col=5),
                 sample.id="test1", assembly="hg38")

#+end_src


#+begin_src R
library(methylKit)
library(tidyverse)

meth <- methylKit:::readMethylBaseDB("/tmp/breast/analysis/emseq/dmr/tabix/methylBase_108f6516736d92.txt.bgz")

meth



# Get percent methylation matrix
meth_matrix <- percMethylation(meth)

head(meth_matrix)

clin = data.frame(library_id = c("NH_11","NH_13","PRO_10","PRO_13"),
           cohort = c("healthy","healthy","progressor","progressor"))

# Compute global methylation (mean per sample)
global_df <- meth_matrix %>%
  as.data.frame() %>%
  pivot_longer(cols = everything(), names_to = "library_id", values_to = "methylation") %>%
  group_by(library_id) %>%
  summarise(global_methylation = mean(methylation, na.rm = TRUE)) %>%
  left_join(clin, by = "library_id")

global_df



# Violin plot (one point per library, jittered for clarity)
ggplot(global_df, aes(x = cohort, y = global_methylation, fill = cohort)) +
  geom_violin(width = 1.0, trim = TRUE, alpha = 0.4) +
  geom_jitter(width = 0.1, size = 2) +
  theme_minimal() +
  labs(title = "Global Methylation per Library",
       y = "Mean % Methylation",
       x = "Group")


# Melt to long format
meth_df <- meth_matrix %>%
  as.data.frame() %>%
  rownames_to_column("CpG") %>%
  pivot_longer(-CpG, names_to = "library_id", values_to = "methylation")

head(meth_df)

# Add group info
meth_df <- left_join(meth_df, sample_metadata, by = "library_id")  # sample_metadata must have `library_id` and `group`

# Violin plot
ggplot(meth_df, aes(x = group, y = methylation, fill = group)) +
  geom_violin(scale = "width", trim = TRUE) +
  facet_wrap(~library_id, nrow = 1) +
  theme_minimal() +
  labs(title = "Global Methylation per Library", y = "% Methylation", x = "Group")

#+end_src



** Testing
- https://chatgpt.com/c/68ceb2e8-4d64-832a-9bc2-8bc08c9d37b3

#+begin_src snakemake

# Development snakemake to test
mosdepth_quant_levels = config["mosdepth-quant-levels"]
repo = "~/repos/emseq"
data_dir=config["data_dir"]
emseq_script_dir = "~/repos/emseq/scripts"
log_dir = f"{data_dir}/logs"

emseq_mincov = 2
emseq_build = "hg38"

threads = 80
# We specify em-seq bam directory directly to allow for workflows that merge at the bam level:
emseq_bam_dir = f"{data_dir}/analysis/emseq/bams"


# Explicitly select which references to build
index_targets = ["unmeth_lambda", "puc19"]

library_ids = ["NH_15_L3", "PRO_6_L2"]

spike_ref_names = ["unmeth_lambda"]

ref_names = ["ncbi_decoy_hg38"]

align_methods = ["bwa_meth"]

emseq_library_ids = library_ids

meth_map = {
    "test": {
        "build": "hg38",
        "mincov": "5",
        "libs": library_ids,
        "tx": "0,1"
}
}


mosdepth_map = {
    "tests": {
        "library_ids": ["NH_15_L3", "PRO_6_L2"],
        "ref_name": "ncbi_decoy_hg38",
        "align_method": "bwa_meth"
    }
}

rule all:
    input:
        # FASTQs
        expand(f"{data_dir}/analysis/emseq/fastqs/{{library_id}}_{{processing}}_{{read}}.fastq.gz",
               library_id = library_ids,
               processing = ["raw","trimmed"],
               read = ["R1","R2"]),

        expand(f"{data_dir}/qc/{{library_id}}_{{processing}}_{{read}}_fastqc.{{suffix}}",
               library_id = library_ids,
               processing = ["raw","trimmed"],
               read = ["R1","R2"],
               suffix = ["zip","html"]),

        # Spike-ins
        expand(f"{data_dir}/analysis/emseq/spike/{{library_id}}.{{ref_name}}.bwa_meth.coorsort.bam",
               library_id = library_ids,
               ref_name = spike_ref_names,
               align_method = "bwa_meth"),

        expand(f"{data_dir}/analysis/emseq/spike/{{library_id}}.{{ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
               library_id=library_ids,
               ref_name=spike_ref_names,
               align_method= "bwa_meth"),

        # Biscuit 1 steps
        ## Index
        expand(f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.fai",
               name = "ncbi_decoy_hg38"),

        ## Align
        expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
               library_id = library_ids,
               ref_name = ref_names),

        # BWA-meth
        # ## Index
        # expand(f"{data_dir}/ref/bwa_meth/{{name}}/{{name}}.fa.bwameth.c2t",
        #        name = ref_names),

        # ## Align

        # expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.bwa_meth.coorsort.bam",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        align_method = "bwa_meth"),

        ## COMMON DEDUP HERE

        ## Pileup
        # expand(f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.{{suffix}}",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        suffix = ["vcf.gz","vcf_meth_average.tsv"]),

        # ## Make per-library methylkit objects
        # expand(f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.{{suffix}}",
        #        library_id = library_ids,
        #        ref_name = ref_names,
        #        suffix = ["txt", "txt.bgz", "txt.bgz.tbi"]),

        # Common post-alignment per-library steps
        ## Deduplicate
        expand(f"{emseq_bam_dir}/{{library_id}}.{{ref_name}}.{{align_method}}.coorsort.deduped.bam",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit","bwa_meth"]),

        ## Depth
        expand(f"{data_dir}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.mosdepth.summary.txt",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit","bwa_meth"]),

        ## Call methylation
        expand(f"{data_dir}/analysis/emseq/meth/{{library_id}}.{{ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = ["biscuit", "bwa_meth"]),

        ## Create per-library methylkit objects
        expand(f"{data_dir}/analysis/emseq/dmr/tabix/{{library_id}}.{{ref_name}}.{{align_method}}.txt",
               library_id = library_ids,
               ref_name = ref_names,
               align_method = "bwa_meth"),

        expand(f"{data_dir}/qc/{{experiment}}.emseq_mosdepth_agg_plot.pdf",
               experiment = mosdepth_map.keys()),





#+end_src
*** Full test
**** Configuration yaml
#+begin_src yaml :tangle ./config/test.yaml
# -----------------------------
# Global runtime/config knobs
# -----------------------------
available-concurrency: 50
threads: 24
main-data-dir: "tests/full"
mosdepth-quant-levels: "1,5"
emseq-mincov: 2

# -----------------------------
# Environments and repositories
# -----------------------------
envs:
  emseq: "../config/emseq-conda-env.yaml"
  methylkit: "../config/methylkit-conda-env.yaml"
repos:
  emseq: "."

# -----------------------------
# Sample set and region filters
# -----------------------------
library-ids: ["lib001", "lib002", "lib003", "lib004"]
keep-bed: "tests/full/inputs/chr22.keep.bed"
exclude-bed: "tests/full/inputs/chr22.exclude.blacklist.bed.gz"

# -----------------------------
# Reference assemblies (primary + spike)
# -----------------------------
emseq_ref_assemblies:
  chr22:
    url: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
    name: chr22
    input: chr22.test.fa.gz
  unmeth_lambda:
    url: https://www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/lambdafsa.txt?rev=c0c6669b9bd340ddb674ebfd9d55c691&hash=7E6375924CFF9457D0157D0D87C9AC19
    name: unmeth_lambda
    input: lambda.fa.gz
  puc19:
    url: https://www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/puc19fsa.txt?rev=6e10f4c4a4234d638e401cd2f4578ef0&hash=E71970068EEA191C175B3458DB99D7BB
    name: puc19
    input: pUC19.fa.gz

# -----------------------------
# Experiments (differential methylation experiments for methylKit)
# NOTE: lib003 is intentionally duplicated to ensure overlapping CpG sites
# across samples in this minimal test dataset for methylKit unite/diff testing.
# -----------------------------
meth-map:
  test:
    libs: ["lib001", "lib003", "lib003", "lib004"]
    emseq_ref_name: ["chr22"]
    align_method: ["bwa_meth"]
    tx: [0, 0, 1, 1]
    mincov: 10
    mingroup: 1
    chunksize: "1e9"
    win_size: 10000
#+end_src

**** Snakefile
#+begin_src snakemake :tangle ./workflows/test.smk
# -----------------------------
# Imports
# -----------------------------
import os

# -----------------------------
# Path expansion for strings in config (~, $VARS)
# -----------------------------
def resolve_config_paths(config_dict):
    for k, v in config_dict.items():
        if isinstance(v, str):
            config_dict[k] = os.path.expandvars(os.path.expanduser(v))
        elif isinstance(v, dict):
            resolve_config_paths(v)
        elif isinstance(v, list):
            config_dict[k] = [os.path.expandvars(os.path.expanduser(i)) if isinstance(i, str) else i for i in v]

resolve_config_paths(config)

# -----------------------------
# Environments
# -----------------------------
ENV_EMSEQ = config['envs']['emseq']
ENV_METHYLKIT = config['envs']['methylkit']

# -----------------------------
# Repositories
# -----------------------------
R_EMSEQ = config['repos']['emseq']

# -----------------------------
# Data directories (derived from main-data-dir)
# -----------------------------
D_DATA = config['main-data-dir']
D_EMSEQ = f"{D_DATA}/emseq"
D_REF = f"{D_DATA}/ref"
D_LOGS = f"{D_DATA}/logs"
D_BENCHMARK = f"{D_DATA}/benchmark"
D_INPUTS = f"{D_DATA}/inputs"

# -----------------------------
# Tool/global params (UPPERCASE for module consumption)
# -----------------------------
MOSDEPTH_QUANT_LEVELS = config.get("mosdepth-quant-levels", "1,5,10,20")
EMSEQ_MINCOV = config.get("emseq-mincov", 2)
FASTP_EXTRA = config.get("fastp", {}).get("extra", "")

# -----------------------------
# Reference assembly lookup (for index rules)
# -----------------------------
EMSEQ_REF_INPUTS = {k: v['input'] for k, v in config['emseq_ref_assemblies'].items()}

# -----------------------------
# Sample set (required by emseq.smk)
# -----------------------------
emseq_library_ids = config["library-ids"]

# -----------------------------
# Reference selections (kept explicit)
# -----------------------------
spike_builds = ["puc19", "unmeth_lambda"]
emseq_ref_names = ["chr22"]

# -----------------------------
# Region filtering inputs
# -----------------------------
KEEP_BED = config["keep-bed"]
EXCL_BED = config["exclude-bed"]

# -----------------------------
# Experiments map from YAML
# (differential methylation experiments for methylKit)
# -----------------------------
meth_map = config["meth-map"]

# -----------------------------
# Rule all
# -----------------------------
rule all:
    input:
        # FASTQs
        expand(
            f"{D_EMSEQ}/fastqs/{{library_id}}.trimmed_{{read}}.fastq.gz",
            library_id=emseq_library_ids,
            read=["R1", "R2"],
        ),
        # Alignment and methylation calling
        expand(
            f"{D_EMSEQ}/dmr/tabix/{{library_id}}.{{emseq_ref_name}}.{{align_method}}.methyldackel.txt.bgz",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["bwa_meth", "biscuit"],
        ),
        # Spike workflow
        expand(
            f"{D_EMSEQ}/spike/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_methyldackel_CpG.methylKit",
            library_id=emseq_library_ids,
            emseq_ref_name=spike_builds,
            align_method="bwa_meth",
        ),
        # QC - FastQC
        expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{processing}}_{{read}}_fastqc.zip",
            library_id=emseq_library_ids,
            processing=["raw", "trimmed"],
            read=["R1", "R2"],
        ),
        # QC - mosdepth
        expand(
            f"{D_EMSEQ}/qc/mosdepth_{{library_id}}.{{emseq_ref_name}}.{{align_method}}.mosdepth.summary.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["bwa_meth", "biscuit"],
        ),
        # QC - M-bias
        expand(
            f"{D_EMSEQ}/qc/{{library_id}}.{{emseq_ref_name}}.{{align_method}}_emseq_mbias.txt",
            library_id=emseq_library_ids,
            emseq_ref_name=emseq_ref_names,
            align_method=["bwa_meth", "biscuit"],
        ),
        # QC - MultiQC (does NOT prompt inputs to run)
        f"{D_EMSEQ}/qc/multiqc.html",
        # MethylKit - per-base
        expand(
            f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.txt.bgz",
            experiment=meth_map.keys(),
        ),
        expand(
            f"{D_EMSEQ}/dmr/diff/methylDiff_{{experiment}}.txt.bgz",
            experiment=meth_map.keys(),
        ),
        # MethylKit - tiled
        expand(
            f"{D_EMSEQ}/dmr/diff/methylBase_{{experiment}}.tiled.txt.bgz",
            experiment=meth_map.keys(),
        ),

# -----------------------------
# Input symlinks
# -----------------------------
rule symlink_input_fastqs:
    message: "Create symlinks for raw input FASTQs into workflow directory"
    input:
        r1 = f"{D_INPUTS}/{{library_id}}.raw_R1.fastq.gz",
        r2 = f"{D_INPUTS}/{{library_id}}.raw_R2.fastq.gz",
    log:
        cmd = f"{D_LOGS}/{{library_id}}_symlink_input_fastqs.log",
    benchmark:
        f"{D_BENCHMARK}/{{library_id}}_symlink_input_fastqs.tsv"
    output:
        r1 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R1.fastq.gz",
        r2 = f"{D_EMSEQ}/fastqs/{{library_id}}.raw_R2.fastq.gz",
    shell:
        """
        exec &>> "{log.cmd}"
        echo "[symlink-fastqs] $(date) lib={wildcards.library_id}"
        mkdir -p "$(dirname "{output.r1}")"
        ln -sfr "{input.r1}" "{output.r1}"
        ln -sfr "{input.r2}" "{output.r2}"
        """

# -----------------------------
# Include module
# -----------------------------
include: "emseq.smk"
#+end_src

*** Example wrapper

#+begin_src yaml :tangle ./config/example-config.yaml
data_dir: /mnt/data/projects/breast
emseq_ref_assemblies:
  ncbi_decoy_hg38:
    url: https:/ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
    name: ncbi_decoy_hg38
    input: GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fa.gz

  ensembl_hg38:
    url: https:/ftp.ensembl.org/pub/release-113/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
    name: ensembl_hg38
    input: Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz

  unmeth_lambda:
    url: https:/www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/lambdafsa.txt?rev=c0c6669b9bd340ddb674ebfd9d55c691&hash=7E6375924CFF9457D0157D0D87C9AC19
    name: unmeth_lambda
    input: Lambda_NEB.fa.gz

  puc19:
    url: https:/www.neb.com/en-us/-/media/nebus/page-images/tools-and-resources/interactive-tools/dna-sequences-and-maps/text-documents/puc19fsa.txt?rev=6e10f4c4a4234d638e401cd2f4578ef0&hash=E71970068EEA191C175B3458DB99D7BB
    name: puc19
    input: pUC19.fa.gz


mosdepth-quant-levels: "1,5,10,20,30"

#+end_src

#+begin_src bash
conda activate biotools

cd ~/repos/emseq
data_dir=/mnt/data/projects/nf1

mkdir -p $data_dir/inputs

config_yaml=config/test.yaml

config_yaml=config/example-config.yaml

url=$(yqgo '.emseq_ref_assemblies.puc19.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.puc19.input' "$config_yaml") && \
wget -O - --user-agent="Mozilla/5.0" --referer="https:/www.neb.com" "$url" | \
  gzip > "$data_dir/inputs/$outfile"


url=$(yqgo '.emseq_ref_assemblies.unmeth_lambda.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.unmeth_lambda.input' "$config_yaml") && \
wget -O - --user-agent="Mozilla/5.0" --referer="https:/www.neb.com" "$url" | \
  gzip > "$data_dir/inputs/$outfile"


url=$(yqgo '.emseq_ref_assemblies.ncbi_decoy_hg38.url' "$config_yaml") && \
outfile=$(yqgo '.emseq_ref_assemblies.ncbi_decoy_hg38.input' "$config_yaml") && \
wget -O "$data_dir/inputs/$outfile" "$url"


#+end_src


#+begin_src snakemake :tangle ./workflows/test-wrap.smk

repo = "~/repos/emseq"
data_dir=config["data_dir"]

# Explicitly select which references to build
index_targets = ["unmeth_lambda", "puc19"]

rule all:
    input:
        expand(f"{data_dir}/ref/{{name}}.fa.bwameth.c2t", name=index_targets)


include: f"{repo}/workflows/dev.smk"

#+end_src
** Reference
- [[id:79dfda7e-8b6d-45c7-88d5-804979155763][cfDNA methylation]]
- Alternative cfDNA WGMS profiling
  - TET-Assisted Pyridine Borane Sequencing (TAPS) [cite:@vavoulis2025]
- https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41587-022-01652-0
- Alignment reference choice
  - discussion [[https:/chatgpt.com/c/67c1c299-f8ec-8005-a2ba-59e05af12369][gtp]]
  - see [[id:326ecd60-8cd4-4815-a389-967b2c3fef0a][Nucleic acid sequence alignment]]
- [cite:@vaisvila2021]
- [cite:@chauhan2024]
- [[id:5e9e8bfa-ac9e-4103-9cc5-7123337b4e24][biscuit]]
- https:/github.com/semenko/serpent-methylation-pipeline
- EM-seq protects 5mC and 5hmC from damination with TET2 enzymatic oxidation. Unprotected cytosines are deaminated to uracils.
- cfDNA WGBS hypomethylation and CNAs as a general cancer marker [cite:@chan2013meth]
- [cite:@chan2013meth]
  - [cite:@liu2020]
  - [cite:@shen2018plasma]
    - [cite:@liang2021meth]
    - [cite:@shen2019cfmedip]
    - [cite:@nuzzo2020] *
    - [cite:@nassiri2020] *
  - [cite:@li20175hmc]
  - [cite:@song20175hmc]
  - [cite:@li2018meth]
    - [cite:@liang2021meth]
    - [cite:@hlady2019]
    - [cite:@moss2020]
    - [cite:@stackpole2022]
      - [cite:@wong2023]
      - [cite:@li2023cfdna]
      - [cite:@melton2023]
    - [cite:@wu2020]
    - [cite:@delvecchio2020]


- [cite:@bie2023]
https:/www-pnas-org.mclibrary.idm.oclc.org/doi/full/10.1073/pnas.2017421118#sec-3
https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41551-021-00746-5#Sec11

https:/www-nature-com.mclibrary.idm.oclc.org/articles/s41586-022-05580-6

[cite:@melton2023]

https:/www-scopus-com.mclibrary.idm.oclc.org/results/results.uri?sort=cp-f&src=s&sid=02157e5ff2f1b8a77a24e67aeefcb07b&sot=a&sdt=a&cluster=scosubtype%2C%22ar%22%2Ct&sl=76&s=%28TITLE-ABS-KEY%28%22cell-free+DNA%22%29+AND+TITLE-ABS-KEY%28methylation%29%29+AND+NOT%28PCR%29&origin=searchadvanced&editSaveSearch=&txGid=3b8b26bec1c779cef84de4d3803c1be9&sessionSearchId=02157e5ff2f1b8a77a24e67aeefcb07b&limit=10

https:/www-nature-com.mclibrary.idm.oclc.org/articles/ng.3805

| article             | group      | platform    | depth | tissue | target | times cited | date |
|---------------------+------------+-------------+-------+--------+--------+-------------+------|
| [cite:@nassiri2020] | decarvalho | cfMeDIP-seq |       | CNS    | CNS    |             |      |

Original EM-seq methods paper - [cite:@vaisvila2021]. Code is in the repo at [[file:resources/EM-seq-master/]]


EM-seq and WGBS are not compatible- have different unique methylated CpGs at 8x [[/home/jeszyman/repos/emseq/emseq.org_20250605_135724.png][./resources/vaisvila2021fig4c.png]]
** Ideas
- Prerequisites in readme
- linter ci https://chatgpt.com/c/68ce07ea-83fc-8326-bd29-774b8da4d25c
- The emseq_bam_dir is individually declared. This allows for workflows where multiple sequencing lanes are merged per-sample at the bam level.
- config optinos as switches
- Mosdepth aggregator
  #+begin_src snakemake :tangle no
print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        thresholds = expand(f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.thresholds.bed.gz",
                            library_id=emseq_library_ids),
        regions = expand(f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{{ref_name}}.{{align_method}}.regions.bed.gz",
                         library_id=emseq_library_ids),
    output:
        pdf = f"{qc_dir}/emseq_mosdepth_agg_plot.pdf",
        tsv = f"{qc_dir}/emseq_mosdepth_agg.tsv",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf} \
        --output_tsv {output.tsv}
        """

#+end_src
  #+begin_src snakemake :tangle no

def flatten(x):
    return [item for sublist in x for item in (sublist if isinstance(sublist, list) else [sublist])]

print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        threshold_list = lambda wildcards, input: " ".join(flatten(input.thresholds)),
        regions_list = lambda wildcards, input: " ".join(flatten(input.regions)),
    output:
        pdf = f"{qc_dir}/mosdepth_agg_plot.pdf",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src

  #+begin_src snakemake
rule emseq_mosdepth_agg_plot:
    conda:
        "../config/mosdepth-conda-env.yaml",
    input:
        thresholds = lambda wildcards: expand(
            f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{mosdepth_map[wildcards.experiment]['ref_name']}."
            f"{mosdepth_map[wildcards.experiment]['align_method']}.thresholds.bed.gz",
            library_id=mosdepth_map[wildcards.experiment]['library_ids']
        ),
        regions = lambda wildcards: expand(
            f"{config['emseq-dir']}/qc/mosdepth_{{library_id}}.{mosdepth_map[wildcards.experiment]['ref_name']}."
            f"{mosdepth_map[wildcards.experiment]['align_method']}.regions.bed.gz",
            library_id=mosdepth_map[wildcards.experiment]['library_ids']
        )
    output:
        pdf = f"{config['emseq-dir']}/qc/{{experiment}}.emseq_mosdepth_agg_plot.pdf",
        tsv = f"{config['emseq-dir']}/qc/{{experiment}}.emseq_mosdepth_agg.tsv",
    params:
        script = f"{config['emseq-script-dir']}/emseq_mosdepth_agg_plot.R",
        library_list = lambda wildcards: " ".join(mosdepth_map[wildcards.experiment]['library_ids']),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf} \
        --output_tsv {output.tsv}
        """

#+end_src

  #+begin_src R :tangle no
#!/usr/bin/env Rscript

# ==============================================================================
# Description:
#   Parses multiple mosdepth threshold files (*.thresholds.bed.gz) and generates
#   a single paginated PDF plot (4Ã—6 panels per page) showing counts of bases
#   covered at actual observed thresholds (e.g., 1X, 2X, 5X...) per sample.
#
#   Infers 0X bins by identifying regions where all threshold counts are zero.
#
# Inputs:
#   --threshold_list   Space-separated list of mosdepth threshold files
#   --library_list     Space-separated list of sample names (must match order)
#   --output_pdf       Full path to output PDF file (single file, multi-page)
# ==============================================================================

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
})


suppressWarnings(library(matrixStats))  # at top


# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (length(threshold_files) != length(library_ids)) {
  stop("Error: threshold_list and library_list must be the same length")
}

# -------------------------------
# Function to parse each threshold file
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

# -------------------------------
# Read and combine all files
# -------------------------------

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Compute median depth per sample
# -------------------------------

hist_data[, threshold_numeric := as.numeric(sub("X$", "", threshold))]
medians <- hist_data[!is.na(threshold_numeric),
  .(median = weightedMedian(threshold_numeric, w = count)),
  by = sample]


# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

# Correct threshold order based on numeric prefix
threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Panel layout and plotting
# -------------------------------

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id, median]
  subtitle <- sprintf("Median depth: %.1fÃ—", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output: single PDF with multiple pages
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()

#+end_src
  #+begin_src R :tangle no
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
  suppressWarnings(library(matrixStats))
})

# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--regions_list", required = TRUE,
                    help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
regions_files <- unlist(strsplit(args$regions_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
  stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
}

# -------------------------------
# Read and melt threshold files
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
hist_data[, count := as.numeric(count)]

all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Read autosomal median from regions.bed.gz
# -------------------------------

get_autosomal_median <- function(file, sample_id) {
  df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
  df <- df[chrom %in% as.character(1:22)]
  df[, sample := sample_id]
  df[, median := median(depth)]
  df[1, .(sample, median)]
}

medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Plot panels
# -------------------------------
print(medians)

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id][["median"]]
  subtitle <- sprintf("Median depth: %.1fÃ—", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()
#+end_src
  - [[file:scripts/emseq_mosdepth_agg_plot.R]]
    #+begin_src R :tangle ./scripts/emseq_mosdepth_agg_plot.R
  #!/usr/bin/env Rscript

  suppressPackageStartupMessages({
    suppressWarnings(library(argparse))
    suppressWarnings(library(data.table))
    suppressWarnings(library(ggplot2))
    suppressWarnings(library(Cairo))
    suppressWarnings(library(scales))
    suppressWarnings(library(patchwork))
    suppressWarnings(library(matrixStats))
  })

  # -------------------------------
  # Argument parsing
  # -------------------------------

  prog <- basename(commandArgs(trailingOnly = FALSE)[1])

  parser <- ArgumentParser(
    description = "Generate a paginated threshold coverage plot from mosdepth output.",
    prog = prog
  )

  parser$add_argument("--threshold_list", required = TRUE,
                      help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
  parser$add_argument("--regions_list", required = TRUE,
                      help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
  parser$add_argument("--library_list", required = TRUE,
                      help = "Space-separated list of sample names (must match file order)")
  parser$add_argument("--output_pdf", required = TRUE,
                      help = "Full output PDF file path (e.g., /tmp/plot.pdf)")
  parser$add_argument("--output_tsv", required = TRUE,
                      help = "Path for tabular output")

  args <- parser$parse_args()
  threshold_files <- unlist(strsplit(args$threshold_list, " "))
  regions_files <- unlist(strsplit(args$regions_list, " "))
  library_ids <- unlist(strsplit(args$library_list, " "))
  output_tsv <- args$output_tsv
  output_pdf <- args$output_pdf

  if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
    stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
  }

  # -------------------------------
  # Read and melt threshold files
  # -------------------------------

  read_thresholds <- function(file, sample) {
    header <- fread(file, nrows = 0)
    names(header)[1] <- sub("^#", "", names(header)[1])
    threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
    df <- fread(file, skip = 1, col.names = names(header))
    df[, sample := sample]
    melted <- melt(df,
      id.vars = c("chrom", "start", "end", "region", "sample"),
      measure.vars = threshold_cols,
      variable.name = "threshold",
      value.name = "count"
    )
    list(data = melted, thresholds = threshold_cols)
  }

  parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
  hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
  hist_data[, count := as.numeric(count)]

  all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

  # -------------------------------
  # Read autosomal median from regions.bed.gz
  # -------------------------------

  get_autosomal_median <- function(file, sample_id) {
    df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
    df <- df[chrom %in% paste0("chr", 1:22)]
    df[, sample := sample_id]
    df[, median := median(depth)]
    df[1, .(sample, median)]
  }

  medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

  # -------------------------------
  # Infer 0X bins from zeroed rows
  # -------------------------------

  hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                     value.var = "count", fill = 0)
  hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
  zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
  zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
  zero_counts[, threshold := "0X"]

  # -------------------------------
  # Aggregate and bind all data
  # -------------------------------

  plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
  plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

  threshold_levels <- unique(plot_data$threshold)
  threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
  plot_data[, threshold := factor(threshold, levels = threshold_levels)]

  # -------------------------------
  # Plot panels
  # -------------------------------
  print(medians)

  make_panel <- function(sample_id) {
    median_val <- medians[sample == sample_id][["median"]]
    subtitle <- sprintf("Median depth: %.1fÃ—", median_val)

    ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
      geom_col(width = 0.8) +
      scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
      scale_fill_brewer(palette = "Set2", guide = "none") +
      labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
      theme_minimal(base_size = 10) +
      theme(
	axis.text = element_text(size = 8),
	axis.title = element_text(size = 9),
	plot.title = element_text(size = 10, hjust = 0.5),
	plot.subtitle = element_text(size = 9, hjust = 0.5),
	panel.grid = element_line(linewidth = 0.2, colour = "grey90")
      )
  }

  ncol <- 4
  nrow <- 6
  panels_per_page <- ncol * nrow
  sample_list <- unique(plot_data$sample)
  pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

  # -------------------------------
  # Output
  # -------------------------------

  CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
  for (i in seq_along(pages)) {
    plots <- lapply(pages[[i]], make_panel)
    layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
      plot_annotation(
	title = "Coverage threshold by sample",
	theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
      )
    print(layout)
  }
  dev.off()

  fwrite(medians,   file = args$output_tsv, sep = "\t")

  #+end_src
- Copy number integration
  - [cite:@chan2013meth]
  - [cite:@widman2024]
- Annotation
  - https:/bioconductor.org/packages/devel/bioc/vignettes/annotatr/inst/doc/annotatr-vignette.html
  - get nearest TSS
  - get region annotation
- TSS coverage
  - https:/deeptools.readthedocs.io/en/stable/content/tools/plotProfile.html
- state fit for methylation like hyper /hypo of bins
- Mosdepth aggregator
  #+begin_src snakemake
print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        thresholds = expand(f"{data_dir}/qc/mosdepth_{{library_id}}.thresholds.bed.gz", library_id=emseq_library_ids),
        regions = expand(f"{data_dir}/qc/mosdepth_{{library_id}}.regions.bed.gz", library_id=emseq_library_ids),
    output:
        pdf = f"{data_dir}/qc/mosdepth_agg_plot.pdf",
    params:
        script = f"{emseq_script_dir}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src
  #+begin_src snakemake :tangle no

def flatten(x):
    return [item for sublist in x for item in (sublist if isinstance(sublist, list) else [sublist])]

print("emseq_library_ids:", emseq_library_ids)
print("type of first item:", type(emseq_library_ids[0]))

rule emseq_mosdepth_agg_plot:
    input:
        threshold_list = lambda wildcards, input: " ".join(flatten(input.thresholds)),
        regions_list = lambda wildcards, input: " ".join(flatten(input.regions)),
    output:
        pdf = f"{qc_dir}/mosdepth_agg_plot.pdf",
    params:
        script = f"{emseq_script_dir}/emseq_mosdepth_agg_plot.R",
        library_list = " ".join(emseq_library_ids),
        threshold_list = lambda wildcards, input: " ".join(input.thresholds),
        regions_list = lambda wildcards, input: " ".join(input.regions),
    shell:
        """
        Rscript {params.script} \
        --threshold_list "{params.threshold_list}" \
        --regions_list "{params.regions_list}" \
        --library_list "{params.library_list}" \
        --output_pdf {output.pdf}
        """

#+end_src

  #+begin_src R
#!/usr/bin/env Rscript

# ==============================================================================
# Description:
#   Parses multiple mosdepth threshold files (*.thresholds.bed.gz) and generates
#   a single paginated PDF plot (4Ã—6 panels per page) showing counts of bases
#   covered at actual observed thresholds (e.g., 1X, 2X, 5X...) per sample.
#
#   Infers 0X bins by identifying regions where all threshold counts are zero.
#
# Inputs:
#   --threshold_list   Space-separated list of mosdepth threshold files
#   --library_list     Space-separated list of sample names (must match order)
#   --output_pdf       Full path to output PDF file (single file, multi-page)
# ==============================================================================

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
})


suppressWarnings(library(matrixStats))  # at top


# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (length(threshold_files) != length(library_ids)) {
  stop("Error: threshold_list and library_list must be the same length")
}

# -------------------------------
# Function to parse each threshold file
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

# -------------------------------
# Read and combine all files
# -------------------------------

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Compute median depth per sample
# -------------------------------

hist_data[, threshold_numeric := as.numeric(sub("X$", "", threshold))]
medians <- hist_data[!is.na(threshold_numeric),
  .(median = weightedMedian(threshold_numeric, w = count)),
  by = sample]


# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

# Correct threshold order based on numeric prefix
threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Panel layout and plotting
# -------------------------------

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id, median]
  subtitle <- sprintf("Median depth: %.1fÃ—", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output: single PDF with multiple pages
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()

#+end_src
  #+begin_src R :tangle no
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  suppressWarnings(library(argparse))
  suppressWarnings(library(data.table))
  suppressWarnings(library(ggplot2))
  suppressWarnings(library(Cairo))
  suppressWarnings(library(scales))
  suppressWarnings(library(patchwork))
  suppressWarnings(library(matrixStats))
})

# -------------------------------
# Argument parsing
# -------------------------------

prog <- basename(commandArgs(trailingOnly = FALSE)[1])

parser <- ArgumentParser(
  description = "Generate a paginated threshold coverage plot from mosdepth output.",
  prog = prog
)

parser$add_argument("--threshold_list", required = TRUE,
                    help = "Space-separated list of mosdepth threshold files (*.thresholds.bed.gz)")
parser$add_argument("--regions_list", required = TRUE,
                    help = "Space-separated list of mosdepth regions files (*.regions.bed.gz)")
parser$add_argument("--library_list", required = TRUE,
                    help = "Space-separated list of sample names (must match file order)")
parser$add_argument("--output_pdf", required = TRUE,
                    help = "Full output PDF file path (e.g., /tmp/plot.pdf)")

args <- parser$parse_args()
threshold_files <- unlist(strsplit(args$threshold_list, " "))
regions_files <- unlist(strsplit(args$regions_list, " "))
library_ids <- unlist(strsplit(args$library_list, " "))
output_pdf <- args$output_pdf

if (!all(lengths(list(threshold_files, regions_files, library_ids)) == length(library_ids))) {
  stop("Error: threshold_list, regions_list, and library_list must all be the same length.")
}

# -------------------------------
# Read and melt threshold files
# -------------------------------

read_thresholds <- function(file, sample) {
  header <- fread(file, nrows = 0)
  names(header)[1] <- sub("^#", "", names(header)[1])
  threshold_cols <- setdiff(names(header), c("chrom", "start", "end", "region"))
  df <- fread(file, skip = 1, col.names = names(header))
  df[, sample := sample]
  melted <- melt(df,
    id.vars = c("chrom", "start", "end", "region", "sample"),
    measure.vars = threshold_cols,
    variable.name = "threshold",
    value.name = "count"
  )
  list(data = melted, thresholds = threshold_cols)
}

parsed <- mapply(read_thresholds, threshold_files, library_ids, SIMPLIFY = FALSE)
hist_data <- rbindlist(lapply(parsed, `[[`, "data"))
hist_data[, count := as.numeric(count)]

all_thresholds <- unique(unlist(lapply(parsed, `[[`, "thresholds")))

# -------------------------------
# Read autosomal median from regions.bed.gz
# -------------------------------

get_autosomal_median <- function(file, sample_id) {
  df <- fread(file, col.names = c("chrom", "start", "end", "depth"))
  df <- df[chrom %in% as.character(1:22)]
  df[, sample := sample_id]
  df[, median := median(depth)]
  df[1, .(sample, median)]
}

medians <- rbindlist(mapply(get_autosomal_median, regions_files, library_ids, SIMPLIFY = FALSE))

# -------------------------------
# Infer 0X bins from zeroed rows
# -------------------------------

hist_wide <- dcast(hist_data, chrom + start + end + region + sample ~ threshold,
                   value.var = "count", fill = 0)
hist_wide[, is_zero := rowSums(.SD) == 0, .SDcols = all_thresholds]
zero_counts <- hist_data[, .(total = sum(count)), by = .(chrom, start, end, region, sample)]
zero_counts <- zero_counts[total == 0, .(count = .N * (end[1] - start[1])), by = sample]
zero_counts[, threshold := "0X"]

# -------------------------------
# Aggregate and bind all data
# -------------------------------

plot_data <- hist_data[, .(count = sum(count)), by = .(sample, threshold)]
plot_data <- rbind(plot_data, zero_counts, fill = TRUE)

threshold_levels <- unique(plot_data$threshold)
threshold_levels <- threshold_levels[order(as.numeric(sub("X$", "", as.character(threshold_levels))))]
plot_data[, threshold := factor(threshold, levels = threshold_levels)]

# -------------------------------
# Plot panels
# -------------------------------
print(medians)

make_panel <- function(sample_id) {
  median_val <- medians[sample == sample_id][["median"]]
  subtitle <- sprintf("Median depth: %.1fÃ—", median_val)

  ggplot(plot_data[sample == sample_id], aes(x = threshold, y = count, fill = threshold)) +
    geom_col(width = 0.8) +
    scale_y_continuous(labels = label_number(scale_cut = cut_short_scale())) +
    scale_fill_brewer(palette = "Set2", guide = "none") +
    labs(title = sample_id, subtitle = subtitle, x = "Coverage threshold", y = "Covered bases") +
    theme_minimal(base_size = 10) +
    theme(
      axis.text = element_text(size = 8),
      axis.title = element_text(size = 9),
      plot.title = element_text(size = 10, hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5),
      panel.grid = element_line(linewidth = 0.2, colour = "grey90")
    )
}

ncol <- 4
nrow <- 6
panels_per_page <- ncol * nrow
sample_list <- unique(plot_data$sample)
pages <- split(sample_list, ceiling(seq_along(sample_list) / panels_per_page))

# -------------------------------
# Output
# -------------------------------

CairoPDF(output_pdf, width = 8.5, height = 11, onefile = TRUE)
for (i in seq_along(pages)) {
  plots <- lapply(pages[[i]], make_panel)
  layout <- wrap_plots(plots, ncol = ncol, nrow = nrow) +
    plot_annotation(
      title = "Coverage threshold by sample",
      theme = theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
    )
  print(layout)
}
dev.off()
#+end_src
*** Methylkit output annotation
https:/www.bioconductor.org/packages/release/bioc/vignettes/methylKit/inst/doc/methylKit.html
- get nearest TSS
- get region annotation


#+begin_src R
## --- deps ---
library(methylKit)
library(GenomicRanges)
library(dplyr)
library(tidyr)

# CpG context
library(annotatr)

# Gene parts + TSS
library(genomation)  # (for distanceToNearest helper; also loads GenomicRanges)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(GenomeInfoDb)
library(AnnotationDbi)
library(org.Hs.eg.db)

## --- 0) load methylKit base-resolution object ---
# md should be methylBase/methylBaseDB at base resolution (not tiles)
md <- methylKit:::readMethylDB(
  "~/repos/emseq/tests/full/emseq/dmr/diff/methylDiff_test.txt.bgz"
)

gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)   # stable key per CpG

## --- 1) CpG context flags: island / shore / shelf / inter (open sea) ---
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) |>
  as_tibble() |>
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(GenomicRanges::seqnames(gr)),
  q_start = GenomicRanges::start(gr),
  q_end   = GenomicRanges::end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a |>
  right_join(keys, by = c("q_chr","q_start","q_end")) |>
  group_by(qid) |>
  summarize(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

## --- 2) Gene parts + nearest TSS (strand-aware) ---
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb), use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = 2000, downstream = 500)  # tweak widths
tsspt <- promoters(txdb, upstream = 0,    downstream = 1)    # 1bp TSS

# harmonize naming; drop to seqlevels present in gr
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

# per-CpG flags
is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0

gene_part_primary <- ifelse(is_prom,  "promoter",
                       ifelse(is_exon,  "exon",
                       ifelse(is_intron,"intron",
                       ifelse(is_5utr,  "5UTR",
                       ifelse(is_3utr,  "3UTR", "intergenic")))))

# nearest TSS distance + symbol
nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# map TSS to gene symbols (TxDb uses Entrez gene_id)
gs <- genes(txdb); gs <- keepSeqlevels(gs, wanted, pruning.mode = "coarse")
sub_hits <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select = "first")
entrez   <- mcols(gs)$gene_id[sub_hits]
sym_map  <- AnnotationDbi::select(org.Hs.eg.db,
                                  keys = unique(na.omit(entrez)),
                                  keytype = "ENTREZID", columns = "SYMBOL")
sym_lut  <- setNames(sym_map$SYMBOL, sym_map$ENTREZID)
nearest_symbol <- unname(sym_lut[entrez])

tss_key <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  nearest_gene_symbol = nearest_symbol
)

dist_tbl <- dist_tbl |>
  left_join(tss_key, by = "tss_idx") |>
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) |>
  left_join(dist_tbl, by = "qid")

## --- 3) Final one-row-per-CpG table (no writing yet) ---
out <- as_tibble(getData(md)) |>
  mutate(qid = row_number()) |>
  left_join(cpg_flags,  by = "qid") |>
  left_join(gene_flags, by = "qid")

out
#+end_src

#+begin_src R
# ------- inputs: mb_base (base-resolution methylBase/DB for cohort) -------
library(methylKit)
library(GenomicRanges)
library(annotatr)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)
library(GenomeInfoDb)
library(AnnotationDbi)
library(org.Hs.eg.db)
library(dplyr)
library(arrow)  # or fst/feather

# 1) cohort CpG set from mb_base
dt <- as.data.frame(getData(mb_base))      # chr,start,end,strand, counts...
gr <- GRanges(dt$chr, IRanges(dt$start, dt$end), strand = dt$strand)
cpg_id <- paste(dt$chr, dt$start, sep=":")

# 2) CpG-context flags via annotatr (island/shore/shelf/inter)
ann_cpg <- build_annotations(genome="hg38", annotations="hg38_cpgs")
a <- annotate_regions(gr, ann_cpg, ignore.strand=TRUE, quiet=TRUE) |>
     as_tibble() |>
     transmute(q_chr=as.character(seqnames), q_start=start, type=annot.type)
keys <- tibble(q_chr=as.character(seqnames(gr)), q_start=start(gr), qid=seq_along(gr))
cpg_ctx <- a |>
  right_join(keys, by=c("q_chr","q_start")) |>
  group_by(qid) |>
  summarise(
    is_island  = any(type=="hg38_cpg_islands"),
    is_shore   = any(type=="hg38_cpg_shores"),
    is_shelf   = any(type=="hg38_cpg_shelves"),
    is_opensea = any(type=="hg38_cpg_inter"),
    .groups="drop"
  )

# 3) Gene parts + TSS (strand-aware) via TxDb
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
ex    <- keepStandardChromosomes(exons(txdb),   pruning.mode="coarse")
intr  <- keepStandardChromosomes(unlist(intronsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
utr5  <- keepStandardChromosomes(unlist(fiveUTRsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
utr3  <- keepStandardChromosomes(unlist(threeUTRsByTranscript(txdb), use.names=FALSE), pruning.mode="coarse")
prom  <- keepStandardChromosomes(promoters(txdb, 2000, 500), pruning.mode="coarse")
tsspt <- keepStandardChromosomes(promoters(txdb, 0, 1), pruning.mode="coarse")
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex<-keepSeqlevels(ex,wanted,pruning.mode="coarse"); intr<-keepSeqlevels(intr,wanted,"coarse")
utr5<-keepSeqlevels(utr5,wanted,"coarse"); utr3<-keepSeqlevels(utr3,wanted,"coarse")
prom<-keepSeqlevels(prom,wanted,"coarse"); tsspt<-keepSeqlevels(tsspt,wanted,"coarse")

is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0
gene_primary <- ifelse(is_prom,"promoter",
                  ifelse(is_exon,"exon",
                  ifelse(is_intron,"intron",
                  ifelse(is_5utr,"5UTR",
                  ifelse(is_3utr,"3UTR","intergenic")))))

nn <- distanceToNearest(gr, tsspt, ignore.strand=FALSE)
dist_tbl <- tibble(qid = queryHits(nn), dist_to_TSS = mcols(nn)$distance, tss_idx = subjectHits(nn))
gs <- genes(txdb); gs <- keepSeqlevels(gs, wanted, pruning.mode="coarse")
map <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select="first")
entrez <- mcols(gs)$gene_id[map]
sym <- AnnotationDbi::select(org.Hs.eg.db, keys=unique(na.omit(entrez)),
                             keytype="ENTREZID", columns="SYMBOL")
sym_lut <- setNames(sym$SYMBOL, sym$ENTREZID)
tss_key <- tibble(tss_idx = unique(dist_tbl$tss_idx),
                  nearest_gene_symbol = unname(sym_lut[entrez]))
dist_tbl <- left_join(dist_tbl, tss_key, by="tss_idx") |> select(-tss_idx)

gene_flags <- tibble(
  qid = seq_along(gr),
  is_promoter = is_prom, is_exon = is_exon, is_intron = is_intron,
  is_5utr = is_5utr, is_3utr = is_3utr,
  gene_part_primary = gene_primary
) |>
  left_join(dist_tbl, by="qid")

# 4) Persist CpG annotation keyed by cpg_id (chr:start)
cpg_anno <- tibble(
  cpg_id = cpg_id
) |>
  mutate(qid = row_number()) |>
  left_join(cpg_ctx,  by="qid") |>
  left_join(gene_flags, by="qid") |>
  dplyr::select(-qid)

write_parquet(cpg_anno, "/tmp/cpg_annotation_hg38.parquet")   # <â€” reuse for every diff file

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges)
  library(GenomeInfoDb)
  library(dplyr)
  library(tidyr)
  library(annotatr)
  library(genomation)
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  library(AnnotationDbi)
  library(org.Hs.eg.db)
})

## --- 1) CLI arguments ---
parser <- ArgumentParser(description = "Annotate base-resolution methylKit objects with CpG context, gene parts, and TSS info")

parser$add_argument("--db", required = TRUE,
  help = "Path to methylKit base-resolution DB file (.txt.bgz)")
parser$add_argument("--prom-up", type = "integer", default = 2000,
  help = "Promoter upstream bp [default: 2000]")
parser$add_argument("--prom-dn", type = "integer", default = 500,
  help = "Promoter downstream bp [default: 500]")
parser$add_argument("--with-symbols", action = "store_true",
  help = "Also map nearest TSS to HGNC gene symbol")
parser$add_argument("--out", required = TRUE,
  help = "Output TSV with annotations")

args <- parser$parse_args()

## --- 2) Load methylKit DB ---
md <- methylKit:::readMethylDB(args$db)

gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)

## --- 3) CpG context (island/shore/shelf/opensea) ---
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) %>%
  as_tibble() %>%
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(seqnames(gr)),
  q_start = start(gr),
  q_end   = end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a %>%
  right_join(keys, by = c("q_chr","q_start","q_end")) %>%
  group_by(qid) %>%
  summarise(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

## --- 4) Gene parts + nearest TSS ---
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = args$prom_up, downstream = args$prom_dn)
tsspt <- promoters(txdb, upstream = 0, downstream = 1)

for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

is_prom   <- countOverlaps(gr, prom) > 0
is_exon   <- countOverlaps(gr, ex)   > 0
is_intron <- countOverlaps(gr, intr) > 0
is_5utr   <- countOverlaps(gr, utr5) > 0
is_3utr   <- countOverlaps(gr, utr3) > 0

gene_part_primary <- ifelse(is_prom,  "promoter",
                        ifelse(is_exon,  "exon",
                        ifelse(is_intron,"intron",
                        ifelse(is_5utr,  "5UTR",
                        ifelse(is_3utr,  "3UTR", "intergenic")))))

nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

if (args$with_symbols) {
  gs <- genes(txdb) %>% keepSeqlevels(wanted, pruning.mode = "coarse")
  sub_hits <- findOverlaps(tsspt[unique(dist_tbl$tss_idx)], gs, select = "first")
  entrez   <- mcols(gs)$gene_id[sub_hits]
  sym_map  <- AnnotationDbi::select(org.Hs.eg.db,
                                    keys = unique(na.omit(entrez)),
                                    keytype = "ENTREZID", columns = "SYMBOL")
  sym_lut  <- setNames(sym_map$SYMBOL, sym_map$ENTREZID)
  nearest_symbol <- unname(sym_lut[entrez])

  tss_key <- tibble(
    tss_idx = unique(dist_tbl$tss_idx),
    nearest_gene_symbol = nearest_symbol
  )

  dist_tbl <- dist_tbl %>%
    left_join(tss_key, by = "tss_idx") %>%
    dplyr::select(-tss_idx)
} else {
  dist_tbl <- dist_tbl %>%
    dplyr::select(-tss_idx)
}

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) %>%
  left_join(dist_tbl, by = "qid")

## --- 5) Assemble and write output ---
out <- as_tibble(getData(md)) %>%
  mutate(qid = dplyr::row_number()) %>%
  left_join(cpg_flags,  by = "qid") %>%
  left_join(gene_flags, by = "qid") %>%
  dplyr::select(
    chr, start, end, strand,
    qid,
    dplyr::starts_with("is_"),
    gene_part_primary,
    dist_to_TSS,
    dplyr::everything()
  )

readr::write_tsv(out, args$out)

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges)
  library(GenomeInfoDb)
  library(dplyr)
  library(tidyr)
  library(annotatr)                               # CpG context (hg38_cpgs)
  library(genomation)                             # distanceToNearest()
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)      # promoters/exons/introns/UTRs/TSS
  library(AnnotationDbi)
  library(org.Hs.eg.db)                           # ENTREZâ†”SYMBOL/ENSEMBL
  library(readr)
})

# ----------------------------- CLI -----------------------------
parser <- ArgumentParser(
  description = "Annotate base-resolution methylKit DB with CpG context, gene parts, and TSS info"
)
parser$add_argument("--db", required = TRUE,
  help = "Path to methylKit tabix DB (.txt.bgz) for base-resolution or methylDiff")
parser$add_argument("--prom-up", type = "integer", default = 2000,
  help = "Promoter upstream bp [default: 2000]")
parser$add_argument("--prom-dn", type = "integer", default = 500,
  help = "Promoter downstream bp [default: 500]")
parser$add_argument("--with-symbols", action = "store_true",
  help = "Also map nearest TSS to SYMBOL and ENSEMBL (via org.Hs.eg.db)")
parser$add_argument("--out", required = TRUE,
  help = "Output TSV path")
args <- parser$parse_args()

# ----------------------- Load loci (STRICT) ----------------------
# You told me to always use this reader. Done.
md <- methylKit:::readMethylDB(args$db)
gr <- as(md, "GRanges")
mcols(gr)$qid <- seq_along(gr)   # stable key per CpG locus

# -------------------- CpG context (annotatr) --------------------
# hg38_cpgs yields *disjoint* classes: islands, shores, shelves, inter
ann_cpg <- build_annotations(genome = "hg38", annotations = "hg38_cpgs")

a <- annotate_regions(gr, ann_cpg, ignore.strand = TRUE, quiet = TRUE) %>%
  as_tibble() %>%
  transmute(
    q_chr   = as.character(seqnames),
    q_start = start,
    q_end   = end,
    type    = annot.type
  )

keys <- tibble(
  q_chr   = as.character(seqnames(gr)),
  q_start = start(gr),
  q_end   = end(gr),
  qid     = mcols(gr)$qid
)

cpg_flags <- a %>%
  right_join(keys, by = c("q_chr","q_start","q_end")) %>%
  group_by(qid) %>%
  summarise(
    is_island  = any(type == "hg38_cpg_islands",  na.rm = TRUE),
    is_shore   = any(type == "hg38_cpg_shores",   na.rm = TRUE),
    is_shelf   = any(type == "hg38_cpg_shelves",  na.rm = TRUE),
    is_opensea = any(type == "hg38_cpg_inter",    na.rm = TRUE),
    .groups = "drop"
  )

# --------------- Gene parts + nearest TSS (TxDb) ----------------
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene

# Transcript-level features
ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names = FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names = FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names = FALSE)
prom  <- promoters(txdb, upstream = args$prom_up, downstream = args$prom_dn)
tsspt <- promoters(txdb, upstream = 0, downstream = 1)  # 1-bp TSS; has tx_id

# Harmonize naming + limit to chromosomes we actually have
for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
ex    <- keepStandardChromosomes(ex,   pruning.mode = "coarse")
intr  <- keepStandardChromosomes(intr, pruning.mode = "coarse")
utr5  <- keepStandardChromosomes(utr5, pruning.mode = "coarse")
utr3  <- keepStandardChromosomes(utr3, pruning.mode = "coarse")
prom  <- keepStandardChromosomes(prom, pruning.mode = "coarse")
tsspt <- keepStandardChromosomes(tsspt, pruning.mode = "coarse")

wanted <- intersect(seqlevels(gr), seqlevels(ex))
ex    <- keepSeqlevels(ex,    wanted, pruning.mode = "coarse")
intr  <- keepSeqlevels(intr,  wanted, pruning.mode = "coarse")
utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode = "coarse")
utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode = "coarse")
prom  <- keepSeqlevels(prom,  wanted, pruning.mode = "coarse")
tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode = "coarse")

# Fast boolean flags (no many-to-many expansion)
is_prom   <- countOverlaps(gr, prom) > 0L
is_exon   <- countOverlaps(gr, ex)   > 0L
is_intron <- countOverlaps(gr, intr) > 0L
is_5utr   <- countOverlaps(gr, utr5) > 0L
is_3utr   <- countOverlaps(gr, utr3) > 0L

# Precedence (explicit, reproducible):
# promoter > exon > intron > 5UTR > 3UTR > intergenic
gene_part_primary <- ifelse(is_prom,  "promoter",
                        ifelse(is_exon,  "exon",
                        ifelse(is_intron,"intron",
                        ifelse(is_5utr,  "5UTR",
                        ifelse(is_3utr,  "3UTR", "intergenic")))))

# Nearest TSS distance (strand-aware)
nn <- distanceToNearest(gr, tsspt, ignore.strand = FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# Map nearest TSS transcript -> ENTREZID -> SYMBOL/ENSEMBL
# (TxDb promoters carry tx_id; use TxDb::select to map TXID -> GENEID/ENTREZ)
tx_for_tss <- mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)]
tx_map <- AnnotationDbi::select(
  x       = txdb,
  keys    = as.character(tx_for_tss),
  keytype = "TXID",
  columns = c("TXID","GENEID")
)
# Keep first mapping per TSS index
tss2tx <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  TXID    = as.character(mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)])
) %>%
  left_join(tx_map, by = "TXID") %>%
  distinct(tss_idx, .keep_all = TRUE)

# Add SYMBOL and ENSEMBL
if (args$with_symbols) {
  gene_map <- AnnotationDbi::select(
    org.Hs.eg.db,
    keys    = unique(na.omit(tss2tx$GENEID)),
    keytype = "ENTREZID",
    columns = c("SYMBOL","ENSEMBL")
  )
  gene_map <- gene_map %>%
    distinct(ENTREZID, .keep_all = TRUE) %>%
    rename(ENTREZID = ENTREZID)
  tss2tx <- tss2tx %>%
    rename(ENTREZID = GENEID) %>%
    left_join(gene_map, by = "ENTREZID")
} else {
  tss2tx <- tss2tx %>% rename(ENTREZID = GENEID)
}

dist_tbl <- dist_tbl %>%
  left_join(tss2tx %>% dplyr::select(tss_idx, ENTREZID, dplyr::any_of(c("SYMBOL","ENSEMBL"))),
            by = "tss_idx") %>%
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_exon     = is_exon,
  is_intron   = is_intron,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  gene_part_primary = gene_part_primary
) %>%
  left_join(dist_tbl, by = "qid")

# -------------------- Assemble & write --------------------------
out <- as_tibble(getData(md)) %>%
  mutate(qid = dplyr::row_number()) %>%
  left_join(cpg_flags,  by = "qid") %>%
  left_join(gene_flags, by = "qid") %>%
  # put useful columns first (your style: dplyr::select)
  dplyr::select(
    chr, start, end, strand,
    qid,
    dplyr::starts_with("is_"),
    gene_part_primary,
    dist_to_TSS,
    dplyr::any_of(c("ENTREZID","SYMBOL","ENSEMBL")),
    dplyr::everything()
  )

readr::write_tsv(out, args$out)

# --------------------- Notes (sources) --------------------------
# CpG context: annotatr::hg38_cpgs (islands/shores/shelves/inter) â€“ disjoint classes.
# Gene models: TxDb.Hsapiens.UCSC.hg38.knownGene (UCSC knownGene; transcript-centric).
# TSS: 1-bp promoters(txdb, 0, 1); nearest computed strand-aware with distanceToNearest().
# ID mapping: org.Hs.eg.db (ENTREZIDâ†”SYMBOL/ENSEMBL).
# Overlap/precedence: booleans may all be TRUE for a locus (e.g., exon & promoter overlap);
#   we report all flags and a primary label using:
#   promoter > exon > intron > 5UTR > 3UTR > intergenic (fixed).

#+end_src

#+begin_src R :tangle /tmp/test.R
#!/usr/bin/env Rscript

suppressPackageStartupMessages({
  library(argparse)
  library(methylKit)
  library(GenomicRanges); library(GenomeInfoDb)
  library(dplyr); library(tidyr); library(readr)
  library(annotatr)                               # CpG context (hg38_cpgs)
  suppressWarnings(library(genomation))           # hush Biostrings::pattern clash
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)      # gene parts / TSS
  library(AnnotationDbi); library(org.Hs.eg.db)   # ENTREZ â†” SYMBOL/ENSEMBL
})

# ----- CLI -----
parser <- ArgumentParser(description="Annotate methylKit DB with CpG context, gene parts, TSS, and IDs")
parser$add_argument("--db",  required=TRUE, help="Path to methylKit tabix DB (.txt.bgz)")
parser$add_argument("--out", required=TRUE, help="Output TSV")
parser$add_argument("--prom-up", type="integer", default=2000, help="Promoter upstream bp [2000]")
parser$add_argument("--prom-dn", type="integer", default=500,  help="Promoter downstream bp [500]")
args <- parser$parse_args()

# ----- noise filter for seqinfo ALT/decoy warnings -----
muffle_outofbound <- function(expr) {
  withCallingHandlers(expr, warning=function(w){
    if (grepl("out-of-bound ranges located on sequences", conditionMessage(w)))
      invokeRestart("muffleWarning")
  })
}

# ----- Load loci (STRICT reader) -----
md <- methylKit:::readMethylDB(args$db)
gr <- as(md, "GRanges"); mcols(gr)$qid <- seq_along(gr)

# ----- CpG context (disjoint) -----
ann_cpg <- suppressMessages(build_annotations(genome="hg38", annotations="hg38_cpgs"))

a <- annotate_regions(gr, ann_cpg, ignore.strand=TRUE, quiet=TRUE) |>
  as_tibble() |>
  transmute(q_chr=as.character(seqnames), q_start=start, q_end=end, type=annot.type)

keys <- tibble(q_chr=as.character(seqnames(gr)), q_start=start(gr), q_end=end(gr), qid=mcols(gr)$qid)

cpg_flags <- a |>
  right_join(keys, by=c("q_chr","q_start","q_end")) |>
  group_by(qid) |>
  summarise(
    is_island  = any(type=="hg38_cpg_islands",  na.rm=TRUE),
    is_shore   = any(type=="hg38_cpg_shores",   na.rm=TRUE),
    is_shelf   = any(type=="hg38_cpg_shelves",  na.rm=TRUE),
    is_opensea = any(type=="hg38_cpg_inter",    na.rm=TRUE),
    .groups="drop"
  )

# ----- Gene parts + nearest TSS -----
txdb  <- TxDb.Hsapiens.UCSC.hg38.knownGene
ex    <- exons(txdb)
intr  <- unlist(intronsByTranscript(txdb), use.names=FALSE)
utr5  <- unlist(fiveUTRsByTranscript(txdb),  use.names=FALSE)
utr3  <- unlist(threeUTRsByTranscript(txdb), use.names=FALSE)
prom  <- promoters(txdb, upstream=args$prom_up, downstream=args$prom_dn)
tsspt <- promoters(txdb, upstream=0, downstream=1)

for (x in list(ex,intr,utr5,utr3,prom,tsspt)) seqlevelsStyle(x) <- seqlevelsStyle(gr)
muffle_outofbound({
  ex    <- keepStandardChromosomes(ex,   pruning.mode="coarse")
  intr  <- keepStandardChromosomes(intr, pruning.mode="coarse")
  utr5  <- keepStandardChromosomes(utr5, pruning.mode="coarse")
  utr3  <- keepStandardChromosomes(utr3, pruning.mode="coarse")
  prom  <- keepStandardChromosomes(prom, pruning.mode="coarse")
  tsspt <- keepStandardChromosomes(tsspt,pruning.mode="coarse")

  wanted <- intersect(seqlevels(gr), seqlevels(ex))
  ex    <- keepSeqlevels(ex,    wanted, pruning.mode="coarse")
  intr  <- keepSeqlevels(intr,  wanted, pruning.mode="coarse")
  utr5  <- keepSeqlevels(utr5,  wanted, pruning.mode="coarse")
  utr3  <- keepSeqlevels(utr3,  wanted, pruning.mode="coarse")
  prom  <- keepSeqlevels(prom,  wanted, pruning.mode="coarse")
  tsspt <- keepSeqlevels(tsspt, wanted, pruning.mode="coarse")
})

is_prom     <- countOverlaps(gr, prom) > 0L
is_5utr     <- countOverlaps(gr, utr5) > 0L
is_3utr     <- countOverlaps(gr, utr3) > 0L
is_exon_raw <- countOverlaps(gr, ex)   > 0L
is_exon     <- is_exon_raw & !is_5utr & !is_3utr   # UTR âŠ‚ exon â†’ exclude
is_intron   <- countOverlaps(gr, intr) > 0L

# Corrected precedence: promoter > 5UTR > 3UTR > exon > intron > intergenic
gene_part_primary <- ifelse(is_prom, "promoter",
                        ifelse(is_5utr, "5UTR",
                        ifelse(is_3utr, "3UTR",
                        ifelse(is_exon, "exon",
                        ifelse(is_intron, "intron", "intergenic")))))

# nearest TSS (strand-aware)
nn <- distanceToNearest(gr, tsspt, ignore.strand=FALSE)
dist_tbl <- tibble(
  qid         = mcols(gr)$qid[queryHits(nn)],
  dist_to_TSS = mcols(nn)$distance,
  tss_idx     = subjectHits(nn)
)

# TSS -> TXID -> ENTREZID -> SYMBOL/ENSEMBL
tx_for_tss <- mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)]
tx_map <- suppressMessages(AnnotationDbi::select(
  x=txdb, keys=as.character(tx_for_tss),
  keytype="TXID", columns=c("TXID","GENEID")
))

tss2tx <- tibble(
  tss_idx = unique(dist_tbl$tss_idx),
  TXID    = as.character(mcols(tsspt)$tx_id[unique(dist_tbl$tss_idx)])
) |>
  left_join(tx_map, by="TXID") |>
  distinct(tss_idx, .keep_all=TRUE) |>
  rename(ENTREZID = GENEID)

gene_map <- suppressMessages(AnnotationDbi::select(
  org.Hs.eg.db,
  keys    = unique(na.omit(tss2tx$ENTREZID)),
  keytype = "ENTREZID",
  columns = c("SYMBOL","ENSEMBL")
)) |>
  distinct(ENTREZID, .keep_all=TRUE)

tss2tx <- tss2tx |> left_join(gene_map, by="ENTREZID")

dist_tbl <- dist_tbl |>
  left_join(tss2tx |> dplyr::select(tss_idx, ENTREZID, SYMBOL, ENSEMBL), by="tss_idx") |>
  dplyr::select(-tss_idx)

gene_flags <- tibble(
  qid = mcols(gr)$qid,
  is_promoter = is_prom,
  is_5utr     = is_5utr,
  is_3utr     = is_3utr,
  is_exon     = is_exon,
  is_intron   = is_intron,
  gene_part_primary = gene_part_primary
) |>
  left_join(dist_tbl, by="qid")

# ----- Assemble; DROP coverage/numC/numT -----
raw_dt <- as_tibble(getData(md))

out <- raw_dt |>
  mutate(qid = dplyr::row_number()) |>
  left_join(cpg_flags,  by="qid") |>
  left_join(gene_flags, by="qid") |>
  dplyr::select(
    chr, start, end, strand, qid,
    dplyr::starts_with("is_"),
    gene_part_primary, dist_to_TSS,
    ENTREZID, SYMBOL, ENSEMBL,
    dplyr::everything(),
    -dplyr::matches("^(coverage|numCs?|numTs?)\\d*$", ignore.case=TRUE)
  )

readr::write_tsv(out, args$out)
#+end_src

*** Biscuit
**** Index
#+begin_src snakemake
rule emseq_biscuit_index:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        lambda wildcards: f"{data_dir}/inputs/{config['emseq_ref_assemblies'][wildcards.name]['input']}"
    output:
        fasta = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa",
        fai = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.fai",
        biscuit_index_done = f"{data_dir}/ref/biscuit/{{name}}/{{name}}.fa.biscuit.index.done"
    log:
        f"{config['log-dir']}/{{name}}_biscuit_index.log"
    shell:
        """
        mkdir -p $(dirname {output.fasta}) && \
        zcat {input} > {output.fasta} && \
        samtools faidx {output.fasta} && \
        biscuit index {output.fasta} > {log} 2>&1 && \
        touch {output.biscuit_index_done}
        """

#+end_src

**** Align
#+begin_src snakemake
rule emseq_align_biscuit:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        r1 = f"{data_dir}/analysis/emseq/fastqs/{{library_id}}.trimmed_R1.fastq.gz",
        r2 = f"{data_dir}/analysis/emseq/fastqs/{{library_id}}.trimmed_R2.fastq.gz",
        fasta = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa",
        index = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa.par.sa",
    log:
        cmd = f"{config['log-dir']}/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
    output:
        bam = f"{config['emseq-dir']}/bams/{{library_id}}.{{ref_name}}.biscuit.coorsort.bam",
    params:
        threads = 80,
    resources:
        concurrency=100
    shell:
        """
        mkdir -p {data_dir}/tmp && \
        biscuit align \
        -@ {params.threads} \
        -biscuit-ref {input.fasta} \
        {input.r1} {input.r2} \
        | samtools sort \
        -@ 8 \
        -m 2G \
        -T {data_dir}/tmp/{wildcards.library_id}_sorttmp \
        -o {output.bam} &>> {log}
        """

#+end_src
**** [[id:4ac48779-f505-4291-b7bf-cc950d3339e6][De-duplicate]]
**** Pileup
#+begin_src snakemake
rule emseq_biscuit_pileup:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        bam = f"{config['emseq-dir']}/bams/{{library_id}}.{{ref_name}}.biscuit.coorsort.deduped.bam",
        fasta = f"{data_dir}/ref/biscuit/{{ref_name}}/{{ref_name}}.fa",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}.biscuit_emseq_pileup.log",
    output:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf.gz",
        tsv = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf_meth_average.tsv",
    params:
        out_base = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf",
    shell:
        """
        biscuit pileup \
        -@ 20 \
        -o {params.out_base} \
        {input.fasta} {input.bam} \
        && bgzip -@ 8 {params.out_base}
        """
#+end_src
#+begin_src snakemake
rule emseq_biscuit_post_pileup:
    conda:
        f"{config['emseq-conda-env']}",
    input:
        vcf = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}.biscuit_pileup.vcf.gz",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}_emseq_biscuit_post_pileup.log",
    output:
        tbi = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_pileup.vcf.gz.tbi",
        bed = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_pileup.bed",
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_bismark_cov.bed",
    shell:
        """
        tabix -p vcf {input.vcf} \
        && biscuit vcf2bed \
	-t cg {input.vcf} > {output.bed} \
        && biscuit vcf2bed -c {input.vcf} > {output.bismark} &> {log}
        """
#+end_src

#+begin_src snakemake
rule make_single_biscuit_methylkit_obj:
    conda:
        "../config/methylkit-conda-env.yaml",
    input:
        bismark = f"{data_dir}/analysis/emseq/pileup/{{library_id}}.{{ref_name}}_bismark_cov.bed",
    log:
        f"{config['log-dir']}/{{library_id}}.{{ref_name}}_make_single_biscuit_methylkit_obj.log",
    output:
        txt = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt",
        bgz = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt.bgz",
        tbi = f"{data_dir}/analysis/emseq/post-biscuit/{{library_id}}.{{ref_name}}_biscuit.txt.bgz.tbi",
    params:
        Rscript = f"{config['emseq-script-dir']}/make_single_biscuit_methylkit_obj.R",
        out_dir = f"{data_dir}/analysis/emseq/post-biscuit",
    shell:
        """
        Rscript {params.Rscript} \
          --bismark_cov_bed {input.bismark} \
          --library_id {wildcards.library_id} \
          --out_dir {params.out_dir} \
          &> {log}
        """
#+end_src

#+begin_src R :tangle ./scripts/make_single_biscuit_methylkit_obj.R
library(argparse)
library(methylKit)

parser <- ArgumentParser()
parser$add_argument("--bismark_cov_bed", required = TRUE)
parser$add_argument("--library_id", required = TRUE)
parser$add_argument("--treatment", type = "integer", required = TRUE)
parser$add_argument("--out_dir", required = TRUE)

args <- parser$parse_args()

myobj= methRead(args$bismark_cov_bed,
                sample.id = args$library_id,
                treatment = 1,
                context="CpG",
                pipeline="bismarkCoverage",
                mincov = 2,
                assembly= "hg38",
                dbtype = "tabix",
                dbdir = args$out_dir)

#+end_src



*** variant calling
- https:/pmc.ncbi.nlm.nih.gov/articles/PMC10072131/
*** Input data model
#+begin_src yaml
defaults:
  required: false       # Default: fields are not required unless specified
  primary_key: false    # Default: fields are not primary keys unless specified

entities:
  - name: subjects
    attributes:
      - name: subject_id
        type: string
        primary_key: true      # Unique identifier for each subject
        required: true

  - name: samples
    attributes:
      - name: sample_id
        type: string
        primary_key: true      # Unique ID for each sample
        required: true
      - name: subject_id
        type: string
        foreign_key: subjects.subject_id   # Link back to subject
        required: true
      - name: sample_type
        type: enum
        values: [biofluid, tissue]         # Sample subtype
        required: true
      - name: collection_date
        type: datetime                         # When sample was collected

  - name: biofluid
    attributes:
      - name: sample_id
        type: string
        primary_key: true
        foreign_key: samples.sample_id     # Must match a sample of type biofluid
        required: true
      - name: biofluid_type
        type: enum
        values: [plasma, serum, csf, drain, urine, other]   # Specific fluid type
      - name: cfdna_conc
        type: float
        unit: ng/uL                         # Concentration of cfDNA

  - name: biofluid_derivative
    attributes:
      - name: aliquot_id
        type: string
        primary_key: true                  # Unique ID for each aliquot
        required: true
      - name: sample_id
        type: string
        foreign_key: biofluid.sample_id    # Parent biofluid sample
        required: true
      - name: biofluid_derivative_type
        type: enum
        values: [ppp, pfp, other]          # Processing method
      - name: derivative_processing_date
        type: date                         # When derivative was processed

  - name: tissue
    attributes:
      - name: sample_id
        type: string
        primary_key: true
        foreign_key: samples.sample_id     # Must match a sample of type tissue
        required: true

  - name: libraries
    attributes:
      - name: library_id
        type: string
        primary_key: true                  # Unique ID for each library
        required: true
      - name: sample_id
        type: string
        foreign_key: samples.sample_id     # Source sample for this library
        required: true
      - name: pcr_cycltes
        type: integer
      - name: expected_coverage
        type: integer

  - name: sequencing
    attributes:
      - name: seq_run_id
        type: string
        primary_key: true                  # Unique ID for sequencing run
        required: true
      - name: library_id
        type: string
        foreign_key: libraries.library_id  # Library used in sequencing
        required: true
      - name: run_date
        type: date                         # When sequencing occurred
      - name: read_length
        type: integer                      # Read length (e.g. 150)
        required: true
      - name: paired_end
        type: boolean                      # True if paired-end sequencing
        required: true

relationships:
  - from: subjects
    to: samples
    type: one-to-many       # One subject can have many samples

  - from: samples
    to: libraries
    type: one-to-many       # One sample can yield multiple libraries

  - from: samples
    to: biofluid
    type: one-to-one        # A sample is either biofluid or tissue

  - from: samples
    to: tissue
    type: one-to-one        # "

  - from: biofluid
    to: biofluid_derivative
    type: one-to-many       # Each biofluid must have at least one aliquot

  - from: libraries
    to: sequencing
    type: one-to-many       # A library can be sequenced multiple times
#+end_src
*** cfDNA methylation and fragmentation
- [cite:@noe2024]

**** An 2023 methylation and fragmentation patterns


#+begin_src bash
#ssh jeff-nf1

#mamba install -c bioconda -c conda-forge bismark -n emseq

conda activate emseq



# ---- settings ----
GENOME_NAME=ncbi_hg38
GENOME_ROOT=/mnt/data/projects/nf1/ref/bismark
GENOME_DIR=$GENOME_ROOT/$GENOME_NAME
INDEX_DIR=$GENOME_DIR/bismark_index
THREADS=16

# ---- prep dirs ----
mkdir -p "$INDEX_DIR"

# By default, bismark expects fasta(s) in the target folder.
# So place the FASTA there (symlink is fine) BEFORE running:

cd /mnt/data/projects/nf1/inputs

wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz

gunzip -c GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz.1 > ../ref/bismark/ncbi_hg38/bismark_index/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa

cd "$GENOME_DIR"

# ---- build the Bismark index (Bowtie2) ----
# (Requires: bismark, bowtie2, perl)
bismark_genome_preparation \
  --bowtie2 \
  --parallel "$THREADS" \
  --verbose \
  "$INDEX_DIR"


# ---- sanity check: index files should now exist ----
ls -1 "$INDEX_DIR" | grep -E 'Bisulfite_Genome|.bt2$'

mkdir -p /mnt/data/projects/nf1/tmp

cd /mnt/data/projects/nf1/tmp/bismark_out

# these write to dir of action
bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out

nohup bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_05.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out \
  > bismark_emseq05.log 2>&1 &

nohup bismark --non_directional \
  -p 24 \
  /mnt/data/projects/nf1/ref/bismark/ncbi_hg38/bismark_index \
  -1 /mnt/data/projects/nf1/emseq/fastqs/emseq_06.raw_R1.fastq.gz \
  -2 /mnt/data/projects/nf1/emseq/fastqs/emseq_06.raw_R2.fastq.gz \
  -o /mnt/data/projects/nf1/tmp/bismark_out \
  > bismark_emseq06.log 2>&1 &

##########1##########2##########3##########4##########5##########6##########7##########8
cp /mnt/data/projects/nf1/tmp/bismark_out/emseq_05.raw_R1_bismark_bt2_pe.bam /mnt/data/projects/nf1/tmp/an/emseq_05.bam

cp /mnt/data/projects/nf1/tmp/bismark_out/emseq_06.raw_R1_bismark_bt2_pe.bam /mnt/data/projects/nf1/tmp/an/emseq_06.bam

cd /mnt/data/projects/nf1/tmp/an
ls

samtools view -h emseq_05.bam | samtools view -b -o emseq_05_repaired.bam

samtools view -h emseq_06.bam | samtools view -b -o emseq_06_repaired.bam

python3 test3.py emseq_05_repaired.bam 10 > /tmp/emseq_05_meth_and_frag.tsv

python3 test3.py emseq_06_repaired.bam 10 > /tmp/emseq_06_meth_and_frag.tsv

python3 test3.py emseq_05_repaired.bam > /tmp/emseq_05_meth_and_frag.tsv

python3 test3.py emseq_06_repaired.bam > /tmp/emseq_06_meth_and_frag.tsv

##########1##########2##########3##########4##########5##########6##########7##########8
# 2) Deduplicate the Bismark BAM (paired-end)
deduplicate_bismark --bam --paired \
  --output_dir /mnt/data/projects/nf1/tmp/bismark_out \
  /mnt/data/projects/nf1/tmp/bismark_out/emseq_12.raw_R1_bismark_bt2_pe.bam

#+end_src

#+begin_src R
library(tidyverse)

pn = read_tsv("/tmp/emseq_05_meth_and_frag.tsv") %>% mutate(dx = "pn")
mpnst = read_tsv("/tmp/emseq_06_meth_and_frag.tsv") %>% mutate(dx = "mpnst")

test=rbind(pn, mpnst)

test %>%
  filter(label != "mid") %>%
  filter(tlen < 167) %>%
  ggplot(aes(x = dx, fill = label)) +
  geom_bar(position = "fill") +
  labs(x = "Diagnosis", y = "Proportion", fill = "Methylation category")


test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(0, 400, 10))) %>%
  group_by(tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, group = 1)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(150, 300, 5))) %>%
  group_by(dx, tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, color = dx, group = dx)) +
  #geom_line() +
  geom_smooth(se=F) +
  labs(x = "Fragment length (bp bins)", y = "Mean CpG fraction") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  mutate(tlen_bin = cut(tlen, breaks = seq(0, 400, 10))) %>%
  group_by(dx, tlen_bin) %>%
  summarise(mean_cpg = mean(cpg_frac, na.rm = TRUE), .groups = "drop") %>%
  ggplot(aes(x = tlen_bin, y = mean_cpg, group = dx, color = dx)) +
  geom_line() +
  facet_wrap(~dx) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

test %>%
  filter(label != "mid") %>%
  filter(tlen > 167) %>%
  ggplot(aes(x = dx, fill = label)) +
  geom_bar(position = "fill") +
  labs(x = "Diagnosis", y = "Proportion", fill = "Methylation category")


test %>%
  mutate(frag_bin = ifelse(tlen < 167, "<167", ">167")) %>%
  group_by(dx, frag_bin) %>%
  summarise(frac_hyper = mean(label == "hypo"), .groups = "drop") %>%
  tidyr::pivot_wider(
    names_from = frag_bin,
    values_from = frac_hyper
  )

test %>%
  mutate(frag_bin = ifelse(tlen < 167, "<167", ">167")) %>%
  group_by(frag_bin) %>%
  summarise(frac_hyper = mean(label == "hypo"), .groups = "drop") %>%
  tidyr::pivot_wider(
    names_from = frag_bin,
    values_from = frac_hyper
  )

test %>%
  filter(label != "mid") %>%
  filter(tlen > 250) %>%
  count(dx, label) %>%
  ggplot(aes(x = dx, y = n, fill = label)) +
  geom_bar(stat = "identity") +
  labs(x = "Diagnosis", y = "Count", fill = "Methylation category")

test %>%
  filter(label != "mid") %>%
  ggplot(., aes(x=tlen, color = label)) + geom_density()

test %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_density(adjust = 0.7) +
  facet_wrap(~dx)

test %>%
  filter(tlen >155, tlen <250) %>%
  ggplot(aes(x = tlen, color = dx)) +
  geom_density(adjust = 0.6) +
  facet_wrap(~label)


test %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, fill = label)) +
  geom_histogram(position = "identity", alpha = 0.4, bins = 50)

df %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_density(adjust = 0.7)   # smaller = less smooth, more jagged

df %>%
  filter(tlen < 200, label != "mid") %>%
  ggplot(aes(x = tlen, color = label)) +
  geom_freqpoly(binwidth = 1)


#########1#########2#########3#########4#########5#########6#########7#########8

meth=read_tsv("/tmp/meth.tsv")

meth <- meth %>% rename(global_meth = `global%meth`)

# Run two-sample t-test
t.test(global_meth ~ dx, data = meth)
#+end_src
